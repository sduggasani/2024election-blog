[{"id":0,"href":"/2024election-blog/post/2024-11-13-final-prediction-postmortem/","title":"Final Prediction Postmortem","section":"Posts","content":" Final Prediction Postmortem # Monday, November 17, 2024\n2 Weeks since Presidential Election\nIt\u0026rsquo;s been two weeks since Donald Trump won the 2024 Presidential Election. If you remember my prediction, you\u0026rsquo;ll notice how this is not what my model ended up forecasting. The past few days have seen Democratic strategists scrambling to figure out where they fell short. This week, I\u0026rsquo;ll be doing much the same with regards to my model. We\u0026rsquo;ll focus on what my model got wrong and attempt to theorize what it actually did well — despite an incorrect prediction.\nModel Recap # As a reminder of my final model, I ultimately decided to go with a LASSO regression. I thought it was best to go with a conservative approach to building my model because so many election forecasts run into the issue of overfitting: they take in too much information that might not necessarily be significant on vote behavior and spin patterns out of the data that might not exist. LASSO was attractive to me because it wholly nullifies those predictions that are not as influential on the response variable and selects only those most relevant.\n## Loading required package: Matrix ## ## Attaching package: \u0026#39;Matrix\u0026#39; ## The following objects are masked from \u0026#39;package:tidyr\u0026#39;: ## ## expand, pack, unpack ## Loaded glmnet 4.1-6 ## Warning: Option grouped=FALSE enforced in cv.glmnet, since \u0026lt; 3 observations per ## fold ![](Screenshot 2024-11-18 at 8.46.31 PM.png)\nThis is just a reminder of the coefficients of each variable involved in the LASSO regression. As you can see, the LASSO model nullifies the mean Democratic poll average, and does not consider it to be a relevant predictor for the response variable of Democratic 2-Party vote share. LASSO also notably diminishes the significance of the Consumer Price Score and GDP Growth variables as compared to previous models.\n## Loading required package: Matrix ## ## Attaching package: \u0026#39;Matrix\u0026#39; ## The following objects are masked from \u0026#39;package:tidyr\u0026#39;: ## ## expand, pack, unpack ## Loaded glmnet 4.1-6 Table 1: (\\#tab:unnamed-chunk-5)Coefficients about a 95% Confidence Interval Predictor Lower Upper (Intercept) -37.0735241 50.2256605 D_pv2p_lag1 0.0000000 0.4574302 D_pv2p_lag2 -0.1224704 0.1576207 latest_pollav_DEM 0.4120334 1.5727115 mean_pollav_DEM -0.6909748 0.3996177 CPI -0.1254901 0.1407011 GDP_growth_quarterly -0.0994109 0.2102683 log(contribution_receipt_amount) -1.7544576 0.3380642 With bootstrapping, I got 95% confidence intervals for each variable and found most of them to include 0, which brought into question their relevance to the response variable. Nevertheless, I trusted LASSO to select those features which were most relevant to the model.\nState mean_dem sd_dem lower_dem upper_dem mean_rep sd_rep lower_rep upper_rep Arizona 49.82247 1.249856 47.37275 52.27219 50.17753 1.249856 47.72781 52.62725 Georgia 49.83683 1.254854 47.37731 52.29634 50.16317 1.254854 47.70366 52.62269 Michigan 50.62857 1.298490 48.08353 53.17361 49.37143 1.298490 46.82639 51.91647 Nevada 50.93553 1.256353 48.47308 53.39799 49.06447 1.256353 46.60201 51.52692 North Carolina 49.77338 1.336243 47.15435 52.39242 50.22662 1.336243 47.60758 52.84565 Pennsylvania 50.11565 1.238461 47.68827 52.54303 49.88435 1.238461 47.45697 52.31173 Wisconsin 51.04669 1.292186 48.51400 53.57938 48.95331 1.292186 46.42062 51.48600 Here, I have a chart of my vote share predictions for each battleground state and expected Michigan, Nevada, Pennsylvania, and Wisconsin to go to Harris while the rest (Arizona, Georgia, and North Carolina) would go to Trump. It is important to note, however, that for each state the win margin for each party was well within margin of error for a 95% confidence interval. This means that both Harris and Trump had a chance of winning each of the battleground states, according to my model.\nElection Recap # ## New names: ## New names: ## • `0` -\u0026gt; `0...31` ## • `0` -\u0026gt; `0...32` ## • `0` -\u0026gt; `0...33` ## • `0` -\u0026gt; `0...34` ## • `0` -\u0026gt; `0...35` ## • `0` -\u0026gt; `0...36` ## • `0` -\u0026gt; `0...37` ## • `0` -\u0026gt; `0...38` ## • `0` -\u0026gt; `0...39` ## • `0` -\u0026gt; `0...40` ## • `0` -\u0026gt; `0...41` ## • `0` -\u0026gt; `0...42` ## | | | 0% | | | 1% | |= | 2% | |== | 3% | |== | 4% | |=== | 5% | |==== | 5% | |==== | 6% | |===== | 7% | |====== | 8% | |======= | 9% | |======= | 10% | |======== | 11% | |======== | 12% | |========= | 13% | |========== | 14% | |=========== | 16% | |============ | 17% | |============= | 18% | |============= | 19% | |============== | 20% | |=============== | 21% | |=============== | 22% | |================ | 23% | |================= | 24% | |================= | 25% | |================== | 26% | |=================== | 27% | |=================== | 28% | |==================== | 28% | |==================== | 29% | |===================== | 30% | |===================== | 31% | |====================== | 31% | |====================== | 32% | |======================= | 33% | |======================== | 34% | |======================== | 35% | |========================= | 35% | |========================= | 36% | |========================== | 37% | |=========================== | 38% | |=========================== | 39% | |============================ | 40% | |============================ | 41% | |============================= | 41% | |============================= | 42% | |============================== | 43% | |=============================== | 44% | |=============================== | 45% | |================================ | 45% | |================================= | 47% | |================================= | 48% | |================================== | 49% | |=================================== | 50% | |==================================== | 51% | |===================================== | 52% | |===================================== | 53% | |====================================== | 54% | |======================================= | 55% | |======================================= | 56% | |======================================== | 57% | |======================================== | 58% | |========================================= | 59% | |========================================== | 60% | |=========================================== | 61% | |============================================ | 62% | |============================================ | 63% | |============================================= | 64% | |============================================== | 66% | |=============================================== | 67% | |================================================ | 68% | |================================================ | 69% | |================================================= | 70% | |================================================== | 71% | |=================================================== | 72% | |=================================================== | 73% | |==================================================== | 74% | |===================================================== | 76% | |====================================================== | 77% | |======================================================= | 78% | |======================================================= | 79% | |======================================================== | 79% | |======================================================== | 80% | |========================================================= | 81% | |========================================================= | 82% | |========================================================== | 83% | |=========================================================== | 85% | |============================================================ | 86% | |============================================================= | 87% | |============================================================== | 88% | |============================================================== | 89% | |=============================================================== | 90% | |================================================================ | 91% | |================================================================ | 92% | |================================================================= | 93% | |================================================================== | 94% | |================================================================== | 95% | |=================================================================== | 96% | |==================================================================== | 97% | |===================================================================== | 98% | |===================================================================== | 99% | |======================================================================| 100% ## | | | 0% | | | 1% | |= | 1% | |= | 2% | |== | 2% | |== | 3% | |=== | 4% | |=== | 5% | |==== | 6% | |===== | 7% | |====== | 8% | |====== | 9% | |======= | 10% | |======== | 11% | |========= | 13% | |========== | 14% | |========== | 15% | |=========== | 16% | |============ | 17% | |============= | 18% | |============= | 19% | |============== | 20% | |=============== | 21% | |=============== | 22% | |================ | 23% | |================= | 24% | |================== | 25% | |================== | 26% | |=================== | 27% | |=================== | 28% | |==================== | 29% | |===================== | 29% | |===================== | 30% | |====================== | 31% | |======================= | 32% | |======================= | 33% | |======================== | 34% | |========================= | 35% | |========================== | 37% | |=========================== | 38% | |=========================== | 39% | |============================ | 39% | |============================ | 40% | |============================= | 41% | |============================== | 43% | |=============================== | 44% | |=============================== | 45% | |================================ | 45% | |================================ | 46% | |================================= | 47% | |================================== | 48% | |================================== | 49% | |=================================== | 50% | |==================================== | 51% | |==================================== | 52% | |===================================== | 53% | |====================================== | 54% | |======================================= | 55% | |======================================= | 56% | |======================================== | 57% | |========================================= | 58% | |========================================= | 59% | |========================================== | 60% | |=========================================== | 61% | |=========================================== | 62% | |============================================ | 62% | |============================================ | 63% | |============================================= | 64% | |============================================== | 65% | |=============================================== | 67% | |=============================================== | 68% | |================================================ | 69% | |================================================= | 69% | |================================================== | 71% | |================================================== | 72% | |=================================================== | 73% | |==================================================== | 74% | |==================================================== | 75% | |===================================================== | 75% | |====================================================== | 77% | |====================================================== | 78% | |======================================================= | 79% | |======================================================== | 80% | |========================================================= | 81% | |========================================================= | 82% | |========================================================== | 82% | |========================================================== | 84% | |=========================================================== | 85% | |============================================================ | 86% | |============================================================== | 88% | |============================================================== | 89% | |=============================================================== | 90% | |================================================================ | 91% | |================================================================= | 93% | |================================================================== | 94% | |================================================================== | 95% | |=================================================================== | 96% | |==================================================================== | 97% | |==================================================================== | 98% | |===================================================================== | 99% | |======================================================================| 99% | |======================================================================| 100% ## [1] 1.885619 These two national maps show us the final election results and county-wise voting shits for presidential party. We see that all the battleground states that I predicted for went to Trump. The rest of the states performed how they did in the last presidential election. The shift map shows us an overwhelming shift toward the Republican Party even in supposed Democratic strongholds.\n## ## Attaching package: \u0026#39;cowplot\u0026#39; ## The following object is masked from \u0026#39;package:ggthemes\u0026#39;: ## ## theme_map ## The following object is masked from \u0026#39;package:ggpubr\u0026#39;: ## ## get_legend Take a look here at the county level shifts in presidential voting at the four battleground states that my model wrongly predicted plus my home state of Georgia. Like much of the United States, we see a sea of rightward shifts for the voters\u0026rsquo; choice for president. In Georgia, there is a pretty substantial enclave of leftward shifts in the southern Atlanta suburbs. If you look at this group within the context of the larger nationwide map we presented earlier, you\u0026rsquo;ll see that these Atlanta suburbs are actually one of the few islands of leftward shifts for the entire nation.\nModel Accuracy # ## # A tibble: 7 × 6 ## State `Predicted Harris %` `Actual Harris %` Error `Predicted Winner` ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; ## 1 Arizona 49.8 47.2 -2.67 Republican ## 2 Georgia 49.8 48.9 -0.958 Republican ## 3 Michigan 50.6 49.3 -1.33 Democrat ## 4 Nevada 50.9 48.4 -2.56 Democrat ## 5 North Caroli… 49.8 48.3 -1.47 Republican ## 6 Pennsylvania 50.1 49.0 -1.13 Democrat ## 7 Wisconsin 51.0 49.5 -1.52 Democrat ## # ℹ 1 more variable: `Actual Winner` \u0026lt;chr\u0026gt; Table 3: (\\#tab:unnamed-chunk-9)Postmortem Model Metrics Metric Value Bias -1.662216 Mean-Squared Error (MSE) 3.157383 Root Mean-Squared Error (RMSE) 1.776903 Mean Absolute Error (MAE) 1.662216 Comparing the vote share predictions for each of the battleground states to the actual Democratic 2-Party vote shares, we see that the model consistently overpredicted the Democratic vote share in this election. In four of the battleground states, this had the consequence of predicting a Democratic win, when it was actually the Republican party that wont that state. In some states the error is much smaller than othes; Georgia, for example, has a much lower error than Arizona. I am curious what made the model better at predicting Democratic vote share in my home state versus Arizona or all other battleground states.\nThe model evaluation metric of bias corroborates this story that the model systematically overpredicted Democratic vote share. As for the other model metrics of MSE, RMSE, and MAE, we see that the actual value of error is not negligible In a race that appeared to be so close and in a game like politics, the value of a percentage point and a half matters a lot. Honestly, I do not believe my model to have been very good at predicting the outcomes this election, even if the actual vote shares were included in its 95% confidence interval.\n## Confusion Matrix and Statistics ## ## Prediction ## Actual DEM REP ## DEM 0 0 ## REP 4 3 ## ## Accuracy : 0.4286 ## 95% CI : (0.099, 0.8159) ## No Information Rate : 0.5714 ## P-Value [Acc \u0026gt; NIR] : 0.8734 ## ## Kappa : 0 ## ## Mcnemar\u0026#39;s Test P-Value : 0.1336 ## ## Sensitivity : 0.0000 ## Specificity : 1.0000 ## Pos Pred Value : NaN ## Neg Pred Value : 0.4286 ## Prevalence : 0.5714 ## Detection Rate : 0.0000 ## Detection Prevalence : 0.0000 ## Balanced Accuracy : 0.5000 ## ## \u0026#39;Positive\u0026#39; Class : DEM ## Here, I use a confusion matrix to visualize the possibilities of predictions of battleground state winners and who actually won those states. You can see, according to the summary statistics, that my model accurately predicted the winner of each battleground state about 43% of the time. I am going to be blunt and say that this is pretty bad; in fact, it is worse than just guessing randomly. There were four states that I predicted the Democrats to win when the Republicans won them. I predicted 3 states that the Republicans would win, and they won those. Because the Democrats did not win any states, I could not construct a ROC-AUC curve (Receiver Operating Characteristic, Area Under the Curve), which would help visualize the efficacy of the model at predicting a winner.\nHypotheses For What Went Wrong # I have two main hypotheses for how my model predicted a narrow Harris victory when Trump won the electoral college in a landslide. The first is that polling data, more so than other variables overpredicted Harris\u0026rsquo;s predicted vote share. The second is more technical: that LASSO regression was too strict and penalized economic indicators too heavily, which would have advantaged Trump in my model.\nPolling Variables Overshot Dem Vote Share\nWhat caught my eye when I was analyzing the residuals between the actual Harris vote share and the predicted Harris vote share across the battleground states was the difference among the states. As I mentioned before, Georgia had a much lower residual than Arizona and the other battleground states. This made me question just how much polling was valued in my model. How could it be that polling quality varied that much between swing states? Perhaps Georgia polls were just better. An analysis by ABC\u0026rsquo;s FiveThirtyEight, however, shows that, while Georgia polls are more accurate than a lot of the nation (especially since 2016), they are pretty similar in error to Arizona and Nevada polls. Errors of polls in Michigan and Wisconsin, though, were notably higher than Georgia\u0026rsquo;s ( https://abcnews.go.com/538/states-accurate-polls/story?id=115108709). Given the variability in poll predictability, I believe that my model could have benefited from devaluing them — remember that my LASSO regression put quite a bit of weight onto the latest polling average as a variable.\nI would also like to bring attention to another reason why overreliance on polling might be flawed. In the past three elections, it seems that pollsters have struggled to account for a nebulous Trump effect — where the intentions of Trump voters were hard to pick up with polling efforts. A recent analysis by the Brooking Institution had found that the final averages undercounted Trump support, but they did not necessarily overcount Harris\u0026rsquo;s ( https://www.brookings.edu/articles/the-polls-underestimated-trumps-support-again/). Nonresponse bias that is particularly higher among Trump voters might account for this, but it has been incredibly difficult to quantify — or even prove — that this effect exists.\nLastly, when I look back on the week that I solely focused on polling data, my model had predicted a Harris victory consistently. Knowing what I know now, I would have been a little bit more cautious involving polling data into my model. You can see my blog post dedicated specifically to polling data here: https://sduggasani.github.io/2024election-blog/post/2024-09-23-week-3-polling/.\nLASSO Was Too Strict\nLooking back on my model, I now believe that the LASSO method of regularization was too strict and penalized features that actually did contribute to the broader model. This issue worked in tandem with the overreliance on polling data. Because we had access to so much polling data and there was fewer data on those economic indicators which I deemed \u0026ldquo;relevant\u0026rdquo;, I hypothesize that LASSO exaggerated the contribution of polling data to the model while significantly diminishing the importance of other features. Research by the Pew Research Center has found that, by far, the economy was the single most important issue facing all voters this election cycle ( https://www.pewresearch.org/politics/2024/09/09/issues-and-the-2024-election/). My model did not reflect this, largely due to the feature selection of the LASSO regression I constructed.\nTesting These Hypotheses\nThe most obvious way to test these hypotheses is to change the regularization method from LASSO to a more liberal and forgiving method, such as elastic-net. An elastic net model would minimize multi-collinearity and increase robustness. Though LASSO and Ridge regression are also useful models, the elastic net is versatile and flexibile because it incorporates both of those methods as well. This would ensure that features other than polling are still involved and contribute to the vote share while also not overindexing on polling data. I will soon be making this change and evaluating how it performs against the actual election results.\nAnother test I could do is a cross-validation of polling data specifically. I would split the data into those election years where Trump was running and those election years where he was not. Then, I would use cross-validation and evaluate how polling variables influenced predictions in each subset of election years. I would be curious to see if there are higher polling residuals (also underpredicting Republican performance) in those years that Trump is a candidate versus those years when he was not. This would give some shape to the \u0026ldquo;Trump effect\u0026rdquo; and would bring into question how much weight we put on polling in forecasts with \u0026ldquo;populist\u0026rdquo; candidates like Trump.\nUpdating My Model # State mean_dem sd_dem lower_dem upper_dem mean_rep sd_rep lower_rep upper_rep Arizona 47.51200 1.274702 45.01358 50.01041 52.48800 1.274702 49.98959 54.98642 Georgia 47.57367 1.358221 44.91156 50.23578 52.42633 1.358221 49.76422 55.08844 Michigan 48.23776 1.258296 45.77150 50.70402 51.76224 1.258296 49.29598 54.22850 Nevada 48.60669 1.309284 46.04050 51.17289 51.39331 1.309284 48.82711 53.95950 North Carolina 47.41412 1.272296 44.92042 49.90782 52.58588 1.272296 50.09218 55.07958 Pennsylvania 47.77572 1.271046 45.28447 50.26697 52.22428 1.271046 49.73303 54.71553 Wisconsin 48.67043 1.316305 46.09048 51.25039 51.32957 1.316305 48.74961 53.90952 Here, we see that, using elastic-net regularization, we can get a Trump victory in all battleground states, just like in the election.\nLet\u0026rsquo;s now see how the model fares with similar bias and error metrics as we reflected upon my original model with.\n## New names: ## • `0` -\u0026gt; `0...31` ## • `0` -\u0026gt; `0...32` ## • `0` -\u0026gt; `0...33` ## • `0` -\u0026gt; `0...34` ## • `0` -\u0026gt; `0...35` ## • `0` -\u0026gt; `0...36` ## • `0` -\u0026gt; `0...37` ## • `0` -\u0026gt; `0...38` ## • `0` -\u0026gt; `0...39` ## • `0` -\u0026gt; `0...40` ## • `0` -\u0026gt; `0...41` ## • `0` -\u0026gt; `0...42` ## # A tibble: 7 × 6 ## State `Predicted Harris %` `Actual Harris %` Error `Predicted Winner` ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;chr\u0026gt; ## 1 Arizona 47.5 47.2 -0.359 Republican ## 2 Georgia 47.6 48.9 1.30 Republican ## 3 Michigan 48.2 49.3 1.06 Republican ## 4 Nevada 48.6 48.4 -0.228 Republican ## 5 North Caroli… 47.4 48.3 0.885 Republican ## 6 Pennsylvania 47.8 49.0 1.21 Republican ## 7 Wisconsin 48.7 49.5 0.861 Republican ## # ℹ 1 more variable: `Actual Winner` \u0026lt;chr\u0026gt; Table 5: (\\#tab:unnamed-chunk-12)New Elastic-Net Model Metrics Metric Value Bias 0.6761734 Mean-Squared Error (MSE) 0.8565409 Root Mean-Squared Error (RMSE) 0.9254949 Mean Absolute Error (MAE) 0.8441381 We see here that, across all states, the bias is significantly less than the bias of the LASSO regression model. In fact, across all model evaluation metrics, the size of the error is significantly smaller. Unlike the LASSO model, this new model does not have a singular direction of bias for every state; for some states, it overpredicts for Harris, and for others, it underpredicts. The elastic-net model, however, is able to accurately predict the winner of each battleground state, where the LASSO model could not. What is interesting, though, is that the residual is actually higher in Georgia with the elastic-net model than with the LASSO model. In my final state reflection, I will scrutinize this phenomenon further.\nConclusion # If I were to make one change to improve my model, it would be to abandon the LASSO regression for the elastic-net regression. I believe that I was too strict with my predictors in feature selection for my original model by using LASSO, and making the switch to the more forgiving elastic-net regression, has brought me to have much smaller residuals and mean errors. With elastic-net, I was able to correctly predict all battleground states.\nIn my final contribution to this blog, I will look further the performance of Georgia in this election. I am particularly interested in how the size of residual jumped from LASSO to elastic-net, where it generally decreased for all other states.\nSources # Galston, Williams A. \u0026ldquo;The Polls Underestimated Trump\u0026rsquo;s Support — Again.\u0026rdquo; Brookings, Brookings Institution, 13 Nov. 2024, www.brookings.edu/articles/the-polls-underestimated-trumps-support-again.\nPew Research Center. \u0026ldquo;Issues and the 2024 Election.\u0026rdquo; Pew Research Center: Politics and Policy, 9 Sept. 2024, www.pewresearch.org/politics/2024/09/09/issues-and-the-2024-election.\nRakich, Nathaniel. \u0026ldquo;Which States Have the Most Accurate Polls?\u0026rdquo; FiveThirtyEight, ABC News, 25 Oct. 2024, abcnews.go.com/538/states-accurate-polls/story?id=115108709.\nPolling Data Provided by GOV 1347: Election Analytics teaching staff (which drew from the FiveThirtyEight GitHub)\nEconomic Data Provided by GOV 1347: Election Analytics teaching staff (which drew from the Bureau of Economic Analysis and Federal Reserve Economic Data)\n"},{"id":1,"href":"/2024election-blog/post/2024-11-02-week-9-final-election-prediction/","title":"Week 9: Final Election Prediction","section":"Posts","content":" Week 9: Final Prediction # Monday, November 4, 2024\n1 Day until Presidential Election\nElection Day is tomorrow! I\u0026rsquo;m flying to Atlanta Tuesday morning and immediately heading to my polling station to cast my ballot after having a lot of trouble with the mail-in process. When I began this blog nine weeks ago, I had very little knowledge of the inner-workings of election forecasting and the kind of data that was fed into predictive electoral models. Over the course of the past two months, I have built models using simple linear regression, probabilistic models, and machine learning methods — all of which had varying levels of robustness and reliability. Some had predicted a Harris landslide, others heavily favored Trump. In the past few weeks, though, my selection of a singular model type and efforts toward regularization have converged the forecasts on an incredibly tight race between the two candidates. As any major forecaster will tell you, this election can go either way. The purpose of this blog post is to corroborate this idea and to make one final prediction before we begin to see results unfold tomorrow ( and likely over the course of this week).\nModel Description \u0026amp; Coefficients # ## Warning: Option grouped=FALSE enforced in cv.glmnet, since \u0026lt; 3 observations per ## fold For my final election prediction model, I decided to go with a LASSO regression. Throughout this semester, we have looked at a number of predictors that could have an impact on a presidential candidate\u0026rsquo;s vote share — from economic indicators to polling data to demographics to hurricanes and other shocks. With all these inputs in mind, I thought it most useful to find a method that selects only the most significant or useful features. This is the function of LASSO, which nullifies those predictors that are not as influential on the response variable. A lot of election forecasts run the risk of overfitting because they take in too much information and generate patterns of out of data that does not necessarily reflect reality. I thought it would be better to be conservative with selecting predictors and LASSO regression helped me do that.\nHere, you can see the predictors and data that I decided to include in my LASSO regression model. I converged on these variables throughout the weeks by testing each of their relationships with a response variable of Democratic 2-party vote share. I included only those predictors which a significant impact on vote share: this includes a state\u0026rsquo;s voting behavior in past elections, state polling data, economic indicators, and campaign donation data. After having cross-validated to find the ideal lambda value for my LASSO regression, my model has nullified the Mean Democratic Poll Average variable. So, my final regularized model has corrected for a variable that I included, which might not actually have been that informative despite my previous regressions.\nThe first is the formula representation of my predictive model, where y refers to Democratic 2-Party Vote Share for a given state in a given election year. The second is a mathematical representation of the regularization objective that would occur for these predictors in particular.\nTo interpret the coefficients as they are represented above, we can say that, if a Democratic party were to receive 0% of the vote in the past two elections, the latest polling average for Democrats is 0, the Consumer Price Index is 0, there is no GDP growth for quarter 2 that year, and there are no campaign donations for the candidate, then the Democrat running that year in that state would get about 7.7% of the 2-Party vote share. Holding all other variables constant, as the Democratic vote share in the past election increases by a point so does the Democratic vote share in the upcoming election by .1257 points (and .0079 points with respect to a point increase in Democratic vote share in the second-to-last election). Holding all other variables constant, a point increase in the latest polling average for Democrats coincides with about a .98 point increase in Democratic 2-Party vote share in the upcoming election. Holding all other variables constant, a point increase in GDP Growth in Quarter 2 results in a .06 point increase in Democratic 2-Party vote share in the upcoming election. Finally, holding all other variables constant, a point increase in the log of campaign donations to Democrats results in about a .6 point decrease in the Democratic 2-party vote share in the upcoming election. All these coefficients seem intuitive except for the campaign donation variable. This representation is due to the logarithmic transformation of campaign donation data to scale its coefficient, but in reality, there exists a positive relationship between how much money a Democratic campaign rakes in and its eventual vote share. ( Refer to Week 6\u0026rsquo;s blog for more on this.)\n## Loading required package: Matrix ## ## Attaching package: \u0026#39;Matrix\u0026#39; ## The following objects are masked from \u0026#39;package:tidyr\u0026#39;: ## ## expand, pack, unpack ## Loaded glmnet 4.1-6 Table 1: (\\#tab:unnamed-chunk-5)Coefficients about a 95% Confidence Interval Predictor Lower Upper (Intercept) -37.0735241 50.2256605 D_pv2p_lag1 0.0000000 0.4574302 D_pv2p_lag2 -0.1224704 0.1576207 latest_pollav_DEM 0.4120334 1.5727115 mean_pollav_DEM -0.6909748 0.3996177 CPI -0.1254901 0.1407011 GDP_growth_quarterly -0.0994109 0.2102683 log(contribution_receipt_amount) -1.7544576 0.3380642 After bootstrapping the LASSO regression, we get the above range of coefficient values within a 95% confidence interval. It is peculiar that a lot of these predictors include 0 in their confidence intervals, which is troublesome for how much value we place on their significance. Nevertheless, their contributions to the model are still valuable to some extent. I will note, however, that the latest polling average for Democrat variable seems to be the most significant and that is reflected in its confidence interval (which does not include 0) and its large coefficient compared to other predictors.\nModel Validation # Table 3: (\\#tab:unnamed-chunk-6)Model Validation Metrics Value R Squared 0.8563942 Mean Squared Error 1.5842029 Leave-One-Out Cross-Validation MSE 2.7810769 To evaluate the robustness of my model, I rely on various model validation methods. First, I made sure to employ cross-validation within my LASSO regression, which minimizes the lambda squared error.\nFor in sample evaluation, I rely on R-Squared metrics and Mean Squared Error. For the coefficient of determination (R-Squared), I get about .86 which suggests a strong model. The Mean Squared Error is also relatively smalled compared to other models I have constructed in previous weeks. It is by no means small, though, especially considering that an MSE of this value in certain tight races could mean that a race swings either way.\nFor out of sample evaluation, I also rely on leave-one-out cross-validation. This gives me a higher value than the MSE, which is not the best but can be attributed to the small amount of observations that are used for this model. Realistically, there is not much data to work with for presidential elections, especially where economic indicators, demographics, and campaign donations are concerned. This is a constraint of all election forecasting models, and mine is not immune to it either.\nUncertainty # State mean_dem sd_dem lower_dem upper_dem mean_rep sd_rep lower_rep upper_rep Arizona 49.82247 1.249856 47.37275 52.27219 50.17753 1.249856 47.72781 52.62725 Georgia 49.83683 1.254854 47.37731 52.29634 50.16317 1.254854 47.70366 52.62269 Michigan 50.62857 1.298490 48.08353 53.17361 49.37143 1.298490 46.82639 51.91647 Nevada 50.93553 1.256353 48.47308 53.39799 49.06447 1.256353 46.60201 51.52692 North Carolina 49.77338 1.336243 47.15435 52.39242 50.22662 1.336243 47.60758 52.84565 Pennsylvania 50.11565 1.238461 47.68827 52.54303 49.88435 1.238461 47.45697 52.31173 Wisconsin 51.04669 1.292186 48.51400 53.57938 48.95331 1.292186 46.42062 51.48600 Just like I bootstrapped for my coefficients in the model, I am also bootstrapping for the Democratic 2-Party Vote Share for the battleground states to give more color to the uncertainty around my predictions. For every single swing state, the margin by which the predicted party \u0026ldquo;wins\u0026rdquo; is well within the standard deviation, or margin of error. This suggests that, while I am converging on one party to win for a given swing state, they are all toss-ups and either party can realistically win them. That is, my model is not determinative. Still, I place some trust in the mean_dem and mean_rep vote share predictions for the swing states above for the sake of this endeavor and my work of the past few weeks. The states colored in blue are those where the point prediction for Democrats (with 2-Party vote share) is higher than it is for Republicans. The states colored in red are those where the point prediction for Republicans (with 2-Party vote share) is higher than it is for Democrats. The standard deviations for all swing states is relatively the same.\nElectoral College Visualization # Table 5: Predicted Electoral Votes by State for 2024 State Predicted Electoral Votes Winner Alabama 9 Republican Alaska 3 Republican Arizona 11 Republican Arkansas 6 Republican California 54 Democrat Colorado 10 Democrat Connecticut 7 Democrat Delaware 3 Democrat District Of Columbia 3 Democrat Florida 30 Republican Georgia 16 Republican Hawaii 4 Democrat Idaho 4 Republican Illinois 19 Democrat Indiana 11 Republican Iowa 6 Republican Kansas 6 Republican Kentucky 8 Republican Louisiana 8 Republican Maine 4 Democrat Maryland 10 Democrat Massachusetts 11 Democrat Michigan 15 Democrat Minnesota 10 Democrat Mississippi 6 Republican Missouri 10 Republican Montana 4 Republican Nebraska 5 Republican Nevada 6 Democrat New Hampshire 4 Democrat New Jersey 14 Democrat New Mexico 5 Democrat New York 28 Democrat North Carolina 16 Republican North Dakota 3 Republican Ohio 17 Republican Oklahoma 7 Republican Oregon 8 Democrat Pennsylvania 19 Democrat Rhode Island 4 Democrat South Carolina 9 Republican South Dakota 3 Republican Tennessee 11 Republican Texas 40 Republican Utah 6 Republican Vermont 3 Democrat Virginia 13 Democrat Washington 12 Democrat West Virginia 4 Republican Wisconsin 10 Democrat Wyoming 3 Republican Table 5: Predicted Electoral Votes for 2024 Winner Electoral Votes Democrat 276 Republican 262 Putting my bootstrapped point predictions into play, I have constructed a final electoral college prediction above. Of the swing states, the Republicans are expected to take Georgia (my home state), North Carolina, and Arizona. The Democrats are expected to take Pennsylvania, Wisconsin, Nevada, and Michigan. This puts the Democrats just barely over the 270 needed to win the office. If this prediction were true, it would make the 2024 election one of the closest in recent history, second only to the 2000 election between Bush and Gore.\nConclusion # According to this week\u0026rsquo;s model, Harris will win the 2024 Presidential Election, taking 276 electoral votes.\nMy models for the past few weeks have been wavering between a Harris victory and a Trump victory by incredibly close margins. This is an incredibly close race, and we should not be surprised by the results. Thank you for following along for the past couple of weeks. Thank you to the GOV 1347 teaching staff for their help throughout the semester with content questions and technical difficulties. Thank you in particular to Matthew Dardet for all his guidance and Prof. Ryan Enos for his incredibly insightful lectures. Hopefully soon, we will see how my prediction fares. Until then, take care!\nSources # \u0026ldquo;US Election Results: When Will We Know?\u0026rdquo; Global News, 4 Nov. 2024, https://globalnews.ca/news/10834744/us-election-results-when-will-we-know/.\nPolling Data Provided by GOV 1347: Election Analytics teaching staff (which drew from the FiveThirtyEight GitHub)\nEconomic Data Provided by GOV 1347: Election Analytics teaching staff (which drew from the Bureau of Economic Analysis and Federal Reserve Economic Data)\n"},{"id":2,"href":"/2024election-blog/post/2024-10-27-week-8-shocks/","title":"Week 8: Shocks","section":"Posts","content":" Week 8: Shocks # Monday, October 28, 2024\n7 Days until Presidential Election\nCan you believe there is just a week left until election day? Thank you for following along throughout this entire process! This will be my second-to-last post, and next week I will post my final prediction. This week we\u0026rsquo;ve been learning about October surprises, which refer to unanticipated events that happen in the month before election day that are thought to impact the final results of the race. This week, the Trump campaign held an event at Madison Square Garden where the comedian Tony Hinchcliffe made problematic jokes about Puerto Rico and Latinos, possibly alienating a demographic that has Trump has made headway with this cycle. President Biden made a clumsily-worded response to the event with people construing his words as referring to Trump\u0026rsquo;s supporters as \u0026ldquo; garbage\u0026rdquo;. I also dealt with my own \u0026ldquo;October surprise\u0026rdquo; this week after realizing that my absentee ballot that I applied for two weeks ago likely got lost in the mail and that it was too late to request another to my dorm in Cambridge, MA. After finding a flight back home to Atlanta for $75, I decided it was worth it to cast my ballot in person on election day. Hopefully, everything goes smoothly, and I can participate in the electoral process. Because the impact of shocks are difficult to measure on vote behavior or outcomes, we will use our analysis this week just to update my model and evaluate its results.\nUpdating Model Predictions # This week to update model predictions, I rely on the same inputs as the last few weeks: Democrat 2 Party Vote Shares in the past two elections, latest poll averages for Democrats, mean poll averages for Democrats, Consumer Price Index, quarterly GDP growth, and campaign donations. Realistically, the only thing that has changed between past weeks\u0026rsquo; models and this week\u0026rsquo;s is polling data. The most recent polling data I include has results from up to 8 days before the election day on November 5th.\nModel Predictions without Regularization # Table 1: Battleground State Predicted Results for 2024 Without Regularization state mean_dem sd_dem lower_dem upper_dem mean_rep sd_rep lower_rep upper_rep Arizona 52.95022 0 52.95022 52.95022 47.04978 0 47.04978 47.04978 Georgia 53.15389 0 53.15389 53.15389 46.84611 0 46.84611 46.84611 Michigan 53.80728 0 53.80728 53.80728 46.19272 0 46.19272 46.19272 Nevada 54.02149 0 54.02149 54.02149 45.97851 0 45.97851 45.97851 North Carolina 53.05170 0 53.05170 53.05170 46.94830 0 46.94830 46.94830 Pennsylvania 53.31148 0 53.31148 53.31148 46.68852 0 46.68852 46.68852 Wisconsin 53.98853 0 53.98853 53.98853 46.01147 0 46.01147 46.01147 Using these inputs, I created a simple prediction of Democratic vote share through a linear regression model; I calculated Republican vote share by subtracting Democratic 2-Party vote share from 100%. This resulted in some pretty obviously problematic findings: that Harris will take all battleground states with a clear lead and miniscule standard deviation that doesn\u0026rsquo;t place the results within the margin of error. This deviates from all credible models and is not something I would trust. So, I will not use these findings for my final forecast.\nLASSO Regression Model # Instead of a simple linear regression, I find it more useful to employ a LASSO Regression model, which will use only those variables with large enough coefficients (or effects on Democrat 2-Party Vote Share) and nullify other small variables. I choose this model because I am incredibly cautious of constructing an overfitted and overly complex model to forecast the election results. Realistically, I am focused on three things: relevant economic indicators, campaign donations, and Democratic performance in polls and past elections.\nTable 2: Battleground State Predicted Results for 2024 state electors Democrat Republican winner Arizona 11 49.29145 50.70855 Republican Georgia 16 49.48063 50.51937 Republican Michigan 15 50.18718 49.81282 Democrat Nevada 6 50.02578 49.97422 Democrat North Carolina 16 49.33849 50.66151 Republican Pennsylvania 19 49.86543 50.13457 Republican Wisconsin 10 50.34243 49.65757 Democrat The results of using LASSO regression are a bit more believable, showing some battleground states going to Harris and most to Trump. The split of battleground states also comports well with what other models are predicting and my general intuition. I would be apprehensive about the exact point estimates of Democrat and Republican vote shares, but I think generally the winner for each state makes sense. Now, let\u0026rsquo;s take these results, fit them within the context of the whole nation, and see who is predicted to win the electoral college next week.\nTable 3: Predicted Electoral Votes by State for 2024 State Predicted Electoral Votes Winner Alabama 9 Republican Alaska 3 Republican Arizona 11 Republican Arkansas 6 Republican California 54 Democrat Colorado 10 Democrat Connecticut 7 Democrat Delaware 3 Democrat District Of Columbia 3 Democrat Florida 30 Republican Georgia 16 Republican Hawaii 4 Democrat Idaho 4 Republican Illinois 19 Democrat Indiana 11 Republican Iowa 6 Republican Kansas 6 Republican Kentucky 8 Republican Louisiana 8 Republican Maine 4 Democrat Maryland 10 Democrat Massachusetts 11 Democrat Michigan 15 Democrat Minnesota 10 Democrat Mississippi 6 Republican Missouri 10 Republican Montana 4 Republican Nebraska 5 Republican Nevada 6 Democrat New Hampshire 4 Democrat New Jersey 14 Democrat New Mexico 5 Democrat New York 28 Democrat North Carolina 16 Republican North Dakota 3 Republican Ohio 17 Republican Oklahoma 7 Republican Oregon 8 Democrat Pennsylvania 19 Republican Rhode Island 4 Democrat South Carolina 9 Republican South Dakota 3 Republican Tennessee 11 Republican Texas 40 Republican Utah 6 Republican Vermont 3 Democrat Virginia 13 Democrat Washington 12 Democrat West Virginia 4 Republican Wisconsin 10 Democrat Wyoming 3 Republican Table 3: Predicted Electoral Votes for 2024 Winner Electoral Votes Democrat 257 Republican 281 In previous weeks, I took certain states as \u0026ldquo;red\u0026rdquo; states and others as \u0026ldquo;blue\u0026rdquo; states based on my intuition and without much justification. The purpose of this was to predict only for battleground states because all other states\u0026rsquo; electoral votes were assumed to go to Harris or Trump. I should have defended this assumption, so this week, I am updating my model to use the party winner of the state in 2020 for all states except for the battleground states (instead of just casting certain states as Republican or Democratic givens).\nAfter doing this, I find my model predicts that the Republicans will take the White House in November, having won all the non-battleground states they did in 2020 and taking Arizona, Georgia, North Carolina, and Pennsylvania. This means that, between 2020 and 2024, the Democrats would have lost Arizona, Georgia, and Pennsylvania.\nLooking at the map, we can see that the South once again is predicted to vote as a Republican bloc, the Northeast and West Coast remain Democratic strongholds, and the Rust Belt states split down the middle.\nConclusion # According to this week\u0026rsquo;s model, Trump will win the 2024 Presidential Election, taking 281 electoral votes.\nIn comparison to last week\u0026rsquo;s model, this week presents a more tempered victory for Trump. I made an effort to regularize my model this week through LASSO this week because I want to be as conservative as possible about introducing new variables into my model, and I think that is mainly why this week\u0026rsquo;s model presents a much much tighter margin. Still, this favors Trump compared to the last time I used LASSO regression because of most recent polling data. In my final prediction, I will continue to rely on this structure and regularize my model with LASSO. It is important to note that the margin of error straddles the win threshold, so these predictions can really go either way to Trump or Harris. Realistically, no one should be surprised by the winner of the election because this race is so close.\nSources # \u0026ldquo;\u0026lsquo;Supporters\u0026rdquo; or \u0026ldquo;supporter\u0026rsquo;s\u0026rsquo;? Biden comments about Trump \u0026lsquo;garbage\u0026rsquo; rally anger the GOP\u0026rdquo; CBS News, 2024. https://www.cbsnews.com/news/bidens-response-to-garbage-joke-about-puerto-rico/.\nPolling Data Provided by GOV 1347: Election Analytics teaching staff (which drew from the FiveThirtyEight GitHub)\nEconomic Data Provided by GOV 1347: Election Analytics teaching staff (which drew from the Bureau of Economic Analysis and Federal Reserve Economic Data)\n"},{"id":3,"href":"/2024election-blog/post/2024-10-21-week-7-ground-game/","title":"Week 7: Ground Game","section":"Posts","content":" Week 7: Ground Game # Monday, October 21, 2024\n14 Days until Presidential Election\nTwo more weeks until election day! Right now, both candidates are engaging in last-ditch efforts to attract undecided voters. Trump and Harris are jumping between battleground states (and other key electorates) holding media appearances, rallies, fund-raisers, and other campaign events. The New York Times reports that Harris has campaigned at 39 events since September 1st while Trump has campaigned at 59. Whether this discrepancy will have an effect on vote share will be the focus of this week\u0026rsquo;s post.\nBinomial Logit Simulations and Probabilistic Models # ## Joining with `by = join_by(year, state)` ## [1] 7803102 ## [1] 42.59986 ## [1] 46.66471 ## [1] 3.710212 ## [1] 6.070667 ## [1] 0.2486347 ## [1] 0.272381 Up until this point, I have generally been using linear regression models to predict party vote shares and turnout. As we have seen through the weeks, there are a couple problems that consistently appear. Total vote shares can add up to over 100%, but binomial logit regressions ensure that outcomes stick within a certain 0-1 threshold. What\u0026rsquo;s more, binomial logit regressions are strong in showing the odds of one outcome over another, which is most helpful in determining who is most likely to win an election.\nThe above charts demonstrate the relationship between hypothetical poll support for each party in each state with the probability of state-eligible voter voting for party. We can compare North Carolina and Georgia and see that there exist two different non-linear relationships across the states. In Georgia, as poll support for both Democrats and Republicans increase, the probability of state-eligible voter voting for the respective party increases relatively gradually. In North Carolina, as poll support for Democrats increase, the probability of state-eligible voter voting for Democrats increases dramatically (the relationship for Republicans appears more gradual and linear).\nIn Georgia, my home state, the voting eligible population increases linearly with each year.\nThe distribution of predicted draws on the win margin for Trump in Georgia shows a firm lead with a range of around 4 points in his favor.\nWe have simulated fluctuations in the probability of a voter from the voting eligible population voting for a party by using a prior at the standard deviation of its polls. This distribution demonstrates an incredibly close race between Harris and Trump but a skew toward Trump, suggesting a Trump victory.\nField Offices and Campaign Events # Table 1: Obama Romney Field Offices Model 1 Model 2 (Intercept) −0.340 0.001 (0.196) (0.079) romney12fo 2.546 (0.114) swingTRUE 0.0006 −0.012 (0.055) (0.011) core_repTRUE 0.007 (0.061) battleTRUE 0.541 0.014 (0.096) (0.042) medage08 −0.0003 −0.0009 (0.003) (0.001) pop2008 0.0000007 −7e−08 (4e−08) (2e−08) medinc08 −0.000002 0.000001 (0.000001) (0.0000006) black 0.003 0.00005 (0.001) (0.0005) hispanic 0.0002 0.0008 (0.001) (0.0006) pc_less_hs00 0.506 −0.130 (0.259) (0.112) pc_degree00 0.951 0.305 (0.223) (0.097) as.factor(state)Arizona −0.028 −0.050 (0.156) (0.067) as.factor(state)Arkansas 0.076 0.001 (0.090) (0.039) as.factor(state)California −0.076 −0.099 (0.104) (0.045) as.factor(state)Colorado 0.163 −0.173 (0.094) (0.041) as.factor(state)Connecticut 0.036 −0.145 (0.200) (0.086) as.factor(state)Delaware 0.207 −0.135 (0.309) (0.134) as.factor(state)Florida −0.290 0.244 (0.091) (0.039) as.factor(state)Georgia 0.029 −0.018 (0.077) (0.033) as.factor(state)Hawaii 0.179 −0.126 (0.272) (0.117) as.factor(state)Idaho 0.154 −0.054 (0.109) (0.047) as.factor(state)Illinois 0.117 −0.033 (0.088) (0.038) as.factor(state)Indiana 0.140 −0.032 (0.090) (0.039) as.factor(state)Iowa 0.081 −0.115 (0.081) (0.035) as.factor(state)Kansas 0.147 −0.046 (0.091) (0.039) as.factor(state)Kentucky 0.105 0.008 (0.084) (0.036) as.factor(state)Louisiana −0.004 −0.0009 (0.092) (0.040) as.factor(state)Maine 0.274 −0.088 (0.150) (0.065) as.factor(state)Maryland −0.047 −0.074 (0.128) (0.055) as.factor(state)Massachusetts −0.118 −0.110 (0.163) (0.070) as.factor(state)Michigan −0.083 0.175 (0.093) (0.040) as.factor(state)Minnesota 0.271 −0.073 (0.092) (0.040) as.factor(state)Mississippi −0.034 0.0002 (0.087) (0.038) as.factor(state)Missouri 0.040 0.059 (0.085) (0.037) as.factor(state)Montana 0.167 −0.050 (0.103) (0.045) as.factor(state)Nebraska 0.167 −0.031 (0.095) (0.041) as.factor(state)Nevada −0.054 0.208 (0.143) (0.062) as.factor(state)New Hampshire 0.091 0.178 (0.178) (0.077) as.factor(state)New Jersey −0.166 −0.087 (0.137) (0.059) as.factor(state)New Mexico 0.093 0.080 (0.128) (0.055) as.factor(state)New York −0.019 −0.056 (0.097) (0.042) as.factor(state)North Carolina 0.230 0.054 (0.084) (0.036) as.factor(state)North Dakota 0.163 −0.032 (0.102) (0.044) as.factor(state)Ohio 0.305 −0.031 (0.084) (0.036) as.factor(state)Oklahoma 0.113 −0.022 (0.092) (0.040) as.factor(state)Oregon 0.270 −0.093 (0.115) (0.050) as.factor(state)Pennsylvania −0.351 0.111 (0.089) (0.039) as.factor(state)Rhode Island 0.117 −0.123 (0.246) (0.106) as.factor(state)South Carolina −0.003 −0.027 (0.101) (0.044) as.factor(state)South Dakota 0.156 −0.033 (0.097) (0.042) as.factor(state)Tennessee 0.081 0.005 (0.087) (0.038) as.factor(state)Texas 0.044 −0.037 (0.082) (0.035) as.factor(state)Utah 0.036 0.060 (0.124) (0.054) as.factor(state)Vermont 0.146 −0.080 (0.158) (0.068) as.factor(state)Virginia −0.396 0.027 (0.083) (0.036) as.factor(state)Washington 0.280 −0.122 (0.112) (0.048) as.factor(state)West Virginia 0.142 0.003 (0.099) (0.043) as.factor(state)Wyoming 0.160 −0.064 (0.135) (0.058) romney12fo × swingTRUE −0.765 (0.116) romney12fo × core_repTRUE −1.875 (0.131) obama12fo 0.374 (0.020) core_demTRUE 0.004 (0.027) obama12fo × swingTRUE −0.081 (0.020) obama12fo × core_demTRUE −0.164 (0.023) Num.Obs. 3110 3110 R2 0.712 0.651 R2 Adj. 0.706 0.644 AIC 4851.7 −366.8 BIC 5226.3 7.9 Log.Lik. −2363.855 245.384 RMSE 0.52 0.22 Table 1: Effects of Field Offices on Turnout and Vote Share Model 1 Model 2 (Intercept) 0.029 0.022 (0.002) (0.003) dummy_fo_change 0.004 0.009 (0.001) (0.002) battleTRUE 0.024 0.043 (0.002) (0.003) as.factor(state)Arizona −0.012 0.0004 (0.005) (0.007) as.factor(state)Arkansas −0.026 −0.055 (0.003) (0.004) as.factor(state)California −0.021 0.020 (0.003) (0.005) as.factor(state)Colorado −0.024 −0.035 (0.003) (0.005) as.factor(state)Connecticut −0.022 0.008 (0.006) (0.010) as.factor(state)Delaware −0.001 0.033 (0.010) (0.015) as.factor(state)District of Columbia 0.035 −0.002 (0.017) (0.026) as.factor(state)Florida −0.035 −0.048 (0.003) (0.005) as.factor(state)Georgia −0.001 0.002 (0.002) (0.004) as.factor(state)Hawaii −0.021 0.069 (0.009) (0.013) as.factor(state)Idaho −0.023 0.005 (0.003) (0.005) as.factor(state)Illinois −0.029 −0.004 (0.003) (0.004) as.factor(state)Indiana −0.030 −0.010 (0.003) (0.004) as.factor(state)Iowa −0.038 −0.039 (0.003) (0.005) as.factor(state)Kansas −0.035 −0.009 (0.003) (0.004) as.factor(state)Kentucky −0.029 −0.029 (0.003) (0.004) as.factor(state)Louisiana −0.006 −0.014 (0.003) (0.004) as.factor(state)Maine −0.030 0.007 (0.005) (0.007) as.factor(state)Maryland 0.005 0.020 (0.004) (0.006) as.factor(state)Massachusetts −0.005 −0.007 (0.005) (0.007) as.factor(state)Michigan −0.035 −0.019 (0.003) (0.004) as.factor(state)Minnesota −0.021 0.0008 (0.003) (0.004) as.factor(state)Mississippi 0.002 0.017 (0.003) (0.004) as.factor(state)Missouri −0.037 −0.045 (0.003) (0.004) as.factor(state)Montana −0.015 −0.019 (0.003) (0.005) as.factor(state)Nebraska −0.020 0.008 (0.003) (0.004) as.factor(state)Nevada −0.039 −0.039 (0.005) (0.007) as.factor(state)New Hampshire −0.038 −0.032 (0.006) (0.009) as.factor(state)New Jersey −0.018 0.023 (0.004) (0.006) as.factor(state)New Mexico −0.032 −0.008 (0.004) (0.006) as.factor(state)New York −0.035 0.019 (0.003) (0.004) as.factor(state)North Carolina 0.004 −0.014 (0.003) (0.004) as.factor(state)North Dakota −0.009 0.002 (0.003) (0.005) as.factor(state)Ohio −0.049 −0.041 (0.003) (0.005) as.factor(state)Oklahoma −0.046 −0.026 (0.003) (0.004) as.factor(state)Oregon −0.033 0.006 (0.003) (0.005) as.factor(state)Pennsylvania −0.050 −0.047 (0.003) (0.005) as.factor(state)Rhode Island −0.009 0.007 (0.008) (0.012) as.factor(state)South Carolina 0.014 0.013 (0.003) (0.005) as.factor(state)South Dakota −0.044 −0.002 (0.003) (0.004) as.factor(state)Tennessee −0.033 −0.048 (0.003) (0.004) as.factor(state)Texas −0.025 −0.009 (0.002) (0.003) as.factor(state)Utah −0.018 −0.015 (0.004) (0.006) as.factor(state)Vermont −0.025 0.035 (0.005) (0.007) as.factor(state)Virginia −0.014 −0.033 (0.003) (0.005) as.factor(state)Washington −0.009 0.009 (0.003) (0.005) as.factor(state)West Virginia −0.043 −0.044 (0.003) (0.005) as.factor(state)Wisconsin −0.046 −0.037 (0.003) (0.005) as.factor(state)Wyoming −0.021 −0.011 (0.004) (0.006) as.factor(year)2012 −0.021 −0.045 (0.0007) (0.001) dummy_fo_change × battleTRUE −0.002 0.007 (0.002) (0.003) Num.Obs. 6224 6224 R2 0.424 0.473 R2 Adj. 0.419 0.469 AIC −28783.2 −23658.9 BIC −28412.7 −23288.4 Log.Lik. 14446.586 11884.440 RMSE 0.02 0.04 Trump Field Offices Clinton Field Offices Romney Field Offices Obama Field Offices 165 538 283 791 For now, we return to linear regressions to the evaluate the relationship between states and demographics and the presence of field offices for the Obama (Model 1) and Romney (Model 2) campaigns in 2012. The Obama model shows that, on average, for every field office that Romney had, Obama had about 2.5. The Obama and Romney campaigns also were more likely to have field offices in counties with higher educational degree attainment. The Obama campaign was more likely to have field offices in counties with higher percentages of less-than-high-school levels of educational attainment than the Romney campaign. We could analyze the relationships between these campaigns and the demographics of the counties they exist in endlessly, but these models are useful in giving color to the idea that the decision of setting up a field office in a certain district is intentional.\nIn another set of models, we can evaluate the effects of the presence of field offices on turnout (Model 1) and Democratic vote share (Model 2). On average, Democratic vote share and turnout were marginalyl higher in the counties of battleground states with field offices. We can also see the discrepancy in the sheer number of field offices between 2012 and 2016 campaigns; the Democratic candidates, Clinton and Obama, had far more field offices than their Republican opponents\n## `summarise()` has grouped output by \u0026#39;year\u0026#39;, \u0026#39;state\u0026#39;. You can override using the ## `.groups` argument. Table 2: Can the number of campaign events predict state-level vote share? Model 1 Model 2 (Intercept) 48.189 51.810 (0.369) (0.369) n_ev_D 0.126 (0.034) ev_diff_D_R 0.105 (0.067) n_ev_R −0.126 (0.034) ev_diff_R_D 0.230 (0.078) Num.Obs. 714 714 R2 0.021 0.021 R2 Adj. 0.019 0.019 AIC 4910.1 4910.2 BIC 4928.4 4928.5 Log.Lik. −2451.039 −2451.089 F 7.778 7.776 RMSE 7.49 7.49 The above maps visualize the locations of various campaign events held for Democrats and Republicans across the current and past two elections. Across all three maps, we see a concentration of events in the Northeast region of the country. We also see how from 2016 to 2024, the number of events greatly diminishes in Florida; this could likely be to the fact that it is now considered much less of a swing state than it used to be. There are fewer events on the whole in 2020 because of the pandemic. By 2024, the campaign events occur either entirely in battleground states or major fundraising centers for each party (e.g. New York and California for the Democrats).\nTake a look at the summary statistics of the model that we created to predict vote share based on the number of campaign events, and you will find pretty large coefficients for the Democrats when they have more events over Republicans (Model 1) and for the Repbulicans when they are the ones that possess the positive margin. This predictive power is quickly humbled by an abysmal R-Squared value. I decide to leave the number of campaign events out of my forecasting model for this reason.\n## `summarise()` has grouped output by \u0026#39;state\u0026#39;, \u0026#39;party\u0026#39;. You can override using ## the `.groups` argument. Here, I visualize the lead that a party has over the other in terms of the number of campaign events held in key battleground states. I look at the current campaign and the past two presidential campaign years. In 2016 and 2020, the Republicans generally held more events in battleground states than the Democrats; in fact, in 2016, they held out over Democrats in all battlegrounds states. By 2024, though, Democrats are holding more events in these states. At the same time, I am still not involving campaign event lead in my predictive model, and I do not believe that Democrats having more events in these states is determinative or even indicative of a win for them.\nUpdating Model Predictions # state electors winner Alabama 9 Republican Alaska 3 Republican Arizona 11 Republican Arkansas 6 Republican California 54 Democrat Colorado 10 Democrat Connecticut 7 Democrat Delaware 3 Democrat District Of Columbia 3 Democrat Florida 30 Republican Georgia 16 Republican Hawaii 4 Democrat Idaho 4 Republican Illinois 19 Democrat Indiana 11 Republican Iowa 6 Republican Kansas 6 Republican Kentucky 8 Republican Louisiana 8 Republican Maine 4 Democrat Maryland 10 Democrat Massachusetts 11 Democrat Michigan 15 Republican Minnesota 10 Democrat Mississippi 6 Republican Missouri 10 Republican Montana 4 Republican Nebraska 5 Republican Nevada 6 Republican New Hampshire 4 Democrat New Jersey 14 Democrat New Mexico 5 Democrat New York 28 Democrat North Carolina 16 Republican North Dakota 3 Republican Ohio 17 Republican Oklahoma 7 Republican Oregon 8 Democrat Pennsylvania 19 Republican Rhode Island 4 Democrat South Carolina 9 Republican South Dakota 3 Republican Tennessee 11 Republican Texas 40 Republican Utah 6 Republican Vermont 3 Republican Virginia 13 Democrat Washington 12 Democrat West Virginia 4 Republican Wisconsin 10 Republican Wyoming 3 Republican winner electoral_votes Democrat 223 Republican 315 This week\u0026rsquo;s model is virtually the same as last week\u0026rsquo;s save for the fact that I rely on elastic-net regression instead of LASSO regression. I fear that LASSO regression is too penalizing, and I think it is wise to take the best of the ridge and LASSO models for something so unclear like election forecasting. With updated polling and economic data and this new regularization method, Trump is predicted to win the election by grabbing the electoral votes of all seven of the battleground states.\nConclusion # According to this week\u0026rsquo;s models, Trump will win the 2024 Presidential Election, taking 315 electoral votes.\nIn comparison to last week\u0026rsquo;s model, this week presents a landslide victory for Trump. I made an effort to regularize my model this week through a more generous method this week, and I think that is mainly why this week\u0026rsquo;s model presents a much much larger margin. I will continue to regularize my models going forward. A lead in the number of campaign events a certain party holds over another does not seem to really affect vote share or relevant variables that could really tip the election in any direction. In my last week of forecasting, I hope to create one final and robust model (taking the best methods from each week) and tee up the ball for my final prediction. I look forward to seeing you next week!\nSources # The New York Times. \u0026ldquo;Where Are Trump and Harris Campaigning?\u0026rdquo; The New York Times, updated 18 Oct. 2024, https://www.nytimes.com/interactive/2024/10/16/us/politics/harris-trump-2024-campaign.html.\nPolling Data Provided by GOV 1347: Election Analytics teaching staff (which itself drew from the FiveThirtyEight GitHub)\nEconomic Data Provided by GOV 1347: Election Analytics teaching staff (which itself drew from the Burueau of Economic Analysia and Federal Reserve Economic Data)\n"},{"id":4,"href":"/2024election-blog/post/2024-10-12-week-6-campaign-spending/","title":"Week 6: Campaign Expenditure","section":"Posts","content":" Week 6: Campaign Expenditure # Monday, October 14, 2024\n21 Days until Presidential Election\nWe are now less than a month away from election day! It means a lot that you\u0026rsquo;ve followed along this far. Thank you! This week, we will be considering how campaign advertisement expenditure can play a role in election outcomes. In the 2020 Presidential Elections, I remember one day receiving over 20 campaign flyers and virtually the only ads aired on television being political. I thought that, if forecasters could take a metric of campaign mail count in my suburban Atlanta district, they\u0026rsquo;d probably have a more accurate model. I cannot monitor the ads in Georgia as closely as I did in the last election because I\u0026rsquo;m in college now, but I hope to at least involve available data on campaign ad expenditure into my model.\nCampaign Ads and Messaging # Above, we see a chart presenting the tone of campaign ads by party and by election cycle. We see that across cycles, Democrats tend to not make the majority of their ads with an attacking tone, but in 2004 and 2012, Republicans did just that. Overall, there is no clear trend as to the tone of campaign ads over time, and I would argue that it depends heavily on the candidates running and their style of campaigning.\nWe also see a visualization of of the purpose of campaign ads by party and by presidential election year. Most of the time, we see that policy ads are the most common across parties and across cycles, except for ads by Democrats in 2016. Across most election cycles, it seems that Democrats field more personal ads than Republicans, and this difference can be marginal or staggering like it was in 2016.\nHere, we can take a look at the issues most frequently mentioned in campaign ads across elections from 2000-2012. In addition to there being more ads in general as time goes on, we see a notable changed in the issues that are mentioned in ads between cycles. The one issue that stays across all cycles is taxes and jobs/employment seems pretty sticky as well.\nGoing into the party split for campaign ads for 2000 and 2012, we see notable differences in the topics for which parties choose to air ads. One thing I find interesting is that, in 2000, Democrats did not touch homosexuality as a topic for campaign ads, and Republicans wre the only ones to air ads on the issue, presumably against it. By 2012, more Democratic ads on homosexuality appeared and the name of the issue changed to a split between Moral/Family/Religious values (for which there were more Republican ads) and Homosexuality/Gay \u0026amp; Lesbian Rights.\nThose issues which both parties pretty evenly air ads on are also very similar to the issues observed in the first plot, which shows the most frequently mentioned issues in campaign ads regardless of party and across election cycles. Taxes, healthcare, and deficit are among them.\nCampaign Expenditure Model # Model 1 Model 2 (Intercept) 46.808 −23.093 (0.771) (7.160) contribution_receipt_amount 0.0000002 (3e−08) log(contribution_receipt_amount) 4.659 (0.460) Num.Obs. 200 200 R2 0.168 0.341 R2 Adj. 0.163 0.338 AIC 1476.7 1430.1 BIC 1486.6 1439.9 Log.Lik. −735.367 −712.027 F 39.886 102.423 RMSE 9.56 8.51 The model summary we see here is a linear regression for Democratic campaign spending and the Democratic two-party vote share. Model 1 refers to treating campaign expenditure as an unmodified variable while Model 2 applies a log transformation to better understand the relationship between the two variables. We see that, in the context of this linear regression, campaign expenditure for Democrats has a positive impact on their two party vote share. This motivates my inclusion of campaign expenditure data into the model I use to predict the outcome of the 2024 elections.\nBayesianism # ## ## SAMPLING FOR MODEL \u0026#39;anon_model\u0026#39; NOW (CHAIN 1). ## Chain 1: ## Chain 1: Gradient evaluation took 8e-05 seconds ## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.8 seconds. ## Chain 1: Adjust your expectations accordingly! ## Chain 1: ## Chain 1: ## Chain 1: Iteration: 1 / 4000 [ 0%] (Warmup) ## Chain 1: Iteration: 400 / 4000 [ 10%] (Warmup) ## Chain 1: Iteration: 800 / 4000 [ 20%] (Warmup) ## Chain 1: Iteration: 1001 / 4000 [ 25%] (Sampling) ## Chain 1: Iteration: 1400 / 4000 [ 35%] (Sampling) ## Chain 1: Iteration: 1800 / 4000 [ 45%] (Sampling) ## Chain 1: Iteration: 2200 / 4000 [ 55%] (Sampling) ## Chain 1: Iteration: 2600 / 4000 [ 65%] (Sampling) ## Chain 1: Iteration: 3000 / 4000 [ 75%] (Sampling) ## Chain 1: Iteration: 3400 / 4000 [ 85%] (Sampling) ## Chain 1: Iteration: 3800 / 4000 [ 95%] (Sampling) ## Chain 1: Iteration: 4000 / 4000 [100%] (Sampling) ## Chain 1: ## Chain 1: Elapsed Time: 1.383 seconds (Warm-up) ## Chain 1: 4.861 seconds (Sampling) ## Chain 1: 6.244 seconds (Total) ## Chain 1: ## ## SAMPLING FOR MODEL \u0026#39;anon_model\u0026#39; NOW (CHAIN 2). ## Chain 2: ## Chain 2: Gradient evaluation took 1.7e-05 seconds ## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds. ## Chain 2: Adjust your expectations accordingly! ## Chain 2: ## Chain 2: ## Chain 2: Iteration: 1 / 4000 [ 0%] (Warmup) ## Chain 2: Iteration: 400 / 4000 [ 10%] (Warmup) ## Chain 2: Iteration: 800 / 4000 [ 20%] (Warmup) ## Chain 2: Iteration: 1001 / 4000 [ 25%] (Sampling) ## Chain 2: Iteration: 1400 / 4000 [ 35%] (Sampling) ## Chain 2: Iteration: 1800 / 4000 [ 45%] (Sampling) ## Chain 2: Iteration: 2200 / 4000 [ 55%] (Sampling) ## Chain 2: Iteration: 2600 / 4000 [ 65%] (Sampling) ## Chain 2: Iteration: 3000 / 4000 [ 75%] (Sampling) ## Chain 2: Iteration: 3400 / 4000 [ 85%] (Sampling) ## Chain 2: Iteration: 3800 / 4000 [ 95%] (Sampling) ## Chain 2: Iteration: 4000 / 4000 [100%] (Sampling) ## Chain 2: ## Chain 2: Elapsed Time: 1.531 seconds (Warm-up) ## Chain 2: 4.538 seconds (Sampling) ## Chain 2: 6.069 seconds (Total) ## Chain 2: ## ## SAMPLING FOR MODEL \u0026#39;anon_model\u0026#39; NOW (CHAIN 3). ## Chain 3: ## Chain 3: Gradient evaluation took 1.7e-05 seconds ## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds. ## Chain 3: Adjust your expectations accordingly! ## Chain 3: ## Chain 3: ## Chain 3: Iteration: 1 / 4000 [ 0%] (Warmup) ## Chain 3: Iteration: 400 / 4000 [ 10%] (Warmup) ## Chain 3: Iteration: 800 / 4000 [ 20%] (Warmup) ## Chain 3: Iteration: 1001 / 4000 [ 25%] (Sampling) ## Chain 3: Iteration: 1400 / 4000 [ 35%] (Sampling) ## Chain 3: Iteration: 1800 / 4000 [ 45%] (Sampling) ## Chain 3: Iteration: 2200 / 4000 [ 55%] (Sampling) ## Chain 3: Iteration: 2600 / 4000 [ 65%] (Sampling) ## Chain 3: Iteration: 3000 / 4000 [ 75%] (Sampling) ## Chain 3: Iteration: 3400 / 4000 [ 85%] (Sampling) ## Chain 3: Iteration: 3800 / 4000 [ 95%] (Sampling) ## Chain 3: Iteration: 4000 / 4000 [100%] (Sampling) ## Chain 3: ## Chain 3: Elapsed Time: 1.626 seconds (Warm-up) ## Chain 3: 4.964 seconds (Sampling) ## Chain 3: 6.59 seconds (Total) ## Chain 3: ## ## SAMPLING FOR MODEL \u0026#39;anon_model\u0026#39; NOW (CHAIN 4). ## Chain 4: ## Chain 4: Gradient evaluation took 1.6e-05 seconds ## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds. ## Chain 4: Adjust your expectations accordingly! ## Chain 4: ## Chain 4: ## Chain 4: Iteration: 1 / 4000 [ 0%] (Warmup) ## Chain 4: Iteration: 400 / 4000 [ 10%] (Warmup) ## Chain 4: Iteration: 800 / 4000 [ 20%] (Warmup) ## Chain 4: Iteration: 1001 / 4000 [ 25%] (Sampling) ## Chain 4: Iteration: 1400 / 4000 [ 35%] (Sampling) ## Chain 4: Iteration: 1800 / 4000 [ 45%] (Sampling) ## Chain 4: Iteration: 2200 / 4000 [ 55%] (Sampling) ## Chain 4: Iteration: 2600 / 4000 [ 65%] (Sampling) ## Chain 4: Iteration: 3000 / 4000 [ 75%] (Sampling) ## Chain 4: Iteration: 3400 / 4000 [ 85%] (Sampling) ## Chain 4: Iteration: 3800 / 4000 [ 95%] (Sampling) ## Chain 4: Iteration: 4000 / 4000 [100%] (Sampling) ## Chain 4: ## Chain 4: Elapsed Time: 1.631 seconds (Warm-up) ## Chain 4: 5.004 seconds (Sampling) ## Chain 4: 6.635 seconds (Total) ## Chain 4: ## ## Call: ## lm(formula = D_pv2p ~ latest_pollav_DEM + mean_pollav_DEM + D_pv2p_lag1 + ## D_pv2p_lag2, data = d.train) ## ## Residuals: ## Min 1Q Median 3Q Max ## -10.4485 -2.0088 -0.4128 1.7700 9.8659 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 9.03700 1.84335 4.902 1.97e-06 *** ## latest_pollav_DEM 0.88022 0.08197 10.739 \u0026lt; 2e-16 *** ## mean_pollav_DEM -0.27845 0.07428 -3.749 0.000233 *** ## D_pv2p_lag1 0.44393 0.04578 9.698 \u0026lt; 2e-16 *** ## D_pv2p_lag2 -0.17487 0.03974 -4.400 1.77e-05 *** ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Residual standard error: 3.383 on 197 degrees of freedom ## Multiple R-squared: 0.7767,\tAdjusted R-squared: 0.7722 ## F-statistic: 171.3 on 4 and 197 DF, p-value: \u0026lt; 2.2e-16 ## Inference for Stan model: anon_model. ## 4 chains, each with iter=4000; warmup=1000; thin=1; ## post-warmup draws per chain=3000, total post-warmup draws=12000. ## ## mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat ## alpha 9.01 0.02 1.86 5.37 7.76 8.99 10.25 12.77 8444 1 ## beta1 0.88 0.00 0.08 0.71 0.82 0.88 0.94 1.04 6523 1 ## beta2 -0.28 0.00 0.08 -0.43 -0.33 -0.28 -0.23 -0.13 6751 1 ## beta3 0.44 0.00 0.05 0.35 0.41 0.44 0.48 0.53 8052 1 ## beta4 -0.17 0.00 0.04 -0.25 -0.20 -0.17 -0.15 -0.09 8514 1 ## sigma 3.40 0.00 0.17 3.09 3.28 3.39 3.51 3.75 9209 1 ## ## Samples were drawn using NUTS(diag_e) at Mon Nov 18 21:06:21 2024. ## For each parameter, n_eff is a crude measure of effective sample size, ## and Rhat is the potential scale reduction factor on split chains (at ## convergence, Rhat=1). Using code provided by Matthew Dardet, I experiment with the use of a Bayesian model as opposed to the frequentist models I have been constructing thus far. In essence, a Bayesian model is one that adjusts its predictions with the addition of new information; in this case, the information we take in is new polling data. If you compare the summary statistics between the frequentist (linear regression) model and the Bayesian model, you cannot find much of a difference between the coefficients (to compare coefficients, go row by row where alpha is the intercept, beta1 is latest_pollav_DEM, etc.). FiveThirtyEight uses Bayesian updating to adjust for changes in the lean of certain polls (see: https://fivethirtyeight.com/methodology/how-our-polling-averages-work/). One objection to the use of Bayesian inference is that the reliance on the idea of prior and posterior knowledge obfuscates what we know to be objective and thus makes the analysis drawn from Bayesian models dubious (counterarguments presented and refuted in Andrew Gelman\u0026rsquo;s http://www.stat.columbia.edu/~gelman/research/published/badbayesmain.pdf). In light of this, I will use a frequentist model for the rest of this week but continue to play around with Bayesianism.\nUpdating Model Predictions # ## `summarise()` has grouped output by \u0026#39;state\u0026#39;. You can override using the ## `.groups` argument. ## Warning: Option grouped=FALSE enforced in cv.glmnet, since \u0026lt; 3 observations per ## fold state electors winner Alabama 9 Republican Alaska 3 Republican Arizona 11 Republican Arkansas 6 Republican California 54 Democrat Colorado 10 Democrat Connecticut 7 Democrat Delaware 3 Democrat District Of Columbia 3 Democrat Florida 30 Republican Georgia 16 Republican Hawaii 4 Democrat Idaho 4 Republican Illinois 19 Democrat Indiana 11 Republican Iowa 6 Republican Kansas 6 Republican Kentucky 8 Republican Louisiana 8 Republican Maine 4 Democrat Maryland 10 Democrat Massachusetts 11 Democrat Michigan 15 Democrat Minnesota 10 Democrat Mississippi 6 Republican Missouri 10 Republican Montana 4 Republican Nebraska 5 Republican Nevada 6 Democrat New Hampshire 4 Democrat New Jersey 14 Democrat New Mexico 5 Democrat New York 28 Democrat North Carolina 16 Republican North Dakota 3 Republican Ohio 17 Republican Oklahoma 7 Republican Oregon 8 Democrat Pennsylvania 19 Democrat Rhode Island 4 Democrat South Carolina 9 Republican South Dakota 3 Republican Tennessee 11 Republican Texas 40 Republican Utah 6 Republican Vermont 3 Republican Virginia 13 Democrat Washington 12 Democrat West Virginia 4 Republican Wisconsin 10 Democrat Wyoming 3 Republican winner electoral_votes Democrat 273 Republican 265 To update this week\u0026rsquo;s model, I involved campaign expenditure data alongside economic fundamentals and polling data. Campaign expenditure data is taken for Democrats only because the model predicts for Democrats and calculates Republican by subtracting Democratic vote share from 100. The last model individually predicted each party\u0026rsquo;s vote share, which made it difficult to really see who was ahead.\nI, then, regularize the model, using LASSO which is a machine learning model that selects relevant features and neutralizes features that are not. This was helpful to making election results appear more realistic. The final results of this model show an incredibly close race with Harris winning over Trump by just 8 electoral votes. The model forecasts that Trump will take Arizona, Georgia, and North Carolina while Harris takes Pennsylvania, Nevada, and Michigan. This presents a pretty even split among swing states between the two candidates.\nConclusion # According to this week\u0026rsquo;s models, Harris will win the 2024 Presidential Election, taking 273 electoral votes.\nIn comparison to last week\u0026rsquo;s model, this week presents a much closer race between Harris and Trump, which I believe will be the case. I made an effort to regularize my model this week, which I did not last week, and I think that is mainly why this week\u0026rsquo;s model presents a much much tighter margin. I will continue to regualarize my models going forward as a result. The involvement of campaign expenditure seems to advantage Democrats in this race, which would make sense considering Harris has raked in $1 billion since entering the race (Goldmacher \u0026amp; Haberman).\nSources # Goldmacher, Shane and Maggie Haberman. \u0026ldquo;Harris Raises $1 Billion, Cementing Status as Fundraising Powerhouse.\u0026rdquo; The New York Times, 9 Oct. 2024, www.nytimes.com/2024/10/09/us/politics/harris-billion-dollar-fundraising.html.\nGelman, Andrew. Why We (Usually) Don’t Have to Worry About Multiple Comparisons. Columbia University, www.stat.columbia.edu/~gelman/research/published/badbayesmain.pdf.\nMorris, G. Elliot \u0026ldquo;How Our Polling Averages Work.\u0026rdquo; FiveThirtyEight, 18 Aug. 2020, fivethirtyeight.com/methodology/how-our-polling-averages-work/.\nPolling Data Provided by GOV 1347: Election Analytics teaching staff (which itself drew from the FiveThirtyEight GitHub)\nEconomic Data Provided by GOV 1347: Election Analytics teaching staff (which itself drew from the Burueau of Economic Analysia and Federal Reserve Economic Data)\n"},{"id":5,"href":"/2024election-blog/post/2024-10-05-week-5-demographics/","title":"Week 5: Demographics","section":"Posts","content":" Week 5: Demographics # Monday, October 7, 2024\n28 Days until Presidential Election\nWelcome back! This week I will focus on demographic data and the role it plays in forecasting. Since last week, the vice presidential candidates faced off in a relatively calm and respectful debate. Again, a principal topic was that of immigration, which, in addition to being incredibly polarizing, often falls to identity-based arguments and concerns over the makeup of the United States demographically. Demographic shifts in race, educational attainment, and income distribution are an undercurrent to many political debates at the community level up to the national level. How identity can affect electoral politics is an incredibly large academic theme within the field of political science. In this post, I will touch on a seminal paper by Kim and Zilinsky (2024), which contributes to the question of if demographics motivate vote choice. I will then move into analyzing the demographics of my own state and a significant battleground state: Georgia. I will end by running simulations of my own model to quantify uncertainty in my own prediction and to visualize what that final prediction looks like as of now.\nDemographic Indicators and Vote Choice # ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading Model 1 (Intercept) 1.697 (0.112) age 0.001 (0.0008) gender −0.348 (0.030) race −0.496 (0.020) educ 0.021 (0.016) income 0.104 (0.012) religion −0.221 (0.014) attend_church −0.121 (0.009) southern −0.137 (0.032) work_status 0.065 (0.013) homeowner −0.0007 (0.006) married −0.071 (0.009) Num.Obs. 21726 AIC 27961.6 BIC 28057.4 Log.Lik. −13968.797 RMSE 0.47 ## Confusion Matrix and Statistics ## ## Reference ## Prediction Democrat Republican ## Democrat 8082 3961 ## Republican 3704 5979 ## ## Accuracy : 0.6472 ## 95% CI : (0.6408, 0.6536) ## No Information Rate : 0.5425 ## P-Value [Acc \u0026gt; NIR] : \u0026lt; 2.2e-16 ## ## Kappa : 0.2878 ## ## Mcnemar\u0026#39;s Test P-Value : 0.003455 ## ## Sensitivity : 0.6857 ## Specificity : 0.6015 ## Pos Pred Value : 0.6711 ## Neg Pred Value : 0.6175 ## Prevalence : 0.5425 ## Detection Rate : 0.3720 ## Detection Prevalence : 0.5543 ## Balanced Accuracy : 0.6436 ## ## \u0026#39;Positive\u0026#39; Class : Democrat ## ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Confusion Matrix and Statistics ## ## Reference ## Prediction Democrat Republican ## Democrat 1973 975 ## Republican 973 1509 ## ## Accuracy : 0.6413 ## 95% CI : (0.6283, 0.654) ## No Information Rate : 0.5425 ## P-Value [Acc \u0026gt; NIR] : \u0026lt;2e-16 ## ## Kappa : 0.2772 ## ## Mcnemar\u0026#39;s Test P-Value : 0.9819 ## ## Sensitivity : 0.6697 ## Specificity : 0.6075 ## Pos Pred Value : 0.6693 ## Neg Pred Value : 0.6080 ## Prevalence : 0.5425 ## Detection Rate : 0.3634 ## Detection Prevalence : 0.5429 ## Balanced Accuracy : 0.6386 ## ## \u0026#39;Positive\u0026#39; Class : Democrat ## The above figures are a result of using a logistic regression that involves demographics to predict presidential vote choice. Much of this code can be attributed to Matthew Dardet, but instead of just looking at how well demographics predicted vote choice in 1964, I included all years including and thereafter. The demographics we involve are age, gender, race, education level, income, religion, whether the voter attends church, whether the voter is from a southern state, work status, home-owning status, and marriage status. The model summary above shows that gender and race have by far the most sway on a voter\u0026rsquo;s choice among these demographics. What I find interesting is that age does not really have that much of an impact on vote choice as compared to other demographics. This work is a replication of the original work of Kim and Zilinsky (2024). Similar to their paper\u0026rsquo;s most notable finding, this replication finds that these key demographics can only predict the vote choice accurately about 64% of the time. Given the reliance of popular media and conventional wisdom on identity politics, it would seem that demographics would play a huge role in vote choice, and they are certainly not negligible. But key demographics are not as determinative as we might have thought.\n## Confusion Matrix and Statistics ## ## Reference ## Prediction Democrat Republican ## Democrat 7926 3091 ## Republican 3860 6849 ## ## Accuracy : 0.6801 ## 95% CI : (0.6738, 0.6863) ## No Information Rate : 0.5425 ## P-Value [Acc \u0026gt; NIR] : \u0026lt; 2.2e-16 ## ## Kappa : 0.3593 ## ## Mcnemar\u0026#39;s Test P-Value : \u0026lt; 2.2e-16 ## ## Sensitivity : 0.6725 ## Specificity : 0.6890 ## Pos Pred Value : 0.7194 ## Neg Pred Value : 0.6396 ## Prevalence : 0.5425 ## Detection Rate : 0.3648 ## Detection Prevalence : 0.5071 ## Balanced Accuracy : 0.6808 ## ## \u0026#39;Positive\u0026#39; Class : Democrat ## ## Confusion Matrix and Statistics ## ## Reference ## Prediction Democrat Republican ## Democrat 1951 728 ## Republican 995 1756 ## ## Accuracy : 0.6827 ## 95% CI : (0.6701, 0.6951) ## No Information Rate : 0.5425 ## P-Value [Acc \u0026gt; NIR] : \u0026lt; 2.2e-16 ## ## Kappa : 0.3661 ## ## Mcnemar\u0026#39;s Test P-Value : 1.472e-10 ## ## Sensitivity : 0.6623 ## Specificity : 0.7069 ## Pos Pred Value : 0.7283 ## Neg Pred Value : 0.6383 ## Prevalence : 0.5425 ## Detection Rate : 0.3593 ## Detection Prevalence : 0.4934 ## Balanced Accuracy : 0.6846 ## ## \u0026#39;Positive\u0026#39; Class : Democrat ## Here, instead of relying on a logistic regression, we employ a Random Forests model. Random Forest modeling is a type of machine learning model where multiple decision trees are built for training and their predictions are aggregated in such a way that is advantageous for accuracy and the reduction of overfitting. Because we are involving so many demographic indicators, it would be useful to use Random Forest modeling and be aware of the risk of overfitting. When we use Random Forests to replicate Kim and Zilinsky\u0026rsquo;s (2024) work, we find that the key demographics can only predict vote choice about 68% of the time. This is a few percentage points higher than when we relied on the logistic regression, but it is not fully determinative, underscoring Kim and Zilinsky\u0026rsquo;s findings as well.\nParty Predicted Vote Share (%) Democrat 50.46 Republican 49.54 I use the Random Forest modeling, which at its crux relies on bootstrap sampling, to predict national vote share based on demographics, including ideology identification metrics. It finds that the Democrats will just narrowly win the popular vote in November. This falls in line with previous models and current polls about the election being one of the closest in decades.\nDelving into a State Voter File # Now, let\u0026rsquo;s delve into a sample of Georgia\u0026rsquo;s voter file. I chose Georgia because it is my home state, I have done political mobilizing on the ground there, and I have been closely following it this election. The voter file data we are relying on is a sample of 1% of the total voter file data for the Georgia electoral and has been generously provided by Statara Solutions. Please check them out here.\nAbove, we look at five key demographics indicators and how they are distributed for the Georgia electorate. First, we see that the gender distribution is relatively similar among males and females in the state with slightly more females. The population of those pertaining to expansive gender identities is very few and among this sample only 8 actually do identify as such.\nThe age distribution for various ranges is even, except for 18-24 year olds and 65+. This makes sense because the range of ages for 18-24 is fewer than other buckets and there are a large amount of ages for which the 65+ bucket covers. Remember this was an indicator that, according to Kim and Zilinsky\u0026rsquo;s (2024) finding, did not affect vote choice all that much.\nDespite the national trend toward the minority majority phenomenon, Georgia\u0026rsquo;s electorate is still majority white. It also has a large Black population and sizable Asian and Hispanic/Latino populations. The indigenous population among Georgia\u0026rsquo;s electorate is quite low, especially compared to other states like Hawaii and Alaska.\nAs for education attainment, the plurality of Georgia\u0026rsquo;s electorate completed high school and a relatively large portion completed college. I did not expect that more Georgian voters completed graduate school than just some college or higher.\nBecause this data was available, I was curious to see the distribution of homeowners versus renters among Georgian voters. I was surprised to see that most voters are actually homeowners, according to this sample.\nLastly, Georgia has one very large metropolitan city with urban sprawl, Atlanta, and a lot of other small to mid size cities. It also has a large rural populations. This even distribution is reflected in the urbanicity graph.\nModel Simulations for Battleground States # ## `summarise()` has grouped output by \u0026#39;state\u0026#39;. You can override using the ## `.groups` argument. State Democrat Republican Arizona 0.0006 0.9994 Georgia 0.9116 0.0884 Michigan 1.0000 0.0000 Nevada 1.0000 0.0000 North Carolina 0.9755 0.0245 Pennsylvania 1.0000 0.0000 Wisconsin 1.0000 0.0000 State mean_dem mean_rep sd_dem sd_rep lower_dem upper_dem lower_rep upper_rep Arizona 52.25068 53.01345 0.1576075 0.3662173 51.94177 52.55959 52.29567 53.73124 Georgia 52.57779 52.29352 0.1605107 0.3729632 52.26319 52.89239 51.56251 53.02452 Michigan 53.61763 50.50728 0.1603770 0.3726526 53.30329 53.93197 49.77688 51.23768 Nevada 54.10442 52.23273 0.1599942 0.3717632 53.79083 54.41801 51.50407 52.96138 North Carolina 52.60621 52.20061 0.1577668 0.3665874 52.29699 52.91543 51.48210 52.91912 Pennsylvania 52.87369 51.60073 0.1587398 0.3688483 52.56256 53.18482 50.87779 52.32368 Wisconsin 53.30806 51.05413 0.1592734 0.3700883 52.99589 53.62024 50.32875 51.77950 Here, I simulate the 2024 election for key battleground states: Georgia, Michigan, Nevada, Wisconsin, North Carolina, Arizona, and Pennsylvania. I involve Democratic and Republican vote shares for the past two elections, Democratic and Republican polling averages for this election, voter turnout, and economic indicators in the form of the Consumer Price Index and the quarterly GDP growth. This is an expansion of my model from past weeks because I now involve voter turnout data.\nPopular poll aggregators and forecasters, like FiveThirtyEight and the Silver Bulletin, use simulations to quantify the uncertainty of their models. Most recently, simulation of FiveThirtyEight\u0026rsquo;s model has demonstrated a virtual coin flip outcome, or a 53 in 100 chance of Harris winning the electoral college and 47 in 100 change of Trump winning the electoral college.\nIt appears that all cases the sum of the mean two party vote share for Democrats and Republicans in the same state is more than 100%. We can attribute this to the fact that these models independently and linearly (without an imposed bound) predict for vote shares between Republicans and Democrats. In 6 out of the 7 battleground states, Democrats are projected to win. The one state where Republicans win is Arizona, which would be a flip back to a Trump victory after Biden won the state in 2020. It is critical to note that for all these predictions, the winning vote shares are well within the margins of error and each party realistically has a chance to win. This is not reflected looking just at how the simulation attributes wins to each party, for example, saying that Democrats win Nevada in 100% of all simulations. When more variables are involved in the simulation, particularly racial demographic changes and respective voter turnouts among racial groups, I predict that this would be much closer across all simulations.\nD R 305 233 Here is the map I predict to see on Election Night this November, according to my model this week. I predict that Harris will win the electoral college and clear the 270 threshold, as per my simulations that involve voter turnout and economic indicators as well as polling data and past vote shares. In all honesty, though, I think the race will be much closer than this, and I hope in future weeks to reflect that.\nConclusion # According to this week\u0026rsquo;s models, Harris will win the 2024 Presidential Election, taking 305 electoral votes.\nI myself am skeptical of this finding because it does not fall in line with the conventional wisdom about the closeness of this race. It also does not comport well with the incredibly close national popular vote share that I calculated using the Random Forests model based on demographics. I find it hard to believe a possibility where Harris would barely win over Trump in the popular vote by less than a percentage point but also take 6 of the 7 critical battleground states. In future models, I hope to reflect the competitiveness of this race better.\nSources # \u0026ldquo;2024 Election Forecast.\u0026rdquo; FiveThirtyEight, 2024, https://projects.fivethirtyeight.com/2024-election-forecast/.\nSeo-young Silvia Kim and Jan Zilinsky. Division does not imply predictability: Demographics continue to reveal little about voting and partisanship. Political Behavior, 46(1):67–87, March 2024. ISSN 1573-6687. doi: 10.1007/s11109-022-09816-z.\nPolling Data Provided by GOV 1347: Election Analytics teaching staff (which itself drew from the FiveThirtyEight GitHub)\nEconomic Data Provided by GOV 1347: Election Analytics teaching staff (which itself drew from the Burueau of Economic Analysia and Federal Reserve Economic Data)\nDemographic Data Provided by GOV 1347: Election Analytics teaching staff (which itself drew from the Burueau of Economic Analysia and Federal Reserve Economic Data)\nVoter File Data Provided by Statara Solutions. Check them out here: https://statara.com/.\n"},{"id":6,"href":"/2024election-blog/post/2024-09-25-week-4-fundamentals-ii-incumbency/","title":"Week 4: Fundamentals II, Incumbency","section":"Posts","content":" Week 4: Fundamentals II, Incumbency # Monday, September 30, 2024\n35 Days until Presidential Election\nToday marks about a month since I\u0026rsquo;ve started this blog to follow and forecast the 2024 Presidential Election. Thanks for following along!\nAfter two assassination attempts, the presence of Security Service at Trump\u0026rsquo;s rallies has become a point of attack for his campaign. Most recently, he has blamed the Biden administration for withholding personnel to guard his events, thereby hindering them from reaching the size they once did. The powers that incumbent political candidates have an don\u0026rsquo;t have is a large focus of American political science. While I am skeptical that we can group Trump\u0026rsquo;s rally attendance in with incumbent advantage, we should scrutinize how the theory applies to this year\u0026rsquo;s election—especially in relation to who we actually consider to be the incumbent between Harris and Trump.\nDescriptive Statistics on Incumbent Advantage # Incumbent President Re-elected Count Percentage FALSE 12 66.67 TRUE 6 33.33 ## Elections with At Least One Incumbent Running: 11 ## Incumbent Victories: 7 ## Percentage: 63.64 Election Year Democratic Candidate Republican Candidate Democratic Incumbency Republican Incumbency Democratic Win Republican Win 2004 Kerry, John Bush, George W. FALSE TRUE FALSE TRUE 2012 Obama, Barack H. Romney, Mitt TRUE FALSE TRUE FALSE 2020 Biden, Joseph R. Trump, Donald J. FALSE TRUE TRUE FALSE Incumbent Party Re-elected Count Percentage FALSE 10 55.56 TRUE 8 44.44 Previous Administration Member Elected Percentage FALSE 72.22 TRUE 27.78 Above we calculate some descriptive statistics on the incumbency advantage. If we simply look at the number of times an incumbent president is reelected or the number of times an incumbent party is reelected, it looks like incumbents actually have worse chances at being elected into office for a second time. Let us actually consider those elections which have incumbent running, however, and we see that incumbents have a higher rate of winning elections than non-incumbents.\nPork Barrel Spending and Incumbency # The advantage of incumbents is partly attributed to the powers they hold while in office and the ability to leverage them to garner votes. One such power is the power to apportion federal spending monies to key certain constituencies; this is known as pork barrel spending. The function of pork barrel spending lies in the idea that voters who receive more funding from an incumbent administration are more likely to view that administration favorably and cast their votes for them in the next election.\nTable 1: Pork County-Level Model Model 1 (Intercept) −6.450 (0.084) dpct_grants 0.005 (0.001) comp_state 0.153 (0.076) as.factor(year)1992 0.171 (0.116) as.factor(year)1996 6.345 (0.116) as.factor(year)2000 −2.050 (0.116) as.factor(year)2004 8.407 (0.116) as.factor(year)2008 3.137 (0.116) dpct_grants × comp_state 0.006 (0.002) Num.Obs. 18464 R2 0.403 R2 Adj. 0.402 AIC 107912.7 BIC 107990.9 Log.Lik. −53946.355 F 1555.616 RMSE 4.49 Table 1: Extended Pork County-Level Model Model 1 (Intercept) −6.523 (0.085) dpct_grants 0.004 (0.001) comp_state 0.155 (0.077) as.factor(year)1992 −0.156 (0.121) as.factor(year)1996 6.231 (0.120) as.factor(year)2000 −2.000 (0.119) as.factor(year)2004 8.248 (0.119) as.factor(year)2008 3.574 (0.124) dpc_income 0.134 (0.022) inc_ad_diff 0.061 (0.011) inc_campaign_diff 0.162 (0.013) dhousevote_inc 0.012 (0.002) iraq_cas2004 −0.153 (0.070) iraq_cas2008 −0.165 (0.022) dpct_popl 2.103 (0.530) dpct_grants × comp_state 0.006 (0.002) Num.Obs. 17959 R2 0.420 R2 Adj. 0.419 AIC 104624.8 BIC 104757.3 Log.Lik. −52295.398 F 865.892 RMSE 4.45 Table 1: Pork State-Level Model Model 1 (Intercept) 9.635 (3.632) is_comp −0.400 (4.150) change_grant_mil 0.114 (0.105) as.factor(year)1992 6.895 (6.717) as.factor(year)1996 −21.379 (5.273) as.factor(year)2000 3.577 (5.626) as.factor(year)2004 −30.162 (5.475) as.factor(year)2008 1.085 (4.863) is_comp × change_grant_mil −0.103 (0.164) Num.Obs. 300 R2 0.268 R2 Adj. 0.247 AIC 2754.6 BIC 2791.6 Log.Lik. −1367.285 F 13.286 RMSE 23.07 Here, we visualize a replication of the findings from Kriner and Reeves\u0026rsquo; \u0026ldquo;Presidential Particularism and Divide-the-Dollar Politics\u0026rdquo; (2015). They find that spending of federal grants in swing states is higher than core states. Just looking at swing states, there is a sizable difference in spending when an incumbent is running in an election versus when they are not. It is intuitive that incumbents use federal spending to advantage them in upcoming elections when they have them. My hope is that visualizing pork barrel spending can help give shape to the idea of the incumbency advantage.\nTime for a Change Model # One model of the incumbency advantage is Alan Abramowitz\u0026rsquo;s Time for Change model, which he developed in 1988. It is a simple Ordinary Least Squares Regression Model that relies on three independent variables: GDP Growth for Quarter 2, June Gallup Poll Approval, and a binary variable on incumbency status of a candidate.\nTable 2: Time for Change Models for 2024 Excluding 2020 Data Including 2020 Data Harris Non-Incumbent Hypothetical, Excluding 2020 Harris Non-Incumbent Hypothetical, Including 2020 (Intercept) 48.212 49.236 48.212 49.236 (1.070) (1.117) (1.070) (1.117) GDP Growth (Quarterly) 0.465 0.147 0.465 0.147 (0.155) (0.088) (0.155) (0.088) Incumbency Status 2.220 2.576 2.220 2.576 (1.244) (1.411) (1.244) (1.411) Approval Rating in June 0.132 0.139 0.132 0.139 (0.025) (0.029) (0.025) (0.029) Num.Obs. 18 19 18 19 R2 0.817 0.753 0.817 0.753 R2 Adj. 0.777 0.703 0.777 0.703 AIC 89.3 99.1 89.3 99.1 BIC 93.8 103.8 93.8 103.8 Log.Lik. −39.673 −44.548 −39.673 −44.548 F 20.783 15.217 20.783 15.217 RMSE 2.19 2.52 2.19 2.52 Table 2: Two-Party Vote Shares (%) Across Various Time for Change Models Candidate Excluding 2020 Data Including 2020 Data Harris Non-Incumbent Hypothetical, Excluding 2020 Harris Non-Incumbent Hypothetical, Including 2020 Silver's Ensemble Model, Weighing Polls Closer to Election Day Kamala Harris 48.93 49.2 46.71 46.62 51.31 Donald Trump 51.07 50.8 53.29 53.38 48.07 I have constructed four models based off of Abramowitz\u0026rsquo;s Time for Change theory and predicted the upcoming 2024 election. In two models, I treat Harris as an incumbent candidate (and Trump a non-incumbent) and the other two models, I treat both candidates as non-incumbents. Like in previous weeks, I have compare models that include 2020 as a data point on which I train the model.\nAll models show promise with relatively high R-squared and adjusted-R-squared values. For the very first time since I have started this blog, a model I constructed predicted a Trump win in popular vote. In fact, across all Time for Change models, Trump is predicted to win the popular vote—whether or not I include 2020 training data and whether I not I treat Harris as an incumbent candidate. We can see how this differs from my preferred model thus far constructed: Nate Silver\u0026rsquo;s, which is an ensemble model that involves economic and polling data and weighs polls higher the closer they get to election day (See more on this in Week 3\u0026rsquo;s blog post).\nAll this to say, the predicted two-party vote shares predicted from Abramowitz\u0026rsquo;s model shows a difference when we treat Harris as an incumbent and when we do not. This makes sense as we would expect an incumbent to be advantaged by some number of percentage points than they would otherwise.\nConclusion # Trump is predicted to win the popular vote in November.\nAcross all four models I constructed off of Abramowitz\u0026rsquo;s Time for Change Model, Donald Trump is predicted to have a greater-than-one-point lead over Harris in two-party popular vote share. This is the first time that Trump has been predicted to win in my models. When Harris\u0026rsquo;s incumbent advantage is removed, his lead over her widens.\nSources # Abramowitz, Alan I. “An Improved Model for Predicting Presidential Election Outcomes.” PS: Political Science and Politics, vol. 21, no. 4, 1988, pp. 843–47. JSTOR, https://doi.org/10.2307/420023.\nKriner, Douglas L., and Andrew Reeves. “Presidential Particularism and Divide-the-Dollar Politics.” American Political Science Review 109.1 (2015): 155–171. Web.\nOlmsted, Edith. “Trump Has a Wild New Theory for His Flagging Crowd Sizes.” The New Republic, 30 Sept. 2024, https://newrepublic.com/post/186504/donald-trump-joe-biden-theory-crowd-sizes.\n“When and Where Is the Vance-Walz US Vice Presidential Debate?” Reuters, 19 Sept. 2024, www.reuters.com/world/us/when-where-is-vance-walz-us-vice-presidential-debate-2024-09-19/.\nPolling Data Provided by GOV 1347: Election Analytics teaching staff (which itself drew from the FiveThirtyEight GitHub)\nEconomic Data Provided by GOV 1347: Election Analytics teaching staff (which itself drew from the Burueau of Economic Analysia and Federal Reserve Economic Data)\n"},{"id":7,"href":"/2024election-blog/post/2024-09-23-week-3-polling/","title":"Week 3: Polling","section":"Posts","content":" Week 3: Polling # Monday, September 23, 2024\n42 Days until Presidential Election\nHi again! Since last week, the Harris and Trump campaigns have been campaigning aggressively in battleground states. Realistically, who the next president will be hinges on voters in these key states: some have called this the closest presidential race of the past six decades. I touched briefly on the Harris-Trump debate last week, and although the Harris campaign agreed to another, Trump refuses to debate while voters in some states are beginning to cast their ballots. The VP candidates, however, are scheduled to debate each other next week on October 1st. This week, early voting begins in Minnesota, South Dakota, and Virginia. Considering how thin the margins between Harris and Trump are, it is important to consistently track their performance through polling data. Involving polling data into my model is the focus of this week. Because this race is unique in the fact that Harris entered with less than 16 weeks until election day, the scope of our forecasting is much more limited in available polling data than previous election years.\nIndividual Poll Ratings # In the charts above, I visualize the distribution of ratings of individual polls I use for the 2016, 2020, and 2024 election years. This data was provided by Matthew Dardet, who initially sourced it from FiveThirtyEight\u0026rsquo;s public GitHub. FiveThirtyEight, a poll aggregator, assigns grade values to individual polls, which we can use a proxy to interpret how much trust to put into their numbers. You might notice that the scale evolves from an A-D grading scaling, to A-F with \u0026ldquo;on-the-fence\u0026rdquo; assignments as well (e.g. \u0026ldquo;A/B\u0026rdquo;), to a continuous numeric scale from 0-3.0. For the sake of comparison, I\u0026rsquo;ve stacked these plots to understand how the distribution of polling quality varies from election year to election year. It seems that there exists—as a whole—a pretty even spread of poll ratings, with convergence on A, B, C grades (or 3, 2, 1 grades). In 2020, however, there seem to be significantly more polls with a C rating. There are also a good amount of polls that have not been assigned grades (NA values). In its forecasting, FiveThirtyEight weights poll data by its rating, so as not to give the same importance to the numbers of a fail-grade poll as an exceptional one.\n2016 Polling Averages # To set up this plot, I averaged individual polls across the same day for the year leading up to the 2016 election. The polling numbers are interesting here because for the first few months it appears that, as Clinton went up in approval, so did Trump—same with when her numbers fell. This is not intuitive because, one would assume, that when a Democratic candidate does well a Republican candidate\u0026rsquo;s approval drops (and vice versa). It is important to note, however, this is before both parties\u0026rsquo; primaries even began. After February 1, 2016 when primaries began, Clinton\u0026rsquo;s gains coincide with Trump\u0026rsquo;s losses and Trump\u0026rsquo;s gains with Clinton\u0026rsquo;s losses. I hypothesize that this is because a frontrunner emerges within each party and voters begin to seriously compare top candidates across parties, resulting in inverse effects between them. The Clinton-Trump polling margin ranged from over 10 points to less than one 1 point. Clinton seemed to maintain the lead throughout the race however, which is in line with her eventually winning the popular vote in November. The dashed line represents each candidate\u0026rsquo;s actual vote share in the election; as a whole, these polls underestimated the popular vote share of both candidates.\n2020 Polling Averages # I set up this plot the same way I did for 2016, by taking day averages. The party primaries in 2020 began on February 3rd. We see the same phenomenon we did in 2016, where before that point the approval of both candidates seems to line up with the same ups and downs. After February 3rd, however, the main candidates emerge and begin to diverge: when Trump did well, Biden did poorly and when Biden did well, Trump did poorly. Especially in comparison to 2016, the final polls were remarkably close to predicting the actual vote share of each candidate. For Biden, it is virtually the same, and for Trump, just a point or two short.\n2024 Polling Averages # For this plot, I calculated and plotted day averages just like I did for 2016 and 2024. You might notice that you see much less polling data for Harris (blue dots) until about July. This is because Biden was the assumed Democratic candidate who would face off against Trump for the majority of the election cycle. The polls that collected data on Harris were likely operating under a hypothetical and testing how various alternates would fare against Trump. After Biden dropped out and that became a reality, more polling data on Harris as president was collected.\nRegularized Regression Using Individual Polls # ## ## November Polling Average OLS Regressions ## ============================================================= ## Dependent variable: ## ----------------------------------------- ## pv ## OLS ## Democratic Candidates Party-Stacked ## (1) (2) ## ------------------------------------------------------------- ## nov_poll 0.745 0.681* ## (0.209) ## ## Constant 13.340 15.733 ## (9.775) ## ## ------------------------------------------------------------- ## Observations 2 4 ## R2 1.000 0.842 ## Adjusted R2 0.763 ## Residual Std. Error 1.314 (df = 2) ## F Statistic 10.635* (df = 1; 2) ## ============================================================= ## Note: *p\u0026lt;0.1; **p\u0026lt;0.05; ***p\u0026lt;0.01 ## ## Comparison of OLS and Regularized Regression Methods ## ============================================== ## Dependent variable: ## --------------------------- ## pv ~ ## OLS ## ---------------------------------------------- ## poll_weeks_left_7 -3.488 ## ## ## poll_weeks_left_8 5.957 ## ## ## poll_weeks_left_9 -1.465 ## ## ## poll_weeks_left_10 ## ## ## poll_weeks_left_11 ## ## ## poll_weeks_left_12 ## ## ## poll_weeks_left_13 ## ## ## poll_weeks_left_14 ## ## ## poll_weeks_left_15 ## ## ## poll_weeks_left_16 ## ## ## Constant 1.984 ## ## ## ---------------------------------------------- ## Observations 4 ## R2 1.000 ## ============================================== ## Note: *p\u0026lt;0.1; **p\u0026lt;0.05; ***p\u0026lt;0.01 ## 11 x 1 sparse Matrix of class \u0026#34;dgCMatrix\u0026#34; ## s1 ## (Intercept) 32.11771129 ## poll_weeks_left_7 0.03034872 ## poll_weeks_left_8 0.03382783 ## poll_weeks_left_9 0.03150732 ## poll_weeks_left_10 0.03251707 ## poll_weeks_left_11 0.03591400 ## poll_weeks_left_12 0.03424576 ## poll_weeks_left_13 0.03573401 ## poll_weeks_left_14 0.03675323 ## poll_weeks_left_15 0.03401006 ## poll_weeks_left_16 0.03482219 ## 11 x 1 sparse Matrix of class \u0026#34;dgCMatrix\u0026#34; ## s1 ## (Intercept) 16.5080023 ## poll_weeks_left_7 . ## poll_weeks_left_8 . ## poll_weeks_left_9 . ## poll_weeks_left_10 . ## poll_weeks_left_11 . ## poll_weeks_left_12 . ## poll_weeks_left_13 0.5079695 ## poll_weeks_left_14 . ## poll_weeks_left_15 0.1674345 ## poll_weeks_left_16 . ## [1] 1.676314 ## [1] 0.3259247 ## [1] 0.5028851 Table: Table 1: 2024 National Popular Vote Prediction \u0026ndash; Individual Polls\ns1 Harris 47.96284 Trump 47.31766 The above charts are bit technical, but their purpose is to visualize the regularization of my regression that uses individual polls from 2016 and 2020 to predict the outcome of the 2024 election. I essentially train a model on polling data from 2016 and 2020, subsetting to the period of 16 weeks to 7 weeks out from election day because accurate polls for Harris\u0026rsquo;s campaign are only available for this time. I, then, test on the Harris-Trump polling data in this period and predict the outcome. I rely on an elastic net model that would minimize multi-collinearity and increase robustness. Though LASSO and Ridge regression are also useful models, the elastic net is versatile and flexibile because it incorporates both of those methods as well. It is also much preferable to Ordinary Least Squares (OLS) because OLS is susceptible to overfitting and collinearity.\nBased on the visualization, we see that 14 weeks from election day (the week after Harris announced her campaign), 11 weeks from election day (during the DNC), and 8 weeks from election day (during the presidential debate where Harris performed well) the model demonstrates relatively higher coefficients—though a marginal difference as compared to other weeks. My model based on individual polls predicts Harris\u0026rsquo;s popular vote share at about 47.96% and Trump\u0026rsquo;s at 47.32%, corroborating predicitions of an incredibly close election. This is a much closer margin than what Dardet predicted with national poll averages from 1968-2024, which had Harris at 51.8% and Trump at 50.7%. We will address later how it is possible that both candidates\u0026rsquo; vote shares add up to more than 100%.\nEnsemble Models Using Individual Polls # Table: Table 2: 2024 National Popular Vote Prediction \u0026ndash; Elastic-Net, Fundamentals\ns1 Harris 50 Trump 50 Table: Table 2: 2024 National Popular Vote Prediction \u0026ndash; Elastic-Net Polls and Fundamentals\ns1 Harris 50 Trump 50 Table: Table 2: 2024 National Popular Vote Prediction \u0026ndash; Unweighted Polls and Fundamentals\ns1 Harris 50.16519 Trump 49.83481 Table: Table 2: 2024 National Popular Vote Prediction \u0026ndash; Weighted Polls Closer to November (Silver)\ns1 Harris 50.28765 Trump 49.71235 Table: Table 2: 2024 National Popular Vote Prediction \u0026ndash; Weighted Fundamentals Closer to November (Gelman \u0026amp; King, 1993)\ns1 Harris 50.04688 Trump 49.95312 After using 2016 and 2020 individual polls to predict the 2024 popular vote outcome, I decided I also wanted involve a fundamentals model (See: Week 2 Post for more details) and consider models that weight data heavier for weeks closer to election day. There are five new models, which I construct.\nA Fundamentals Only Model using Elastic Net\nA Combined Fundamentals and Polling Data Model using Elastic Net\nAn Unweighted Polling Data and Fundamentals Model\nAn Closer-To-November-Increasing Weight Polling Data Model (attributable to Nate Silver)\nAn Closer-To-November-Increasing Weight Fundamentals Model (attributable to Gelman \u0026amp; King, 1993)\nBecause elastic net predicts linearly and without constraints, I initially had predictions saying that Harris and Trump would get popular vote shares above 60% each. This does not make sense, so I regularized the scales and recalculated such that Harris and Trump were compared against each other and their sums would be 100% to be more informative of how they would actually fare in the election. This would be similar to a two-party vote share. The first two models show that Harris and Trump will tie at 50% vote shares. Once we move to the third Unweighted Polling Data and Fundamentals Model, we find that Harris is predicted to win the two-party popular vote by about .3 points. Mimicing Silver\u0026rsquo;s model, which assigns higher weights to polls as we move closer to election day, I find that Harris is predicted to win the two-party popular vote by about .6 points. The margins for a Harris win are much slimmer using Gelman \u0026amp; King\u0026rsquo;s model, which weights fundamentals higher closer to the election at .1.\nConclusion # Prediction: Based on my individual polls-generated models, Harris will win the popular vote in November by a razor-thin margin.\nAcross all models I constructed using individual polls from 2016, 2020, and 2024, Harris is predicted to win the popular vote. The models all vary by how much she is predicted to win, but they all find that she will win by an incredibly thin margin. This corroborates the characterization of this race as the closest in decades.\nSources # Bradner, Eric. “Analysis: The Closest Presidential Race in a Generation.” CNN, 22 Sept. 2024, www.cnn.com/2024/09/22/politics/closest-presidential-race-harris-trump/index.html.Chiacu, Doina. “When and Where Is the Vance-Walz US Vice Presidential Debate?” Reuters, 19 Sept. 2024, www.reuters.com/world/us/when-where-is-vance-walz-us-vice-presidential-debate-2024-09-19/.\nCole, Devan. “Harris and Trump Set for First Debate of Closest Presidential Race in Years.” CNN, 21 Sept. 2024, www.cnn.com/2024/09/21/politics/presidential-debate-harris-trump-cnn/index.html.\n“Early In-Person Voting Begins in Three States, Kicking off the Sprint to Election Day.” PBS NewsHour, 22 Sept. 2024, www.pbs.org/newshour/politics/early-in-person-voting-begins-in-three-states-kicking-off-the-sprint-to-election-day.\nPolling Data Provided by GOV 1347: Election Analytics teaching staff (which itself drew from the FiveThirtyEight GitHub)\nEconomic Data Provided by GOV 1347: Election Analytics teaching staff (which itself drew from the Burueau of Economic Analysia and Federal Reserve Economic Data)\nCollaborated with Shivali Korgaonkar and Nick Dominguez to construct this model, as part of our week\u0026rsquo;s presentation on polling.\n"},{"id":8,"href":"/2024election-blog/post/2024-09-12-week-2-fundamentals-i-the-economy/","title":"Week 2: Fundamentals I, The Economy ","section":"Posts","content":" Week 2: Forecasting Fundamentals, the Economy # Monday, September 16, 2024\n49 Days until Presidential Election\nWelcome back and thanks for following along my forecast of the 2024 US Presidential Election. Since my last post, Vice President Harris and President Trump faced off in a debate moderated by ABC\u0026rsquo;s Linsey Davis and David Muir. Both candidates were asked about abortion, immigration, foreign policy, and the economy. Only one question was directly asked about the economy, aimed at VP Harris. \u0026ldquo;When it comes to the economy, do you believe Americans are better off than they were four years ago?\u0026rdquo; The focus of this week\u0026rsquo;s post is to build and evaluate models that attempt to illustrate the relationship between incumbent success and measures of the economy.\nA Quick Note on Methodology # I deviate from class-provided data by using incumbent vote margin as the outcome variable instead of incumbent two-party-adjusted vote share. There are two main reasons for this. The first is that two-party-adjusted vote metrics do not account for votes for third-party candidates, overlooking potentially significant voter dissatisfaction with the incumbent and/or main challenger candidate. At the same time, the vote margin metric is resistant to the shocks that a potentially \u0026ldquo;successful\u0026rdquo; third-party candidate might have on vote share. The second is that vote margin provides us with more insight into the swing between the main candidate: how far ahead was the winner to the runner-up and how close was the election are questions for which the vote margin metric can provide insight.\nI source relevant metrics of the economy from a lively discussion between Geoffrey Skelley and Mary Radcliffe on the FiveThirtyEight Politics Podcast Episode \u0026ldquo;Presidential Debates Do Matter\u0026rdquo;. I highly recommend listening to the episode here. Interestingly, Skelley notes that American voters tend to look to national metrics of the economy in deciding who to vote for more than personal metrics, a phenomenon known as sociotropic voting. I believe there is some truth to this, especially in the ways that changes in national economic performance can trickle down to affect personal finances. Radcliffe and Skelley put together four broad economic phemeona voters internalize as they vote:\ninflation\nunemployment\npersonal finances\nstock market performance\nPart of my contribution this week is interpreting these phenomena into specific metrics. I rely on the Consumer Price Index as a measure of inflation, the unemployment rate as a measure of unemployment, quarterly growth in Real Disposable Personal Income as a measure of personal finances, and percent change between SP500 Open and Close reports as a measure of stock market performance. Radcliffe argues that before COVID the price of goods and services and unemployment/jobs were the most salient economic issues to voters. Since shutdowns, though, unemployment has become a much bigger concern for voters.\nGDP Growth and Vote Margin # Let\u0026rsquo;s first look at a broad measure of economic performance and evaluate it against incumbent vote margin:\n## Warning: The following aesthetics were dropped during statistical transformation: label. ## ℹ This can happen when ggplot fails to infer the correct grouping structure in ## the data. ## ℹ Did you forget to specify a `group` aesthetic or to convert a numerical ## variable into a factor? ## Warning: The following aesthetics were dropped during statistical transformation: label. ## ℹ This can happen when ggplot fails to infer the correct grouping structure in ## the data. ## ℹ Did you forget to specify a `group` aesthetic or to convert a numerical ## variable into a factor? Here, I run a linear regression on the relationship between between Quarterly GDP Growth and Incumbent Vote Margin, mapping actual election results from 1948 to 2020 onto the plot as well. We observe a pretty strong positive relationship between GDP growth and incumbent vote margin, suggesting that the better the output of the national economy, the better an incumbent party's performance in the upcoming presidential election. You might notice that I have two plots: one with 2020 as a data point and one without. This is because across a number of metrics 2020 is a distant outlier, which often skews models in a ways that confuses any actual evaluation of a relationship between economy and election performance. I keep both plots to illustrate this discrepancy and to note which metrics 2020 data falls into a predicted pattern for and which it does not. ## [1] \u0026#34;With 2020 R-Squared: 0.187884044842374\u0026#34; ## [1] \u0026#34;Without 2020 R-Squared: 0.317291723250674\u0026#34; ## [1] \u0026#34;With 2020 Mean Squared Error: 79.2859405902988\u0026#34; ## [1] \u0026#34;Without 2020 Mean Squared Error: 67.7703432164646\u0026#34; ## [1] \u0026#34;Cross-Validation Mean Absolute Value Error (Without 2020): 3.45136273870236\u0026#34; Above are some in-sample and out-of-sample ways to evaluate the strength of GDP Growth model. Across the board, the model performs pretty poorly, as we see very low R-Squared values, high Mean Squared Errors and Cross-Validation Mean Absolute Value Errors with vote margin percentages large enough to sway a close election. The GDP model that leaves out 2020 generally fares better, but it is still not great.\n## [1] \u0026#34;2024 GDP-Predicted Incumbent Vote Margin: 4.15855909921272\u0026#34; ## [1] \u0026#34;2024 GDP-Predicted Incumbent Vote Margin (Excluding 2020 from Model): 3.21368743265838\u0026#34; Even still, we can predict how the incumbent party will perform given GDP growth as the input. Across models that involve 2020 and exclude it, it seems that Harris will have a fairly large lead in national popular vote share against Trump. We will tally these outcomes, although flawed in terms of strength of model, as we go along.\nHarris +1\nCPI and Vote Margin # ## Warning: The following aesthetics were dropped during statistical transformation: label. ## ℹ This can happen when ggplot fails to infer the correct grouping structure in ## the data. ## ℹ Did you forget to specify a `group` aesthetic or to convert a numerical ## variable into a factor? ## Warning: The following aesthetics were dropped during statistical transformation: label. ## ℹ This can happen when ggplot fails to infer the correct grouping structure in ## the data. ## ℹ Did you forget to specify a `group` aesthetic or to convert a numerical ## variable into a factor? Above, I run a linear regression on the relationship between between Consumer Price Index and Incumbent Vote Margin. This is a critical measure because voters are exposed to sticker shock effects as a result of inflation and can vote accordingly. It might be a national measure, but individual voters are directly exposed to it. According to the model, there is a pretty strong negative relationship between CPI and incumbent vote margin, suggesting that the higher that consumer prices are, the worse an incumbent party's performance in the upcoming presidential election. Here, it seems that 2020 actually does not distort the model's relationship of the two variables. ## [1] \u0026#34;With 2020 R-Squared: 0.0801668996456767\u0026#34; ## [1] \u0026#34;Without 2020 R-Squared: 0.0520097549971837\u0026#34; ## [1] \u0026#34;With 2020 Mean Squared Error: 89.8022407816482\u0026#34; ## [1] \u0026#34;Without 2020 Mean Squared Error: 94.1040653199678\u0026#34; ## [1] \u0026#34;Cross-Validation Mean Absolute Value Error (Without 2020): 3.89064544066784\u0026#34; The CPI model fares even worse than the GDP model with abysmal R-Squared values, high Mean Squared Errors, and a large Cross-Validation Mean Absolute Value Error.\n## [1] \u0026#34;2024 CPI-Predicted Incumbent Vote Margin: -3.30839041076806\u0026#34; ## [1] \u0026#34;2024 CPI-Predicted Incumbent Vote Margin (Excluding 2020 from Model): -2.19490995507331\u0026#34; Building our linear regression model on solely the CPI, we see that Harris trails Trump by 3.3% share of national popular vote with 2020 data and 2.2% excluding it. This makes sense as voters have consistently aired their grievances about inflation through this campaign season.\nTrump +1\nRDPI Growth and Vote Margin # ## Warning: The following aesthetics were dropped during statistical transformation: label. ## ℹ This can happen when ggplot fails to infer the correct grouping structure in ## the data. ## ℹ Did you forget to specify a `group` aesthetic or to convert a numerical ## variable into a factor? ## Warning: The following aesthetics were dropped during statistical transformation: label. ## ℹ This can happen when ggplot fails to infer the correct grouping structure in ## the data. ## ℹ Did you forget to specify a `group` aesthetic or to convert a numerical ## variable into a factor? Now, I run a linear regression on the relationship between between Quarterly Growth in Real Disposable Personal Income and Incumbent Vote Margin. RDPI is my proxy for personal finances and can provide insight into how much voters are actually working with after taxes. According to the model, there is a pretty strong positive relationship between RDPI and incumbent vote margin, suggesting that the greater growth in RDPI, the better an incumbent party's performance in the upcoming presidential election. Here, it seems that 2020 completely distorts the model's relationship of the two variables, so it is probably best to leave it out. ## [1] \u0026#34;With 2020 R-Squared: 0.00355888626006062\u0026#34; ## [1] \u0026#34;Without 2020 R-Squared: 0.109188411395232\u0026#34; ## [1] \u0026#34;With 2020 Mean Squared Error: 97.2813924464543\u0026#34; ## [1] \u0026#34;Without 2020 Mean Squared Error: 88.4281166011348\u0026#34; ## [1] \u0026#34;Cross-Validation Mean Absolute Value Error (Without 2020): 4.08789153699003\u0026#34; Again, the RDPI model performs pretty poorly with in-sample and out-of-sample tests. It yields low R-Squared values even when I leave out 2020 data. The Mean Squared Error is high and so is the Cross-Validation Mean Absolute Value Error.\n## [1] \u0026#34;2024 RDPI Growth-Predicted Incumbent Vote Margin: 3.9250814230794\u0026#34; ## [1] \u0026#34;2024 RDPI Growth-Predicted Incumbent Vote Margin (Excluding 2020 from Model): 0.788092792500218\u0026#34; However, if we use this model to forecast the upcoming election, it appears that Harris will win. The model that involves 2020 data I determined was extremely flawed for distorting the input-outcome relationship. When we exclude 2020 data, it appears that Harris only wins the national popular vote share by less than a percentage, signaling a close race (if Quarterly RDPI Growth is all that mattered to voters).\nHarris +1\nUnemployment and Vote Margin # ## Warning: The following aesthetics were dropped during statistical transformation: label. ## ℹ This can happen when ggplot fails to infer the correct grouping structure in ## the data. ## ℹ Did you forget to specify a `group` aesthetic or to convert a numerical ## variable into a factor? ## Warning: The following aesthetics were dropped during statistical transformation: label. ## ℹ This can happen when ggplot fails to infer the correct grouping structure in ## the data. ## ℹ Did you forget to specify a `group` aesthetic or to convert a numerical ## variable into a factor? Continuing with the economic phenomena Radcliffe and Skelley highlight as important to voters, I run a linear regression on the relationship between between Unemployment and Incumbent Vote Margin. Interestingly, the model suggests that there is no correlation between unemployment and incumbent vote margin, especially if we look at the one that excludes 2020 data. It makes sense to exclude 2020 here because it forces a relationship that looks like does not exist. ## [1] \u0026#34;With 2020 R-Squared: 0.0165836375771564\u0026#34; ## [1] \u0026#34;Without 2020 R-Squared: 0.00052581496233859\u0026#34; ## [1] \u0026#34;With 2020 Mean Squared Error: 96.0098010529196\u0026#34; ## [1] \u0026#34;Without 2020 Mean Squared Error: 99.2147171241475\u0026#34; ## [1] \u0026#34;Cross-Validation Mean Absolute Value Error (Without 2020): 4.28920477488786\u0026#34; The R-Squared values for the unemployment-predicted model are the lowest we have seen so far. THe Mean Squared Errors are also the highest and the Cross-Validation Mean Absolute Value Error is a large percentage vote margin that could push an election in any direction.\n## [1] \u0026#34;2024 Unemployment-Predicted Incumbent Vote Margin: 4.67350537665337\u0026#34; ## [1] \u0026#34;2024 Unemployment-Predicted Incumbent Vote Margin (Excluding 2020 from Model): 3.79434427081865\u0026#34; The model suggests that the incumbent party, Harris and the Democrats, will win the national popular vote share in November—whether we include 2020 data or not.\nHarris +1\nStock Market Performance and Vote Margin # ## Warning: The following aesthetics were dropped during statistical transformation: label. ## ℹ This can happen when ggplot fails to infer the correct grouping structure in ## the data. ## ℹ Did you forget to specify a `group` aesthetic or to convert a numerical ## variable into a factor? ## Warning: The following aesthetics were dropped during statistical transformation: label. ## ℹ This can happen when ggplot fails to infer the correct grouping structure in ## the data. ## ℹ Did you forget to specify a `group` aesthetic or to convert a numerical ## variable into a factor? Finally, we look to stock market performance as a metric of economic success that voters find salient. Both 2020-inclusive and 2020-exclusive models suggest a negative relationship between Stock Market Change and Incumbent Vote Margin. This is counter-intuitive because it suggests that greater growth of the SP500 coincides with poorer performance of the incumbent party in an upcoming election. It might be that higher percentage stock market changes actually signal a volatile economy that voters fear; this is speculative though and not an actual attempt to establish causality. If this were the case, it would not be wise to use a linear model and to use a more complex one instead.\n## [1] \u0026#34;With 2020 R-Squared: 0.114865484041972\u0026#34; ## [1] \u0026#34;Without 2020 R-Squared: 0.0881691133665322\u0026#34; ## [1] \u0026#34;With 2020 Mean Squared Error: 86.4146581543887\u0026#34; ## [1] \u0026#34;Without 2020 Mean Squared Error: 90.5146374330731\u0026#34; ## [1] \u0026#34;Cross-Validation Mean Absolute Value Error (Without 2020): 4.25381698061605\u0026#34; Like the rest, the stock market model performs poorly in measures of in-sample and out-of-sample testing. The R-Squared values are low, the Mean Square Errors are high, and the Cross-Validation Mean Absolute Value is a large percentage value.\n## [1] \u0026#34;2024 Stock Market-Predicted Incumbent Vote Margin: 3.99855641825043\u0026#34; ## [1] \u0026#34;2024 Stock Market--Predicted Incumbent Vote Margin (Excluding 2020 from Model): 3.8267002013802\u0026#34; When we predict incumbent vote margin using this model, we get that Harris will be ahead of Trump by about 4 points with regards to the national popular vote share.\nHarris +1\nConclusion # Harris: 4\nTrump: 1\nPrediction: Harris will win the popular vote in November.\nIf we treat each metric of the economy (that I used to run these regressions) as keys, we see that Harris has won four economic keys and Trump has won just one. This deviates from Skelley\u0026rsquo;s suggestion that retrospective voters will disfavor Harris in light of their economic grievances.\nIn all honesty, these models are quite bad. I would not put my money on the prediction resultant from them. The best model by in-sample and out-of-sample metrics was the Quarterly-GDP-Growth-Predicted Model, which itself was pretty poor. The absolute worst model overall was the Quarterly-RDPI-Growth Predicted Model. I suspect that these models are not robust because there are only 18 or 19 (when including 2020) observations of election years off of which I am working. It is a pretty small sample size and difficult to draw statistically significant insights from. This reflects a challenge with using economic data to forecast elections—there are only so many elections to draw data from and to use to train models, resulting in a lot of variance as we see with my linear regression models. Across all models, I had errors that could have totally changed the outcome of who wins the popular vote. How can we base a forecast on models that themselves cannot make a real prediction?\nIn future economic models, I hope to use more granular data (month-wise or quarter-wise) and involve polling data to track how opinions change along with measures of economic performance. This time, I only used bivariate linear regressions, but I will in the future include multiple independent variables and weigh them by polls of voters and how salient they are.\nSources # “Presidential Debates Do Matter | 538 Politics Podcast.” YouTube, uploaded by FiveThirtyEight, 9 Sept. 2024, www.youtube.com/watch?v=PkjfKF0frvs.\nData Provided by GOV 1347: Election Analytics teaching staff (which itself drew from the Burueau of Economic Analysia and Federal Reserve Economic Data)\n"},{"id":9,"href":"/2024election-blog/post/2024-09-09-week-1-past-presidential-elections/","title":"Week 1: Past Presidential Elections","section":"Posts","content":" Week 1: Past Presidential Elections # Monday, September 9, 2024\n56 Days until Presidential Election\nWelcome to my first week tracking and forecasting the 2024 US Presidential Election. The main purpose of this first post is to get acquainted with the process of analyzing basic election data. Every Monday, I will come back here to post increasingly more sophisticated and informed additions to my forecast. For now, I am relying on past election data to predict who will become the next president of the United States. What you will find in this post is a very rudimentary method of forecasting, given it is the first week, but it should not be wholly discounted. Arguably, the best way to predict the future is by looking to the past.\nA Note on Data-Driven Prophecies and Crystal Balls # Just last week, an article in Politico written by Stanford’s Justin Grimmer, cast doubt on the ability to forecast presidential elections in the first place (Grimmer 2024). He and his co-authors for the paper behind the article, Dean Knox and Sean Westwood, find that the accuracy of election forecasts is virtually untestable because it relies on probabilities to be played out. Say, for example, that a famous poll aggregator forecasted that Kamala Harris were to win the next election 45 out of 100 times. They make the point that we have not even seen 100 presidential elections as a country to test this finding and compare it to other models.\nThough I believe Grimmer, Knox, and Westwood to be overly pessimistic about the attention given to political forecasts, especially presidential ones, I will carry their skepticism with me as I build my models. There is value in mathematically evaluating how various data inputs could impact candidate success, but surely an overreliance on quantitative data will not be truly informative.\nCreating a Standard Style # # custom ggplot theme my_prettier_theme \u0026lt;- function() { theme( # no border panel.border = element_blank(), # background panel.background = element_rect(fill = \u0026#34;snow2\u0026#34;), # text plot.title = element_text(size = 15, hjust = .5, face = \u0026#34;bold\u0026#34;, family = \u0026#34;sans\u0026#34;), plot.subtitle = element_text(size = 13, hjust = .5, family = \u0026#34;sans\u0026#34;), plot.title.position = \u0026#34;panel\u0026#34;, axis.text.x = element_text(size = 8, angle = 45, hjust = .5, family = \u0026#34;sans\u0026#34;), axis.text.y = element_text(size = 8, family = \u0026#34;sans\u0026#34;), axis.title.x = element_text(family = \u0026#34;sans\u0026#34;), axis.title.y = element_text(angle = 90, family = \u0026#34;sans\u0026#34;), axis.ticks = element_line(colour = \u0026#34;black\u0026#34;), axis.line = element_line(colour = \u0026#34;grey\u0026#34;), # legend legend.position = \u0026#34;right\u0026#34;, legend.title = element_text(size = 12, family = \u0026#34;sans\u0026#34;), legend.text = element_text(size = 10, family = \u0026#34;sans\u0026#34;), # aspect ratio aspect.ratio = .8 ) } Before we move into content, I wanted to establish a standard style for my visualizations going forward. I choose sans serif font and relatively large size text for ease of reading.\nGuiding Questions for this Week # How competitive are presidential elections in the United States?\nWhich states vote blue/red and how consistently?\nTo answer these questions, let’s look at popular vote share and electoral college data from presidential elections between 1948 and 2020. Thank you to Matthew Dardet for cleaning and providing this data.\n####----------------------------------------------------------# #### Visualize trends in national presidential popular vote. ####----------------------------------------------------------# # Visualize the two-party presidential popular over time. two_party_visualization \u0026lt;- d_popvote |\u0026gt; ggplot(mapping = aes(x = year, y = pv2p, # look at two-party popular vote color = party)) + # color code by winning party geom_line() + geom_point() + # add points for each election scale_color_manual(\u0026#34;Party\u0026#34;, values = c(\u0026#34;steelblue3\u0026#34;, \u0026#34;tomato3\u0026#34;)) + labs(title = \u0026#34;Two Party Presidential Popular Over Time\u0026#34;, subtitle = \u0026#34;1948-2020\u0026#34;, x = \u0026#34;Year\u0026#34;, y = \u0026#34;Winning Popular Vote Share\u0026#34;) + my_prettier_theme() two_party_visualization ggsave (\u0026#34;figures/two_party_vis.png\u0026#34;) ## Saving 7 x 5 in image The above line chart helps visualize an answer to our question on the competitiveness of presidential elections in the United States. Broadly speaking, I would say that the presidential races are very competitive between the two main parties, Democrats and Republicans. The chart shows that no one party has a solidified dominance over the popular vote, though it is noteworthy that Democrats have won the popular vote for the past four elections. According to findings in Gallup from 2021, partisan identification with either Democrats or Republicans is relatively the same but independents remain the largest group of American voters, hinting their potential to sway elections differently each election (Jones 2022). Popular vote is not necessarily how candidates win the presidency, though, so let’s take a look at state and electoral vote data.\n####----------------------------------------------------------# #### State-by-state map of presidential popular votes. ####----------------------------------------------------------# # Sequester shapefile of states from `maps` library. states_map \u0026lt;- map_data(\u0026#34;state\u0026#34;) unique(states_map$region) ## [1] \u0026quot;alabama\u0026quot; \u0026quot;arizona\u0026quot; \u0026quot;arkansas\u0026quot; ## [4] \u0026quot;california\u0026quot; \u0026quot;colorado\u0026quot; \u0026quot;connecticut\u0026quot; ## [7] \u0026quot;delaware\u0026quot; \u0026quot;district of columbia\u0026quot; \u0026quot;florida\u0026quot; ## [10] \u0026quot;georgia\u0026quot; \u0026quot;idaho\u0026quot; \u0026quot;illinois\u0026quot; ## [13] \u0026quot;indiana\u0026quot; \u0026quot;iowa\u0026quot; \u0026quot;kansas\u0026quot; ## [16] \u0026quot;kentucky\u0026quot; \u0026quot;louisiana\u0026quot; \u0026quot;maine\u0026quot; ## [19] \u0026quot;maryland\u0026quot; \u0026quot;massachusetts\u0026quot; \u0026quot;michigan\u0026quot; ## [22] \u0026quot;minnesota\u0026quot; \u0026quot;mississippi\u0026quot; \u0026quot;missouri\u0026quot; ## [25] \u0026quot;montana\u0026quot; \u0026quot;nebraska\u0026quot; \u0026quot;nevada\u0026quot; ## [28] \u0026quot;new hampshire\u0026quot; \u0026quot;new jersey\u0026quot; \u0026quot;new mexico\u0026quot; ## [31] \u0026quot;new york\u0026quot; \u0026quot;north carolina\u0026quot; \u0026quot;north dakota\u0026quot; ## [34] \u0026quot;ohio\u0026quot; \u0026quot;oklahoma\u0026quot; \u0026quot;oregon\u0026quot; ## [37] \u0026quot;pennsylvania\u0026quot; \u0026quot;rhode island\u0026quot; \u0026quot;south carolina\u0026quot; ## [40] \u0026quot;south dakota\u0026quot; \u0026quot;tennessee\u0026quot; \u0026quot;texas\u0026quot; ## [43] \u0026quot;utah\u0026quot; \u0026quot;vermont\u0026quot; \u0026quot;virginia\u0026quot; ## [46] \u0026quot;washington\u0026quot; \u0026quot;west virginia\u0026quot; \u0026quot;wisconsin\u0026quot; ## [49] \u0026quot;wyoming\u0026quot; # Read wide version of dataset that can be used to compare candidate votes with one another. d_pvstate_wide \u0026lt;- read_csv(\u0026#34;clean_wide_state_2pv_1948_2020.csv\u0026#34;) ## Rows: 959 Columns: 14 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: \u0026quot;,\u0026quot; ## chr (1): state ## dbl (13): year, D_pv, R_pv, D_pv2p, R_pv2p, D_pv_lag1, R_pv_lag1, D_pv2p_lag... ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. # Merge d_pvstate_wide with state_map. d_pvstate_wide$region \u0026lt;- tolower(d_pvstate_wide$state) pv_map \u0026lt;- d_pvstate_wide |\u0026gt; filter(year == 2020) |\u0026gt; left_join(states_map, by = \u0026#34;region\u0026#34;) # Make map grid of state winners for each election year available in the dataset. pv_win_map \u0026lt;- pv_map |\u0026gt; mutate(winner = ifelse(R_pv \u0026gt; D_pv, \u0026#34;republican\u0026#34;, \u0026#34;democrat\u0026#34;)) pv_win_map |\u0026gt; ggplot(aes(long, lat, group = group)) + geom_polygon(aes(fill = winner), color = \u0026#34;black\u0026#34;) + scale_fill_manual(values = c(\u0026#34;steelblue\u0026#34;, \u0026#34;tomato3\u0026#34;)) + theme_void() + labs(title = \u0026#34;Map Grid of State Winners\u0026#34;, subtitle = \u0026#34;2020 Election\u0026#34;) + my_prettier_theme() + theme(axis.title.x= element_blank(), axis.title.y= element_blank(), axis.text.x= element_blank(), axis.text.y= element_blank(), axis.ticks = element_blank(), axis.line= element_blank()) ggsave (\u0026#34;figures/PV_win_map.png\u0026#34;) ## Saving 7 x 5 in image Here, I have coded which candidate won in each state during the 2020 election between President Joe Biden and President Donald Trump. Democrats did very well along the coasts and Republicans the midwest and South with the notable exception of Georgia. Throughout this blog, I will draw consistent attention onto Georgia because it is my home state and I find its political behavior interesting.\nd_pvstate_wide |\u0026gt; filter(year \u0026gt;= 1980) |\u0026gt; left_join(states_map, by = \u0026#34;region\u0026#34;) |\u0026gt; mutate(winner = ifelse(R_pv2p\u0026gt;D_pv2p, \u0026#34;republican\u0026#34;, \u0026#34;democrat\u0026#34;)) |\u0026gt; ggplot(aes(long, lat, group = group)) + facet_wrap(facets = year ~.) + geom_polygon(aes(fill = winner), color = \u0026#34;white\u0026#34;)+ scale_fill_manual(values = c(\u0026#34;steelblue\u0026#34;, \u0026#34;tomato3\u0026#34;)) + labs(title = \u0026#34;Presidential Vote Share by State\u0026#34;, subtitle = \u0026#34;1980-2020\u0026#34;) + theme(strip.text = element_text(size = 12), aspect.ratio = 1) + my_prettier_theme() + theme(axis.title.x= element_blank(), axis.title.y= element_blank(), axis.text.x= element_blank(), axis.text.y= element_blank(), axis.ticks = element_blank(), axis.line= element_blank()) ## Warning in left_join(filter(d_pvstate_wide, year \u0026gt;= 1980), states_map, by = \u0026quot;region\u0026quot;): Detected an unexpected many-to-many relationship between `x` and `y`. ## ℹ Row 1 of `x` matches multiple rows in `y`. ## ℹ Row 1 of `y` matches multiple rows in `x`. ## ℹ If a many-to-many relationship is expected, set `relationship = ## \u0026quot;many-to-many\u0026quot;` to silence this warning. ggsave (\u0026#34;figures/PV_states_historical.png\u0026#34;) ## Saving 7 x 5 in image Placing the last map in context, we can see how certain states have either shifted parties (in the sense of having a preference for one party over another) or flip-flopped between elections over time. Something that sticks out to me is that California had pretty consistently voted Republican until 1992 when it firmly switched Democrat. New York has cast its electoral votes for Democrats for all elections in this period except 1984. Certain regions like the Midwest are solidly Republican from 1980 to 2020 and states like Texas, Alabama, Mississippi, South Carolina are firmly red. It appears that in the past few elections most states vote for a single party pretty consistently, but there exist certain states that swing either way.\n####----------------------------------------------------------# #### Forecast: simplified electoral cycle model. ####----------------------------------------------------------# # Create prediction (pv2p and margin) based on simplified electoral cycle model: # vote_2024 = 3/4*vote_2020 + 1/4*vote_2016 (lag1, lag2, respectively). pv2p_2024_states \u0026lt;- d_pvstate_wide |\u0026gt; filter(year == 2020) |\u0026gt; group_by(state)|\u0026gt; summarize(R_pv2p_2024 = .75*R_pv2p + .25*R_pv2p_lag1, D_pv2p_2024 = .75*D_pv2p + .25*D_pv2p_lag1) |\u0026gt; mutate(pv2p_2024_margin = R_pv2p_2024 - D_pv2p_2024, winner = ifelse(R_pv2p_2024 \u0026gt; D_pv2p_2024, \u0026#34;R\u0026#34;, \u0026#34;D\u0026#34;), region = tolower(state)) pv2p_2024_states_2 \u0026lt;- pv2p_2024_states # Plot the margin of victory in a U.S. state map. states_map \u0026lt;- map_data(\u0026#34;state\u0026#34;) state_mapa \u0026lt;- pv2p_2024_states |\u0026gt; left_join(states_map, by = \u0026#34;region\u0026#34;) state_centers \u0026lt;- data.frame(state.center, state.abb, state.name) state_mapa \u0026lt;- state_mapa |\u0026gt; ggplot(aes(long, lat, group = group)) + geom_polygon(aes(fill = pv2p_2024_margin), color = \u0026#34;black\u0026#34;)+ scale_fill_gradient2(high = \u0026#34;tomato3\u0026#34;, low = \u0026#34;steelblue3\u0026#34;, mid = \u0026#34;white\u0026#34;, name = \u0026#34;Two-Party Win Margin\u0026#34;, breaks = c(-50, -25, 0, 25, 50), limits = c(-50,50)) + labs(title = \u0026#34;2024 Presidential Forecast\u0026#34;, subtitle = \u0026#34;Simplified Electoral Cycle Model\u0026#34;) + my_prettier_theme() + theme(axis.title.x= element_blank(), axis.title.y= element_blank(), axis.text.x= element_blank(), axis.text.y= element_blank(), axis.ticks = element_blank(), axis.line= element_blank()) state_mapa ggsave(\u0026#34;figures/PV2024_simple_forecast.png\u0026#34;) ## Saving 7 x 5 in image For the above map, we rely on a very basic mathematical model to predict the outcome of the upcoming election. It works as a such: in a given state, we can find the popular vote in the 2024 election by \\(vote_{2024} = \\frac{3}{4}*vote_{2020} + \\frac{1}{4}*vote_{2016}\\). From there, we can color code each state on a gradient, which relies on the projected win margin for the two main parties. We find that states that are consistently red or blue tend to stay that way. The battleground states, which are those closest to white, are Pennsylvania, Georgia, Wisconsin, North Carolina, Nevada, and Arizona. This falls in line with generally accepted knowledge about the political behavior in these states. One thing that surprised me though was how close Texas is to being a battleground state based on this projection.\n####----------------------------------------------------------# #### Extension 1: Add state labels ####----------------------------------------------------------# # Rename ggplot state data region variable to state for ease states_map \u0026lt;- map_data(\u0026#34;state\u0026#34;) |\u0026gt; rename(state = region) # Transform state boundaries into an sf object states_sf \u0026lt;- st_as_sf(states_map, coords = c(\u0026#34;long\u0026#34;, \u0026#34;lat\u0026#34;), crs = 4326, agr = \u0026#34;constant\u0026#34;) # Create a geometry for each state states_sf \u0026lt;- states_sf |\u0026gt; group_by(state) |\u0026gt; summarize(geometry = st_combine(geometry)) |\u0026gt; st_cast(\u0026#34;POLYGON\u0026#34;) |\u0026gt; st_make_valid() # Merge with your election results data pv2p_2024_states \u0026lt;- pv2p_2024_states |\u0026gt; mutate(state = tolower(state)) # Merge state polygons with 2024 vote margin data states_sf \u0026lt;- left_join(states_sf, pv2p_2024_states, by = \u0026#34;state\u0026#34;) # Create an interactive map with leaflet interactive_map \u0026lt;- leaflet(states_sf) |\u0026gt; addTiles() |\u0026gt; addPolygons( fillColor = ~colorBin(palette = c(\u0026#34;steelblue3\u0026#34;, \u0026#34;white\u0026#34;, \u0026#34;tomato3\u0026#34;), domain = states_sf$pv2p_2024_margin, bins = c(-50, -25, 0, 25, 50))(pv2p_2024_margin), fillOpacity = 0.7, color = \u0026#34;black\u0026#34;, weight = 1, highlight = highlightOptions( weight = 3, color = \u0026#34;#666\u0026#34;, fillOpacity = 0.7, bringToFront = TRUE ), label = ~paste(str_to_title(state), \u0026#34; Win Margin: \u0026#34;, round(pv2p_2024_margin,2)), labelOptions = labelOptions( style = list(\u0026#34;font-weight\u0026#34; = \u0026#34;normal\u0026#34;, padding = \u0026#34;5px 10px\u0026#34;), textsize = \u0026#34;15px\u0026#34;, direction = \u0026#34;auto\u0026#34; ) ) |\u0026gt; addLegend( pal = colorBin(palette = c(\u0026#34;steelblue3\u0026#34;, \u0026#34;white\u0026#34;, \u0026#34;tomato3\u0026#34;), domain = states_sf$pv2p_2024_margin, bins = c(-50, -25, 0, 25, 50)), values = ~pv2p_2024_margin, opacity = 0.7, title = \u0026#34;Two-Party Win Margin (%)\u0026#34;, position = \u0026#34;bottomleft\u0026#34; ) |\u0026gt; addControl( html = \u0026#34;\u0026lt;h3 style=\u0026#39;color: black; text-align: center;\u0026#39;\u0026gt;2024 Presidential Forecast\u0026lt;/h3\u0026gt;\u0026lt;h5\u0026gt;Simplified Electoral Cycle Model\u0026lt;/h5\u0026gt;\u0026#34;, position = \u0026#34;topright\u0026#34;, className = \u0026#34;map-title\u0026#34;) ## Warning in colorBin(palette = c(\u0026quot;steelblue3\u0026quot;, \u0026quot;white\u0026quot;, \u0026quot;tomato3\u0026quot;), domain = ## states_sf$pv2p_2024_margin, : Some values were outside the color scale and will ## be treated as NA interactive_map If you are unfamiliar with American geography, here is an interactive version of the same map, where you can see state labels and what notable cities are in each state.\n# Generate projected state winners and merge with electoral college votes to make # summary of electoral college vote distributions. ec \u0026lt;- read_csv(\u0026#34;ec_full.csv\u0026#34;) ## Rows: 1010 Columns: 4 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: \u0026quot;,\u0026quot; ## chr (2): state, stateab ## dbl (2): year, electors ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. pv2p_2024_states_2 \u0026lt;- pv2p_2024_states_2 |\u0026gt; mutate(year = 2024)|\u0026gt; left_join(ec, by = c(\u0026#34;state\u0026#34;, \u0026#34;year\u0026#34;)) projected_electoral_winner \u0026lt;- pv2p_2024_states_2 |\u0026gt; group_by(winner)|\u0026gt; summarize(electoral_votes = sum(electors)) projected_electoral_winner ## # A tibble: 2 × 2 ## winner electoral_votes ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; ## 1 D 276 ## 2 R 262 Harris: 276 # Trump: 262 # Using the formula we drew on before, we can determine which states will (by this model) cast their electoral votes for Democrats and which will for Republicans. Then, we tally up the totals and find that Democrats pass the threshold of 270 to win the office. Based on this very rudimentary model, Kamala Harris is projected to be the next president of the United States.\nYou can find my code for this entry by clicking on the Github link to the right. Please reach out if you encounter any errors.\nSources # Grimmer, Justin. “Don’t Trust the Election Forecasts.” POLITICO, POLITICO, 3 Sept. 2024, www.politico.com/news/magazine/2024/09/03/election-forecasts-data-00176905.\nJones, Jeffrey M. “U.S. Political Party Preferences Shifted Greatly During 2021.” Gallup, 17 Jan. 2022, https://news.gallup.com/poll/388781/political-party-preferences-shifted-greatly-during-2021.aspx.\nData Provided by GOV 1347: Election Analytics teaching staff.\n"}]