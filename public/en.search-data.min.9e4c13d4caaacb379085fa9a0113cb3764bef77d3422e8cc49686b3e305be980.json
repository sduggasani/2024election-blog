[{"id":0,"href":"/2024election-blog/post/2024-09-12-week-2-fundamentals-i-the-economy/","title":"Week 2: Fundamentals I, The Economy ","section":"Posts","content":" Week 2: Forecasting Fundamentals, the Economy # Monday, September 16, 2024\n49 Days until Presidential Election\nWelcome back and thanks for following along my forecast of the 2024 US Presidential Election. Since my last post, Vice President Harris and President Trump faced off in a debate moderated by ABC\u0026rsquo;s Linsey Davis and David Muir. Both candidates were asked about abortion, immigration, foreign policy, and the economy. Only one question was directly asked about the economy, aimed at VP Harris: When it comes to the economy, do you believe Americans are better off than they were four years ago? The focus of this week\u0026rsquo;s post is to build and evaluate models that attempt to illustrate the relationship between incumbent success and measures of the economy.\nA Quick Note on Methodology # I deviate from class-provided data by using incumbent vote margin as the outcome variable instead of incumbent two-party-adjusted vote share. There are two main reasons for this. The first is that two-party-adjusted vote metrics do not account for votes for third-party candidates, overlooking potentially significant voter dissatisfaction with the incumbent and/or main challenger candidate. At the same time, the vote margin metric is resistant to the shocks that a potentially \u0026ldquo;successful\u0026rdquo; third-party candidate might have on vote share. The second is that vote margin provides us with more insight into the swing between the main candidate: how far ahead was the winner to the runner-up and how close was the election are questions for which the vote margin metric can provide insight.\nI source relevant metrics of the economy from a lively discussion between Geoffrey Skelley and Mary Radcliffe on the FiveThirtyEight Politics Podcast Episode \u0026ldquo;Presidential Debates Do Matter\u0026rdquo;. I highly recommend listening to the episode here. Interestingly, Skelley notes that American voters tend to look to national metrics of the economy in deciding who to vote for more than personal metrics, a phenomenon known as sociotropic voting. I believe there is some truth to this, especially in the ways that changes in national economic performance can trickle down to affect personal finances. Radcliffe and Skelley put together four broad economic phemeona voters internalize as they vote:\ninflation\nunemployment\npersonal finances\nstock market performance\nPart of my contribution this week is interpreting these phenomena into specific metrics. I rely on the Consumer Price Index as a measure of inflation, the unemployment rate as a measure of unemployment, quarterly growth in Real Disposable Personal Income as a measure of personal finances, and percent change between SP500 Open and Close reports as a measure of stock market performance. Radcliffe argues that before COVID the price of goods and services and unemployment/jobs were the most salient economic issues to voters. Since shutdowns, though, unemployment has become a much bigger concern for voters.\n#\u0026#39; @title GOV 1347: Week 2 (Economics) Laboratory Session #\u0026#39; @author Sammy Duggasani #\u0026#39; @date September 10, 2024 ####----------------------------------------------------------# #### Preamble ####----------------------------------------------------------# # Load libraries. ## install via `install.packages(\u0026#34;name\u0026#34;)` library(car) ## Loading required package: carData library(tidyverse) ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.2 ## ── ## ✔ ggplot2 3.4.0 ✔ purrr 0.3.5 ## ✔ tibble 3.1.8 ✔ dplyr 1.0.10 ## ✔ tidyr 1.2.1 ✔ stringr 1.5.1 ## ✔ readr 2.1.3 ✔ forcats 0.5.2 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## ✖ dplyr::filter() masks stats::filter() ## ✖ dplyr::lag() masks stats::lag() ## ✖ dplyr::recode() masks car::recode() ## ✖ purrr::some() masks car::some() library(ggplot2) library(ggrepel) library(dplyr) ## set working directory here setwd(\u0026#34;/Users/sammy/Documents/Harvard/Senior Year/2024election-blog/content/post/2024-09-12-week-2-fundamentals-i-the-economy\u0026#34;) # custom ggplot theme my_prettier_theme \u0026lt;- function() { theme( # no border panel.border = element_blank(), # background panel.background = element_rect(fill = \u0026#34;snow2\u0026#34;), # text plot.title = element_text(size = 15, hjust = .5, face = \u0026#34;bold\u0026#34;, family = \u0026#34;sans\u0026#34;), plot.subtitle = element_text(size = 13, hjust = .5, family = \u0026#34;sans\u0026#34;), plot.title.position = \u0026#34;panel\u0026#34;, axis.text.x = element_text(size = 8, angle = 45, hjust = .5, family = \u0026#34;sans\u0026#34;), axis.text.y = element_text(size = 8, family = \u0026#34;sans\u0026#34;), axis.title.x = element_text(family = \u0026#34;sans\u0026#34;), axis.title.y = element_text(angle = 90, family = \u0026#34;sans\u0026#34;), axis.ticks = element_line(colour = \u0026#34;black\u0026#34;), axis.line = element_line(colour = \u0026#34;grey\u0026#34;), # legend legend.position = \u0026#34;right\u0026#34;, legend.title = element_text(size = 12, family = \u0026#34;sans\u0026#34;), legend.text = element_text(size = 10, family = \u0026#34;sans\u0026#34;), # # aspect ratio # aspect.ratio = .8 ) } ####----------------------------------------------------------# #### Read, merge, and process data. ####----------------------------------------------------------# # Load popular vote data. d_popvote \u0026lt;- read_csv(\u0026#34;popvote_1948-2020.csv\u0026#34;) ## Rows: 38 Columns: 9 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: \u0026#34;,\u0026#34; ## chr (2): party, candidate ## dbl (3): year, pv, pv2p ## lgl (4): winner, incumbent, incumbent_party, prev_admin ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. # Load economic data from FRED: https://fred.stlouisfed.org. # Variables, units, \u0026amp; ranges: # GDP, billions $, 1947-2024 # GDP_growth_quarterly, % # RDPI, $, 1959-2024 # RDPI_growth_quarterly, % # CPI, $ index, 1947-2024 # unemployment, %, 1948-2024 # sp500_, $, 1927-2024 d_fred \u0026lt;- read_csv(\u0026#34;fred_econ.csv\u0026#34;) ## Rows: 387 Columns: 14 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: \u0026#34;,\u0026#34; ## dbl (14): year, quarter, GDP, GDP_growth_quarterly, RDPI, RDPI_growth_quarte... ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. # Load economic data from the BEA: https://apps.bea.gov/iTable/?reqid=19\u0026amp;step=2\u0026amp;isuri=1\u0026amp;categories=survey#eyJhcHBpZCI6MTksInN0ZXBzIjpbMSwyLDMsM10sImRhdGEiOltbImNhdGVnb3JpZXMiLCJTdXJ2ZXkiXSxbIk5JUEFfVGFibGVfTGlzdCIsIjI2NCJdLFsiRmlyc3RfWWVhciIsIjE5NDciXSxbIkxhc3RfWWVhciIsIjIwMjQiXSxbIlNjYWxlIiwiMCJdLFsiU2VyaWVzIiwiUSJdXX0=. # GDP, 1947-2024 (all) # GNP # RDPI # Personal consumption expenditures # Goods # Durable goods # Nondurable goods # Services # Population (midperiod, thousands) d_bea \u0026lt;- read_csv(\u0026#34;bea_econ.csv\u0026#34;) |\u0026gt; rename(year = \u0026#34;Year\u0026#34;, quarter = \u0026#34;Quarter\u0026#34;, gdp = \u0026#34;Gross domestic product\u0026#34;, gnp = \u0026#34;Gross national product\u0026#34;, dpi = \u0026#34;Disposable personal income\u0026#34;, consumption = \u0026#34;Personal consumption expenditures\u0026#34;, goods = \u0026#34;Goods\u0026#34;, durables = \u0026#34;Durable goods\u0026#34;, nondurables = \u0026#34;Nondurable goods\u0026#34;, services = \u0026#34;Services\u0026#34;, pop = \u0026#34;Population (midperiod, thousands)\u0026#34;) ## Rows: 310 Columns: 11 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: \u0026#34;,\u0026#34; ## chr (1): Quarter ## dbl (10): Year, Gross domestic product, Gross national product, Disposable p... ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. # Filter and merge data. d_inc_econ \u0026lt;- d_popvote |\u0026gt; filter(incumbent_party == TRUE) |\u0026gt; select(year, pv, pv2p, winner) |\u0026gt; left_join(d_fred |\u0026gt; filter(quarter == 2)) |\u0026gt; left_join(d_bea |\u0026gt; filter(quarter == \u0026#34;Q2\u0026#34;) |\u0026gt; select(year, dpi)) ## Joining, by = \u0026#34;year\u0026#34; ## Joining, by = \u0026#34;year\u0026#34; # N.B. two different sources of data to use, FRED \u0026amp; BEA. # We are using second-quarter data since that is the latest 2024 release. # Feel free to experiment with different data/combinations! # Try using two-party vote margin instead of two-party popular vote share; why: accounts for and more resistant to third-party presence d_popvote_2 \u0026lt;- read_csv(\u0026#34;popvote_1948-2020.csv\u0026#34;) ## Rows: 38 Columns: 9 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: \u0026#34;,\u0026#34; ## chr (2): party, candidate ## dbl (3): year, pv, pv2p ## lgl (4): winner, incumbent, incumbent_party, prev_admin ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. d_popvote_2$incumbent_party_name \u0026lt;- ifelse(d_popvote_2$incumbent_party == TRUE, d_popvote_2$party, NA) d_popvote_wide_2 \u0026lt;- d_popvote_2 |\u0026gt; select(year, party, winner, pv, pv2p, incumbent_party_name) |\u0026gt; pivot_wider(names_from = party, values_from = c(winner, pv, pv2p, incumbent_party_name)) d_popvote_wide_2 \u0026lt;- d_popvote_wide_2 |\u0026gt; mutate(winner = ifelse(winner_democrat == TRUE, \u0026#34;D\u0026#34;, \u0026#34;R\u0026#34;), incumbent_party_name = ifelse(incumbent_party_name_democrat == \u0026#34;democrat\u0026#34;, \u0026#34;D\u0026#34;, \u0026#34;R\u0026#34;), incumbent_party = replace_na(incumbent_party_name, \u0026#34;R\u0026#34;), pv_winner = ifelse(pv_democrat \u0026gt; pv_republican, \u0026#34;D\u0026#34;, \u0026#34;R\u0026#34;), pv2p = ifelse(incumbent_party == \u0026#34;D\u0026#34;, pv2p_democrat, pv2p_republican)) |\u0026gt; select(year, winner, incumbent_party, pv_winner, pv_democrat, pv_republican, pv2p_democrat, pv2p_republican, pv2p) # Adding a variable to give more information about the elections where the popular vote winner was not the electoral college winner, coded as double_win d_popvote_wide_2 \u0026lt;- d_popvote_wide_2 |\u0026gt; mutate(double_win = ifelse(winner == pv_winner, TRUE, FALSE)) # Add incumbent vote margin variable d_popvote_wide_2 \u0026lt;- d_popvote_wide_2 |\u0026gt; mutate(incumb_vote_margin = ifelse(incumbent_party == \u0026#34;D\u0026#34;, pv_democrat - pv_republican, pv_republican-pv_democrat)) # Join with econ info elec_econ_comb \u0026lt;- d_popvote_wide_2 |\u0026gt; left_join(d_fred |\u0026gt; filter(quarter == 2)) |\u0026gt; left_join(d_bea |\u0026gt; filter(quarter == \u0026#34;Q2\u0026#34;) |\u0026gt; select(year, dpi)) ## Joining, by = \u0026#34;year\u0026#34; ## Joining, by = \u0026#34;year\u0026#34; GDP Growth and Vote Margin # Let\u0026rsquo;s first look at a broad measure of economic performance and evaluate it against incumbent vote margin:\n## [1] 0.4334559 ## [1] 0.5632865 ## ## Call: ## lm(formula = incumb_vote_margin ~ GDP_growth_quarterly, data = elec_econ_comb) ## ## Residuals: ## Min 1Q Median 3Q Max ## -13.486 -6.655 -1.613 5.163 17.675 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 2.5596 2.2198 1.153 0.2648 ## GDP_growth_quarterly 0.5330 0.2688 1.983 0.0637 . ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Residual standard error: 9.413 on 17 degrees of freedom ## Multiple R-squared: 0.1879,\tAdjusted R-squared: 0.1401 ## F-statistic: 3.933 on 1 and 17 DF, p-value: 0.06374 ## ## Call: ## lm(formula = incumb_vote_margin ~ GDP_growth_quarterly, data = elec_econ_comb_2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -10.9883 -8.1760 0.4772 3.6120 17.3829 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) -1.0360 2.7711 -0.374 0.7134 ## GDP_growth_quarterly 1.4165 0.5195 2.727 0.0149 * ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Residual standard error: 8.732 on 16 degrees of freedom ## Multiple R-squared: 0.3173,\tAdjusted R-squared: 0.2746 ## F-statistic: 7.436 on 1 and 16 DF, p-value: 0.01493 ## Warning: The following aesthetics were dropped during statistical transformation: label ## ℹ This can happen when ggplot fails to infer the correct grouping structure in ## the data. ## ℹ Did you forget to specify a `group` aesthetic or to convert a numerical ## variable into a factor? ## Warning: The following aesthetics were dropped during statistical transformation: label ## ℹ This can happen when ggplot fails to infer the correct grouping structure in ## the data. ## ℹ Did you forget to specify a `group` aesthetic or to convert a numerical ## variable into a factor? Here, I run a linear regression on the relationship between between Quarterly GDP Growth and Incumbent Vote Margin, mapping actual election results from 1948 to 2020 onto the plot as well. We observe a pretty strong positive relationship between GDP growth and incumbent vote margin, suggesting that the better the output of the national economy, the better an incumbent party's performance in the upcoming presidential election. You might notice that I have two plots: one with 2020 as a data point and one without. This is because across a number of metrics 2020 is a distant outlier, which often skews models in a ways that confuses any actual evaluation of a relationship between economy and election performance. I keep both plots to illustrate this discrepancy and to note which metrics 2020 data falls into a predicted pattern for and which it does not. # EVALUATING VOTE MARGIN AND GDP GROWTH MODEL # Evaluate the in-sample fit of your preferred model. # R-squared method # With 2020 print(paste(\u0026#34;With 2020 R-Squared: \u0026#34;, summary(reg_gdp_margin)$r.squared)) ## [1] \u0026#34;With 2020 R-Squared: 0.187884044842374\u0026#34; # Without 2020 print(paste(\u0026#34;Without 2020 R-Squared: \u0026#34;, summary(reg_gdp_margin_2)$r.squared)) ## [1] \u0026#34;Without 2020 R-Squared: 0.317291723250674\u0026#34; # In-sample error, plotting residuals # With 2020 plot(elec_econ_comb$year, elec_econ_comb$incumb_vote_margin, type = \u0026#34;l\u0026#34;, main =\u0026#34;True Y (Line), Predicted Y (Dot) for Each Year\u0026#34;) points(elec_econ_comb$year, predict(reg_gdp_margin, elec_econ_comb)) # Without 2020 plot(elec_econ_comb_2$year, elec_econ_comb_2$incumb_vote_margin, type = \u0026#34;l\u0026#34;, main =\u0026#34;True Y (Line), Predicted Y (Dot) for Each Year\u0026#34;) points(elec_econ_comb_2$year, predict(reg_gdp_margin_2, elec_econ_comb_2)) # Mean Squared Error mse_2020 \u0026lt;- mean((reg_gdp_margin$model$incumb_vote_margin - reg_gdp_margin$fitted.values)^2) mse_no2020 \u0026lt;- mean((reg_gdp_margin_2$model$incumb_vote_margin - reg_gdp_margin_2$fitted.values)^2) print(paste(\u0026#34;With 2020 Mean Squared Error: \u0026#34;, mse_2020)) ## [1] \u0026#34;With 2020 Mean Squared Error: 79.2859405902988\u0026#34; print(paste(\u0026#34;Without 2020 Mean Squared Error: \u0026#34;, mse_no2020)) ## [1] \u0026#34;Without 2020 Mean Squared Error: 67.7703432164646\u0026#34; # # Model Testing: Leave-One-Out # (out_samp_pred \u0026lt;- predict(reg_gdp_margin_2, elec_econ_comb_2[elec_econ_comb_2$year == 2020,])) # (out_samp_truth \u0026lt;- elec_econ_comb |\u0026gt; filter(year == 2020) |\u0026gt; select(incumb_vote_margin)) # print(paste(\u0026#34;Leave-One-Out: \u0026#34;, (out_samp_pred - out_samp_truth))) # Dangers of fundamentals-only model! # # https://www.nytimes.com/2020/07/30/business/economy/q2-gdp-coronavirus-economy.html # # Model Testing: Cross-Validation (One Run) # years_out_samp \u0026lt;- sample(elec_econ_comb_2$year, 9) # mod \u0026lt;- lm(incumb_vote_margin ~ GDP_growth_quarterly, # elec_econ_comb_2[!(elec_econ_comb_2$year %in% years_out_samp),]) # out_samp_pred \u0026lt;- predict(mod, elec_econ_comb_2[elec_econ_comb_2$year %in% years_out_samp,]) # out_samp_truth \u0026lt;- elec_econ_comb_2$incumb_vote_margin[elec_econ_comb_2$year %in% years_out_samp] # mean(out_samp_pred - out_samp_truth) # Model Testing: Cross-Validation (1000 Runs) out_samp_errors \u0026lt;- sapply(1:1000, function(i) { years_out_samp \u0026lt;- sample(elec_econ_comb_2$year, 9) mod \u0026lt;- lm(incumb_vote_margin ~ GDP_growth_quarterly, elec_econ_comb_2[!(elec_econ_comb_2$year %in% years_out_samp),]) out_samp_pred \u0026lt;- predict(mod, elec_econ_comb_2[elec_econ_comb_2$year %in% years_out_samp,]) out_samp_truth \u0026lt;- elec_econ_comb_2$incumb_vote_margin[elec_econ_comb_2$year %in% years_out_samp] mean(out_samp_pred - out_samp_truth) }) # mean(out_samp_errors) print(paste(\u0026#34;Cross-Validation Mean Absolute Value Error (Without 2020): \u0026#34;, mean(abs(out_samp_errors)))) ## [1] \u0026#34;Cross-Validation Mean Absolute Value Error (Without 2020): 3.42560959973424\u0026#34; Above are some in-sample and out-of-sample ways to evaluate the strength of GDP Growth model. Across the board, the model performs pretty poorly, as we see very low R-Squared values, high Mean Squared Errors and Cross-Validation Mean Absolute Value Errors with vote margin percentages large enough to sway a close election. The GDP model that leaves out 2020 generally fares better, but it is still not great.\n####----------------------------------------------------------# #### Predicting 2024 results using simple GDP and vote margin model. ####----------------------------------------------------------# # Sequester 2024 data. GDP_new \u0026lt;- d_fred |\u0026gt; filter(year == 2024 \u0026amp; quarter == 2) |\u0026gt; select(GDP_growth_quarterly) # Predict. print(paste(\u0026#34;2024 GDP-Predicted Incumbent Vote Margin:\u0026#34;, predict(reg_gdp_margin, GDP_new))) ## [1] \u0026#34;2024 GDP-Predicted Incumbent Vote Margin: 4.15855909921272\u0026#34; print(paste(\u0026#34;2024 GDP-Predicted Incumbent Vote Margin (Excluding 2020 from Model):\u0026#34;, predict(reg_gdp_margin_2, GDP_new))) ## [1] \u0026#34;2024 GDP-Predicted Incumbent Vote Margin (Excluding 2020 from Model): 3.21368743265838\u0026#34; Even still, we can predict how the incumbent party will perform given GDP growth as the input. Across models that involve 2020 and exclude it, it seems that Harris will have a fairly large lead in national popular vote share against Trump. We will tally these outcomes, although flawed in terms of strength of model, as we go along.\nHarris +1\nCPI and Vote Margin # ####----------------------------------------------------------# #### Understanding the relationship between economy and vote margin. ####----------------------------------------------------------# # Create scatterplot to visualize relationship between CPI and # incumbent vote margin scatterplot_cpi_margin \u0026lt;- elec_econ_comb |\u0026gt; ggplot(aes(x = CPI, y = incumb_vote_margin, label = year)) + geom_text() + labs(x = \u0026#34;CPI\u0026#34;, y = \u0026#34;Incumbent Party\u0026#39;s National Popular Vote Margin\u0026#34;) + theme_bw() scatterplot_cpi_margin_2 \u0026lt;- elec_econ_comb_2 |\u0026gt; ggplot(aes(x = CPI, y = incumb_vote_margin, label = year)) + geom_text() + labs(x = \u0026#34;CPI\u0026#34;, y = \u0026#34;Incumbent Party\u0026#39;s National Popular Vote Margin\u0026#34;) + my_prettier_theme() # Compute correlations between Q2 GDP growth and incumbent vote 2-party vote share. cor(elec_econ_comb$CPI, elec_econ_comb$incumb_vote_margin) ## [1] -0.2831376 cor(elec_econ_comb_2$CPI, elec_econ_comb_2$incumb_vote_margin) ## [1] -0.2280565 # Fit bivariate OLS. reg_cpi_margin \u0026lt;- lm(incumb_vote_margin ~ CPI, data = elec_econ_comb) reg_cpi_margin |\u0026gt; summary() ## ## Call: ## lm(formula = incumb_vote_margin ~ CPI, data = elec_econ_comb) ## ## Residuals: ## Min 1Q Median 3Q Max ## -17.113 -7.251 -1.099 5.314 17.070 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 7.52926 3.97750 1.893 0.0755 . ## CPI -0.03461 0.02843 -1.217 0.2402 ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Residual standard error: 10.02 on 17 degrees of freedom ## Multiple R-squared: 0.08017,\tAdjusted R-squared: 0.02606 ## F-statistic: 1.482 on 1 and 17 DF, p-value: 0.2402 reg_cpi_margin_2 \u0026lt;- lm(incumb_vote_margin ~ CPI, data = elec_econ_comb_2) reg_cpi_margin_2 |\u0026gt; summary() ## ## Call: ## lm(formula = incumb_vote_margin ~ CPI, data = elec_econ_comb_2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -16.9232 -7.5255 -0.3135 5.5328 17.1912 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 7.21922 4.18451 1.725 0.104 ## CPI -0.03006 0.03209 -0.937 0.363 ## ## Residual standard error: 10.29 on 16 degrees of freedom ## Multiple R-squared: 0.05201,\tAdjusted R-squared: -0.00724 ## F-statistic: 0.8778 on 1 and 16 DF, p-value: 0.3627 # Can add bivariate regression lines to our scatterplots. regplot_cpi_margin \u0026lt;- elec_econ_comb |\u0026gt; ggplot(aes(x = CPI, y = incumb_vote_margin, label = year)) + geom_smooth(method = \u0026#34;lm\u0026#34;, formula = y ~ x) + labs(x = \u0026#34;CPI\u0026#34;, y = \u0026#34;Incumbent Party\u0026#39;s National Popular Vote Margin\u0026#34;, title = \u0026#34;Relating CPI and Incumbent Vote Margin\u0026#34;, subtitle = \u0026#34;Y = 7.52926 + (-0.03461) * X\u0026#34;) + geom_text_repel() + my_prettier_theme() regplot_cpi_margin ## Warning: The following aesthetics were dropped during statistical transformation: label ## ℹ This can happen when ggplot fails to infer the correct grouping structure in ## the data. ## ℹ Did you forget to specify a `group` aesthetic or to convert a numerical ## variable into a factor? regplot_cpi_margin_2 \u0026lt;- elec_econ_comb_2 |\u0026gt; ggplot(aes(x = CPI, y = incumb_vote_margin, label = year)) + geom_smooth(method = \u0026#34;lm\u0026#34;, formula = y ~ x) + labs(x = \u0026#34;CPI\u0026#34;, y = \u0026#34;Incumbent Party\u0026#39;s National Popular Vote Margin\u0026#34;, title = \u0026#34;Relating CPI and Incumbent Vote Margin\u0026#34;, subtitle = \u0026#34;Y = 7.21922 + (-0.03006) * X\u0026#34;, caption = \u0026#34;Excluding 2020 data\u0026#34;) + geom_text_repel() + my_prettier_theme() regplot_cpi_margin_2 ## Warning: The following aesthetics were dropped during statistical transformation: label ## ℹ This can happen when ggplot fails to infer the correct grouping structure in ## the data. ## ℹ Did you forget to specify a `group` aesthetic or to convert a numerical ## variable into a factor? Above, I run a linear regression on the relationship between between Consumer Price Index and Incumbent Vote Margin. This is a critical measure because voters are exposed to sticker shock effects as a result of inflation and can vote accordingly. It might be a national measure, but individual voters are directly exposed to it. According to the model, there is a pretty strong negative relationship between CPI and incumbent vote margin, suggesting that the higher that consumer prices are, the worse an incumbent party's performance in the upcoming presidential election. Here, it seems that 2020 actually does not distort the model's relationship of the two variables. # EVALUATING VOTE MARGIN AND CPI MODEL # Evaluate the in-sample fit of your preferred model. # R-squared method # With 2020 print(paste(\u0026#34;With 2020 R-Squared: \u0026#34;, summary(reg_cpi_margin)$r.squared)) ## [1] \u0026#34;With 2020 R-Squared: 0.0801668996456767\u0026#34; # Without 2020 print(paste(\u0026#34;Without 2020 R-Squared: \u0026#34;, summary(reg_cpi_margin_2)$r.squared)) ## [1] \u0026#34;Without 2020 R-Squared: 0.0520097549971837\u0026#34; # In-sample error, plotting residuals # With 2020 plot(elec_econ_comb$year, elec_econ_comb$incumb_vote_margin, type = \u0026#34;l\u0026#34;, main =\u0026#34;True Y (Line), Predicted Y (Dot) for Each Year\u0026#34;) points(elec_econ_comb$year, predict(reg_cpi_margin, elec_econ_comb)) # Without 2020 plot(elec_econ_comb_2$year, elec_econ_comb_2$incumb_vote_margin, type = \u0026#34;l\u0026#34;, main =\u0026#34;True Y (Line), Predicted Y (Dot) for Each Year\u0026#34;) points(elec_econ_comb_2$year, predict(reg_cpi_margin_2, elec_econ_comb_2)) # Mean Squared Error mse_2020 \u0026lt;- mean((reg_cpi_margin$model$incumb_vote_margin - reg_cpi_margin$fitted.values)^2) mse_no2020 \u0026lt;- mean((reg_cpi_margin_2$model$incumb_vote_margin - reg_cpi_margin_2$fitted.values)^2) print(paste(\u0026#34;With 2020 Mean Squared Error: \u0026#34;, mse_2020)) ## [1] \u0026#34;With 2020 Mean Squared Error: 89.8022407816482\u0026#34; print(paste(\u0026#34;Without 2020 Mean Squared Error: \u0026#34;, mse_no2020)) ## [1] \u0026#34;Without 2020 Mean Squared Error: 94.1040653199678\u0026#34; # # Model Testing: Leave-One-Out # (out_samp_pred \u0026lt;- predict(reg_cpi_margin_2, elec_econ_comb_2[elec_econ_comb_2$year == 2020,])) # (out_samp_truth \u0026lt;- elec_econ_comb_2 |\u0026gt; filter(year == 2020) |\u0026gt; select(incumb_vote_margin)) # print(paste(\u0026#34;Leave-One-Out: \u0026#34;, (out_samp_pred - out_samp_truth))) # Dangers of fundamentals-only model! # # https://www.nytimes.com/2020/07/30/business/economy/q2-gdp-coronavirus-economy.html # # Model Testing: Cross-Validation (One Run) # years_out_samp \u0026lt;- sample(elec_econ_comb_2$year, 9) # mod \u0026lt;- lm(incumb_vote_margin ~ GDP_growth_quarterly, # elec_econ_comb_2[!(elec_econ_comb_2$year %in% years_out_samp),]) # out_samp_pred \u0026lt;- predict(mod, elec_econ_comb_2[elec_econ_comb_2$year %in% years_out_samp,]) # out_samp_truth \u0026lt;- elec_econ_comb_2$incumb_vote_margin[elec_econ_comb_2$year %in% years_out_samp] # mean(out_samp_pred - out_samp_truth) # Model Testing: Cross-Validation (1000 Runs) out_samp_errors \u0026lt;- sapply(1:1000, function(i) { years_out_samp \u0026lt;- sample(elec_econ_comb_2$year, 9) mod \u0026lt;- lm(incumb_vote_margin ~ CPI, elec_econ_comb_2[!(elec_econ_comb_2$year %in% years_out_samp),]) out_samp_pred \u0026lt;- predict(mod, elec_econ_comb_2[elec_econ_comb_2$year %in% years_out_samp,]) out_samp_truth \u0026lt;- elec_econ_comb_2$incumb_vote_margin[elec_econ_comb_2$year %in% years_out_samp] mean(out_samp_pred - out_samp_truth) }) # mean(out_samp_errors) print(paste(\u0026#34;Cross-Validation Mean Absolute Value Error (Without 2020): \u0026#34;, mean(abs(out_samp_errors)))) ## [1] \u0026#34;Cross-Validation Mean Absolute Value Error (Without 2020): 4.30330631116584\u0026#34; The CPI model fares even worse than the GDP model with abysmal R-Squared values, high Mean Squared Errors, and a large Cross-Validation Mean Absolute Value Error.\n####----------------------------------------------------------# #### Predicting 2024 results using simple CPI and vote margin model. ####----------------------------------------------------------# # Sequester 2024 data. CPI_new \u0026lt;- d_fred |\u0026gt; filter(year == 2024 \u0026amp; quarter == 2) |\u0026gt; select(CPI) # Predict. print(paste(\u0026#34;2024 CPI-Predicted Incumbent Vote Margin:\u0026#34;, predict(reg_cpi_margin, CPI_new))) ## [1] \u0026#34;2024 CPI-Predicted Incumbent Vote Margin: -3.30839041076806\u0026#34; print(paste(\u0026#34;2024 CPI-Predicted Incumbent Vote Margin (Excluding 2020 from Model):\u0026#34;, predict(reg_cpi_margin_2, CPI_new))) ## [1] \u0026#34;2024 CPI-Predicted Incumbent Vote Margin (Excluding 2020 from Model): -2.19490995507331\u0026#34; Building our linear regression model on solely the CPI, we see that Harris trails Trump by 3.3% share of national popular vote with 2020 data and 2.2% excluding it. This makes sense as voters have consistently aired their grievances about inflation through this campaign season.\nTrump +1\nRDPI Growth and Vote Margin # ####----------------------------------------------------------# #### Understanding the relationship between economy and vote margin. ####----------------------------------------------------------# # Create scatterplot to visualize relationship between RDPI Growth and # incumbent vote margin scatterplot_rdpi_margin \u0026lt;- elec_econ_comb |\u0026gt; ggplot(aes(x = RDPI_growth_quarterly, y = incumb_vote_margin, label = year)) + geom_text() + labs(x = \u0026#34;RDPI Quarterly Growth (%)\u0026#34;, y = \u0026#34;Incumbent Party\u0026#39;s National Popular Vote Margin\u0026#34;) + theme_bw() scatterplot_rdpi_margin_2 \u0026lt;- elec_econ_comb_2 |\u0026gt; ggplot(aes(x = RDPI_growth_quarterly, y = incumb_vote_margin, label = year)) + geom_text() + labs(x = \u0026#34;RDPI Quarterly Growth (%)\u0026#34;, y = \u0026#34;Incumbent Party\u0026#39;s National Popular Vote Margin\u0026#34;) + my_prettier_theme() # Compute correlations between Q2 GDP growth and incumbent vote 2-party vote share. cor(elec_econ_comb$RDPI_growth_quarterly, elec_econ_comb$incumb_vote_margin) ## [1] -0.0596564 cor(elec_econ_comb_2$RDPI_growth_quarterly, elec_econ_comb_2$incumb_vote_margin) ## [1] 0.3304367 # Fit bivariate OLS. reg_rdpi_margin \u0026lt;- lm(incumb_vote_margin ~ RDPI_growth_quarterly, data = elec_econ_comb) reg_rdpi_margin |\u0026gt; summary() ## ## Call: ## lm(formula = incumb_vote_margin ~ RDPI_growth_quarterly, data = elec_econ_comb) ## ## Residuals: ## Min 1Q Median 3Q Max ## -14.175 -5.886 -1.894 4.348 19.426 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 3.9848 2.9067 1.371 0.188 ## RDPI_growth_quarterly -0.0597 0.2423 -0.246 0.808 ## ## Residual standard error: 10.43 on 17 degrees of freedom ## Multiple R-squared: 0.003559,\tAdjusted R-squared: -0.05506 ## F-statistic: 0.06072 on 1 and 17 DF, p-value: 0.8083 reg_rdpi_margin_2 \u0026lt;- lm(incumb_vote_margin ~ RDPI_growth_quarterly, data = elec_econ_comb_2) reg_rdpi_margin_2 |\u0026gt; summary() ## ## Call: ## lm(formula = incumb_vote_margin ~ RDPI_growth_quarterly, data = elec_econ_comb_2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -15.012 -6.463 -1.750 4.939 19.535 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) -0.09853 3.76747 -0.026 0.979 ## RDPI_growth_quarterly 0.88662 0.63312 1.400 0.180 ## ## Residual standard error: 9.974 on 16 degrees of freedom ## Multiple R-squared: 0.1092,\tAdjusted R-squared: 0.05351 ## F-statistic: 1.961 on 1 and 16 DF, p-value: 0.1805 # Can add bivariate regression lines to our scatterplots. regplot_rdpi_margin \u0026lt;- elec_econ_comb |\u0026gt; ggplot(aes(x = RDPI_growth_quarterly, y = incumb_vote_margin, label = year)) + geom_smooth(method = \u0026#34;lm\u0026#34;, formula = y ~ x) + labs(x = \u0026#34;RDPI Quarterly Growth (%)\u0026#34;, y = \u0026#34;Incumbent Party\u0026#39;s National Popular Vote Margin\u0026#34;, title = \u0026#34;Relating RDPI Growth and Incumbent Vote Margin\u0026#34;, subtitle = \u0026#34;Y = 3.9848 + (-0.0597) * X\u0026#34;) + geom_text_repel() + my_prettier_theme() regplot_rdpi_margin ## Warning: The following aesthetics were dropped during statistical transformation: label ## ℹ This can happen when ggplot fails to infer the correct grouping structure in ## the data. ## ℹ Did you forget to specify a `group` aesthetic or to convert a numerical ## variable into a factor? regplot_rdpi_margin_2 \u0026lt;- elec_econ_comb_2 |\u0026gt; ggplot(aes(x = RDPI_growth_quarterly, y = incumb_vote_margin, label = year)) + geom_smooth(method = \u0026#34;lm\u0026#34;, formula = y ~ x) + labs(x = \u0026#34;RDPI Quarterly Growth (%)\u0026#34;, y = \u0026#34;Incumbent Party\u0026#39;s National Popular Vote Margin\u0026#34;, title = \u0026#34;Relating RDPI Growth and Incumbent Vote Margin\u0026#34;, subtitle = \u0026#34;Y = -0.09853 + 0.88662 * X\u0026#34;, caption = \u0026#34;Excluding 2020 data\u0026#34;) + geom_text_repel() + my_prettier_theme() regplot_rdpi_margin_2 ## Warning: The following aesthetics were dropped during statistical transformation: label ## ℹ This can happen when ggplot fails to infer the correct grouping structure in ## the data. ## ℹ Did you forget to specify a `group` aesthetic or to convert a numerical ## variable into a factor? Now, I run a linear regression on the relationship between between Quarterly Growth in Real Disposable Personal Income and Incumbent Vote Margin. RDPI is my proxy for personal finances and can provide insight into how much voters are actually working with after taxes. According to the model, there is a pretty strong positive relationship between RDPI and incumbent vote margin, suggesting that the greater growth in RDPI, the better an incumbent party's performance in the upcoming presidential election. Here, it seems that 2020 completely distorts the model's relationship of the two variables, so it is probably best to leave it out. # EVALUATING VOTE MARGIN AND RDPI MODEL # Evaluate the in-sample fit of your preferred model. # R-squared method # With 2020 print(paste(\u0026#34;With 2020 R-Squared: \u0026#34;, summary(reg_rdpi_margin)$r.squared)) ## [1] \u0026#34;With 2020 R-Squared: 0.00355888626006062\u0026#34; # Without 2020 print(paste(\u0026#34;Without 2020 R-Squared: \u0026#34;, summary(reg_rdpi_margin_2)$r.squared)) ## [1] \u0026#34;Without 2020 R-Squared: 0.109188411395232\u0026#34; # In-sample error, plotting residuals # With 2020 plot(elec_econ_comb$year, elec_econ_comb$incumb_vote_margin, type = \u0026#34;l\u0026#34;, main =\u0026#34;True Y (Line), Predicted Y (Dot) for Each Year\u0026#34;) points(elec_econ_comb$year, predict(reg_rdpi_margin, elec_econ_comb)) # Without 2020 plot(elec_econ_comb_2$year, elec_econ_comb_2$incumb_vote_margin, type = \u0026#34;l\u0026#34;, main =\u0026#34;True Y (Line), Predicted Y (Dot) for Each Year\u0026#34;) points(elec_econ_comb_2$year, predict(reg_rdpi_margin_2, elec_econ_comb_2)) # Mean Squared Error mse_2020 \u0026lt;- mean((reg_rdpi_margin$model$incumb_vote_margin - reg_rdpi_margin$fitted.values)^2) mse_no2020 \u0026lt;- mean((reg_rdpi_margin_2$model$incumb_vote_margin - reg_rdpi_margin_2$fitted.values)^2) print(paste(\u0026#34;With 2020 Mean Squared Error: \u0026#34;, mse_2020)) ## [1] \u0026#34;With 2020 Mean Squared Error: 97.2813924464543\u0026#34; print(paste(\u0026#34;Without 2020 Mean Squared Error: \u0026#34;, mse_no2020)) ## [1] \u0026#34;Without 2020 Mean Squared Error: 88.4281166011348\u0026#34; # # Model Testing: Leave-One-Out # (out_samp_pred \u0026lt;- predict(reg_rdpi_margin_2, elec_econ_comb_2[elec_econ_comb_2$year == 2020,])) # (out_samp_truth \u0026lt;- elec_econ_comb_2 |\u0026gt; filter(year == 2020) |\u0026gt; select(incumb_vote_margin)) # print(paste(\u0026#34;Leave-One-Out: \u0026#34;, (out_samp_pred - out_samp_truth))) # Dangers of fundamentals-only model! # # https://www.nytimes.com/2020/07/30/business/economy/q2-gdp-coronavirus-economy.html # # Model Testing: Cross-Validation (One Run) # years_out_samp \u0026lt;- sample(elec_econ_comb_2$year, 9) # mod \u0026lt;- lm(incumb_vote_margin ~ GDP_growth_quarterly, # elec_econ_comb_2[!(elec_econ_comb_2$year %in% years_out_samp),]) # out_samp_pred \u0026lt;- predict(mod, elec_econ_comb_2[elec_econ_comb_2$year %in% years_out_samp,]) # out_samp_truth \u0026lt;- elec_econ_comb_2$incumb_vote_margin[elec_econ_comb_2$year %in% years_out_samp] # mean(out_samp_pred - out_samp_truth) # Model Testing: Cross-Validation (1000 Runs) out_samp_errors \u0026lt;- sapply(1:1000, function(i) { years_out_samp \u0026lt;- sample(elec_econ_comb_2$year, 9) mod \u0026lt;- lm(incumb_vote_margin ~ RDPI_growth_quarterly, elec_econ_comb_2[!(elec_econ_comb_2$year %in% years_out_samp),]) out_samp_pred \u0026lt;- predict(mod, elec_econ_comb_2[elec_econ_comb_2$year %in% years_out_samp,]) out_samp_truth \u0026lt;- elec_econ_comb_2$incumb_vote_margin[elec_econ_comb_2$year %in% years_out_samp] mean(out_samp_pred - out_samp_truth) }) # mean(out_samp_errors) print(paste(\u0026#34;Cross-Validation Mean Absolute Value Error (Without 2020): \u0026#34;, mean(abs(out_samp_errors)))) ## [1] \u0026#34;Cross-Validation Mean Absolute Value Error (Without 2020): 4.1182564160077\u0026#34; Again, the RDPI model performs pretty poorly with in-sample and out-of-sample tests. It yields low R-Squared values even when I leave out 2020 data. The Mean Squared Error is high and so is the Cross-Validation Mean Absolute Value Error.\n####----------------------------------------------------------# #### Predicting 2024 results using simple RDPI Growth and vote margin model. ####----------------------------------------------------------# # Sequester 2024 data. RDPI_new \u0026lt;- d_fred |\u0026gt; filter(year == 2024 \u0026amp; quarter == 2) |\u0026gt; select(RDPI_growth_quarterly) # Predict. print(paste(\u0026#34;2024 RDPI Growth-Predicted Incumbent Vote Margin:\u0026#34;, predict(reg_rdpi_margin, RDPI_new))) ## [1] \u0026#34;2024 RDPI Growth-Predicted Incumbent Vote Margin: 3.9250814230794\u0026#34; print(paste(\u0026#34;2024 RDPI Growth-Predicted Incumbent Vote Margin (Excluding 2020 from Model):\u0026#34;, predict(reg_rdpi_margin_2, RDPI_new))) ## [1] \u0026#34;2024 RDPI Growth-Predicted Incumbent Vote Margin (Excluding 2020 from Model): 0.788092792500218\u0026#34; However, if we use this model to forecast the upcoming election, it appears that Harris will win. The model that involves 2020 data I determined was extremely flawed for distorting the input-outcome relationship. When we exclude 2020 data, it appears that Harris only wins the national popular vote share by less than a percentage, signaling a close race (if Quarterly RDPI Growth is all that mattered to voters).\nHarris +1\nUnemployment and Vote Margin # ####----------------------------------------------------------# #### Understanding the relationship between economy and vote margin. ####----------------------------------------------------------# # Create scatterplot to visualize relationship between Unemployment and # incumbent vote margin scatterplot_unemp_margin \u0026lt;- elec_econ_comb |\u0026gt; ggplot(aes(x = unemployment, y = incumb_vote_margin, label = year)) + geom_text() + labs(x = \u0026#34;Unemployment Rate (%)\u0026#34;, y = \u0026#34;Incumbent Party\u0026#39;s National Popular Vote Margin\u0026#34;) + theme_bw() scatterplot_unemp_margin_2 \u0026lt;- elec_econ_comb_2 |\u0026gt; ggplot(aes(x = unemployment, y = incumb_vote_margin, label = year)) + geom_text() + labs(x = \u0026#34;Unemployment Rate (%)\u0026#34;, y = \u0026#34;Incumbent Party\u0026#39;s National Popular Vote Margin\u0026#34;) + my_prettier_theme() # Compute correlations between Q2 Unemployment and incumbent vote 2-party vote share. cor(elec_econ_comb$unemployment, elec_econ_comb$incumb_vote_margin) ## [1] -0.1287775 cor(elec_econ_comb_2$unemployment, elec_econ_comb_2$incumb_vote_margin) ## [1] 0.02293066 # Fit bivariate OLS. reg_unemp_margin \u0026lt;- lm(incumb_vote_margin ~ unemployment, data = elec_econ_comb) reg_unemp_margin |\u0026gt; summary() ## ## Call: ## lm(formula = incumb_vote_margin ~ unemployment, data = elec_econ_comb) ## ## Residuals: ## Min 1Q Median 3Q Max ## -15.764 -5.236 -2.002 4.256 19.458 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 6.9590 6.7471 1.031 0.317 ## unemployment -0.5714 1.0671 -0.535 0.599 ## ## Residual standard error: 10.36 on 17 degrees of freedom ## Multiple R-squared: 0.01658,\tAdjusted R-squared: -0.04126 ## F-statistic: 0.2867 on 1 and 17 DF, p-value: 0.5993 reg_unemp_margin_2 \u0026lt;- lm(incumb_vote_margin ~ unemployment, data = elec_econ_comb_2) reg_unemp_margin_2 |\u0026gt; summary() ## ## Call: ## lm(formula = incumb_vote_margin ~ unemployment, data = elec_econ_comb_2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -14.139 -6.019 -1.664 4.323 19.109 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 3.1909 9.4185 0.339 0.739 ## unemployment 0.1509 1.6443 0.092 0.928 ## ## Residual standard error: 10.56 on 16 degrees of freedom ## Multiple R-squared: 0.0005258,\tAdjusted R-squared: -0.06194 ## F-statistic: 0.008417 on 1 and 16 DF, p-value: 0.928 # Can add bivariate regression lines to our scatterplots. regplot_unemp_margin \u0026lt;- elec_econ_comb |\u0026gt; ggplot(aes(x = unemployment, y = incumb_vote_margin, label = year)) + geom_smooth(method = \u0026#34;lm\u0026#34;, formula = y ~ x) + labs(x = \u0026#34;Unemployment Rate (%)\u0026#34;, y = \u0026#34;Incumbent Party\u0026#39;s National Popular Vote Margin\u0026#34;, title = \u0026#34;Relating Unemployment Rate and Incumbent Vote Margin\u0026#34;, subtitle = \u0026#34;Y = 6.9590 + (-0.5714) * X\u0026#34;) + geom_text_repel() + my_prettier_theme() regplot_unemp_margin ## Warning: The following aesthetics were dropped during statistical transformation: label ## ℹ This can happen when ggplot fails to infer the correct grouping structure in ## the data. ## ℹ Did you forget to specify a `group` aesthetic or to convert a numerical ## variable into a factor? regplot_unemp_margin_2 \u0026lt;- elec_econ_comb_2 |\u0026gt; ggplot(aes(x = unemployment, y = incumb_vote_margin, label = year)) + geom_smooth(method = \u0026#34;lm\u0026#34;, formula = y ~ x) + labs(x = \u0026#34;Unemployment Rate (%)\u0026#34;, y = \u0026#34;Incumbent Party\u0026#39;s National Popular Vote Margin\u0026#34;, title = \u0026#34;Relating Unemployment Rate and Incumbent Vote Margin\u0026#34;, subtitle = \u0026#34;Y = 3.1909 + 0.1509 * X\u0026#34;, caption = \u0026#34;Excluding 2020 data\u0026#34;) + geom_text_repel() + my_prettier_theme() regplot_unemp_margin_2 ## Warning: The following aesthetics were dropped during statistical transformation: label ## ℹ This can happen when ggplot fails to infer the correct grouping structure in ## the data. ## ℹ Did you forget to specify a `group` aesthetic or to convert a numerical ## variable into a factor? Continuing with the economic phenomena Radcliffe and Skelley highlight as important to voters, I run a linear regression on the relationship between between Unemployment and Incumbent Vote Margin. Interestingly, the model suggests that there is no correlation between unemployment and incumbent vote margin, especially if we look at the one that excludes 2020 data. It makes sense to exclude 2020 here because it forces a relationship that looks like does not exist. # EVALUATING VOTE MARGIN AND Unemployment MODEL # Evaluate the in-sample fit of your preferred model. # R-squared method # With 2020 print(paste(\u0026#34;With 2020 R-Squared: \u0026#34;, summary(reg_unemp_margin)$r.squared)) ## [1] \u0026#34;With 2020 R-Squared: 0.0165836375771564\u0026#34; # Without 2020 print(paste(\u0026#34;Without 2020 R-Squared: \u0026#34;, summary(reg_unemp_margin_2)$r.squared)) ## [1] \u0026#34;Without 2020 R-Squared: 0.00052581496233859\u0026#34; # In-sample error, plotting residuals # With 2020 plot(elec_econ_comb$year, elec_econ_comb$incumb_vote_margin, type = \u0026#34;l\u0026#34;, main =\u0026#34;True Y (Line), Predicted Y (Dot) for Each Year\u0026#34;) points(elec_econ_comb$year, predict(reg_unemp_margin, elec_econ_comb)) # Without 2020 plot(elec_econ_comb_2$year, elec_econ_comb_2$incumb_vote_margin, type = \u0026#34;l\u0026#34;, main =\u0026#34;True Y (Line), Predicted Y (Dot) for Each Year\u0026#34;) points(elec_econ_comb_2$year, predict(reg_unemp_margin_2, elec_econ_comb_2)) # Mean Squared Error mse_2020 \u0026lt;- mean((reg_unemp_margin$model$incumb_vote_margin - reg_unemp_margin$fitted.values)^2) mse_no2020 \u0026lt;- mean((reg_unemp_margin_2$model$incumb_vote_margin - reg_unemp_margin_2$fitted.values)^2) print(paste(\u0026#34;With 2020 Mean Squared Error: \u0026#34;, mse_2020)) ## [1] \u0026#34;With 2020 Mean Squared Error: 96.0098010529196\u0026#34; print(paste(\u0026#34;Without 2020 Mean Squared Error: \u0026#34;, mse_no2020)) ## [1] \u0026#34;Without 2020 Mean Squared Error: 99.2147171241475\u0026#34; # # Model Testing: Leave-One-Out # (out_samp_pred \u0026lt;- predict(reg_unemp_margin_2, elec_econ_comb_2[elec_econ_comb_2$year == 2020,])) # (out_samp_truth \u0026lt;- elec_econ_comb_2 |\u0026gt; filter(year == 2020) |\u0026gt; select(incumb_vote_margin)) # print(paste(\u0026#34;Leave-One-Out: \u0026#34;, (out_samp_pred - out_samp_truth))) # Dangers of fundamentals-only model! # https://www.nytimes.com/2020/07/30/business/economy/q2-gdp-coronavirus-economy.html # # Model Testing: Cross-Validation (One Run) # years_out_samp \u0026lt;- sample(elec_econ_comb_2$year, 9) # mod \u0026lt;- lm(incumb_vote_margin ~ GDP_growth_quarterly, # elec_econ_comb_2[!(elec_econ_comb_2$year %in% years_out_samp),]) # out_samp_pred \u0026lt;- predict(mod, elec_econ_comb_2[elec_econ_comb_2$year %in% years_out_samp,]) # out_samp_truth \u0026lt;- elec_econ_comb_2$incumb_vote_margin[elec_econ_comb_2$year %in% years_out_samp] # mean(out_samp_pred - out_samp_truth) # Model Testing: Cross-Validation (1000 Runs) out_samp_errors \u0026lt;- sapply(1:1000, function(i) { years_out_samp \u0026lt;- sample(elec_econ_comb_2$year, 9) mod \u0026lt;- lm(incumb_vote_margin ~ unemployment, elec_econ_comb_2[!(elec_econ_comb_2$year %in% years_out_samp),]) out_samp_pred \u0026lt;- predict(mod, elec_econ_comb_2[elec_econ_comb_2$year %in% years_out_samp,]) out_samp_truth \u0026lt;- elec_econ_comb_2$incumb_vote_margin[elec_econ_comb_2$year %in% years_out_samp] mean(out_samp_pred - out_samp_truth) }) # mean(out_samp_errors) print(paste(\u0026#34;Cross-Validation Mean Absolute Value Error (Without 2020): \u0026#34;, mean(abs(out_samp_errors)))) ## [1] \u0026#34;Cross-Validation Mean Absolute Value Error (Without 2020): 4.27701705434377\u0026#34; The R-Squared values for the unemployment-predicted model are the lowest we have seen so far. THe Mean Squared Errors are also the highest and the Cross-Validation Mean Absolute Value Error is a large percentage vote margin that could push an election in any direction.\n####----------------------------------------------------------# #### Predicting 2024 results using simple GDP and vote margin model. ####----------------------------------------------------------# # Sequester 2024 data. unemp_new \u0026lt;- d_fred |\u0026gt; filter(year == 2024 \u0026amp; quarter == 2) |\u0026gt; select(unemployment) # Predict. print(paste(\u0026#34;2024 Unemployment-Predicted Incumbent Vote Margin:\u0026#34;, predict(reg_unemp_margin, unemp_new))) ## [1] \u0026#34;2024 Unemployment-Predicted Incumbent Vote Margin: 4.67350537665337\u0026#34; print(paste(\u0026#34;2024 Unemployment-Predicted Incumbent Vote Margin (Excluding 2020 from Model):\u0026#34;, predict(reg_unemp_margin_2, unemp_new))) ## [1] \u0026#34;2024 Unemployment-Predicted Incumbent Vote Margin (Excluding 2020 from Model): 3.79434427081865\u0026#34; The model suggests that the incumbent party, Harris and the Democrats, will win the national popular vote share in November—whether we include 2020 data or not.\nHarris +1\nStock Market Performance and Vote Margin # ####----------------------------------------------------------# #### Understanding the relationship between economy and vote margin. ####----------------------------------------------------------# # Create Stock Margin Performance Variable (as percentage change) elec_econ_comb \u0026lt;- elec_econ_comb |\u0026gt; mutate(sp500_perf = (sp500_close-sp500_open)/(sp500_open)*100) elec_econ_comb_2 \u0026lt;- elec_econ_comb_2 |\u0026gt; mutate(sp500_perf = (sp500_close-sp500_open)/(sp500_open)*100) # Create scatterplot to visualize relationship between Stock Market and # incumbent vote margin scatterplot_stock_margin \u0026lt;- elec_econ_comb |\u0026gt; ggplot(aes(x = sp500_perf, y = incumb_vote_margin, label = year)) + geom_text() + labs(x = \u0026#34;Stock Market Open-Close Change (%)\u0026#34;, y = \u0026#34;Incumbent Party\u0026#39;s National Popular Vote Margin\u0026#34;) + theme_bw() scatterplot_stock_margin_2 \u0026lt;- elec_econ_comb_2 |\u0026gt; ggplot(aes(x = sp500_perf, y = incumb_vote_margin, label = year)) + geom_text() + labs(x = \u0026#34;Stock Market Open-Close Change (%)\u0026#34;, y = \u0026#34;Incumbent Party\u0026#39;s National Popular Vote Margin\u0026#34;) + my_prettier_theme() # Compute correlations between Q2 Unemployment and incumbent vote 2-party vote share. cor(elec_econ_comb$sp500_perf, elec_econ_comb$incumb_vote_margin) ## [1] -0.3389181 cor(elec_econ_comb_2$sp500_perf, elec_econ_comb_2$incumb_vote_margin) ## [1] -0.2969328 # Fit bivariate OLS. reg_stock_margin \u0026lt;- lm(incumb_vote_margin ~ sp500_perf, data = elec_econ_comb) reg_stock_margin |\u0026gt; summary() ## ## Call: ## lm(formula = incumb_vote_margin ~ sp500_perf, data = elec_econ_comb) ## ## Residuals: ## Min 1Q Median 3Q Max ## -14.388 -6.502 -2.020 5.282 19.102 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 5.245 2.518 2.083 0.0527 . ## sp500_perf -1.557 1.048 -1.485 0.1558 ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Residual standard error: 9.828 on 17 degrees of freedom ## Multiple R-squared: 0.1149,\tAdjusted R-squared: 0.0628 ## F-statistic: 2.206 on 1 and 17 DF, p-value: 0.1558 reg_stock_margin_2 \u0026lt;- lm(incumb_vote_margin ~ sp500_perf, data = elec_econ_comb_2) reg_stock_margin_2 |\u0026gt; summary() ## ## Call: ## lm(formula = incumb_vote_margin ~ sp500_perf, data = elec_econ_comb_2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -14.996 -6.818 -1.964 5.794 19.409 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 5.398 2.622 2.058 0.0562 . ## sp500_perf -1.963 1.578 -1.244 0.2315 ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Residual standard error: 10.09 on 16 degrees of freedom ## Multiple R-squared: 0.08817,\tAdjusted R-squared: 0.03118 ## F-statistic: 1.547 on 1 and 16 DF, p-value: 0.2315 # Can add bivariate regression lines to our scatterplots. regplot_stock_margin \u0026lt;- elec_econ_comb |\u0026gt; ggplot(aes(x = sp500_perf, y = incumb_vote_margin, label = year)) + geom_smooth(method = \u0026#34;lm\u0026#34;, formula = y ~ x) + labs(x = \u0026#34;Stock Market Open-Close Change (%)\u0026#34;, y = \u0026#34;Incumbent Party\u0026#39;s National Popular Vote Margin\u0026#34;, title = \u0026#34;Relating Stock Market Performance and Incumbent Vote Margin\u0026#34;, subtitle = \u0026#34;Y = 5.245 + (-1.557) * X\u0026#34;) + geom_text_repel() + my_prettier_theme() regplot_stock_margin ## Warning: The following aesthetics were dropped during statistical transformation: label ## ℹ This can happen when ggplot fails to infer the correct grouping structure in ## the data. ## ℹ Did you forget to specify a `group` aesthetic or to convert a numerical ## variable into a factor? regplot_stock_margin_2 \u0026lt;- elec_econ_comb_2 |\u0026gt; ggplot(aes(x = sp500_perf, y = incumb_vote_margin, label = year)) + geom_smooth(method = \u0026#34;lm\u0026#34;, formula = y ~ x) + labs(x = \u0026#34;Stock Market Open-Close Change (%)\u0026#34;, y = \u0026#34;Incumbent Party\u0026#39;s National Popular Vote Margin\u0026#34;, title = \u0026#34;Relating Stock Market Performance and Incumbent Vote Margin\u0026#34;, subtitle = \u0026#34;Y = 5.398 + (-1.963) * X\u0026#34;, caption = \u0026#34;Excluding 2020 data\u0026#34;) + geom_text_repel() + my_prettier_theme() regplot_stock_margin_2 ## Warning: The following aesthetics were dropped during statistical transformation: label ## ℹ This can happen when ggplot fails to infer the correct grouping structure in ## the data. ## ℹ Did you forget to specify a `group` aesthetic or to convert a numerical ## variable into a factor? Finally, we look to stock market performance as a metric of economic success that voters find salient. Both 2020-inclusive and 2020-exclusive models suggest a negative relationship between Stock Market Change and Incumbent Vote Margin. This is counter-intuitive because it suggests that greater growth of the SP500 coincides with poorer performance of the incumbent party in an upcoming election. It might be that higher percentage stock market changes actually signal a volatile economy that voters fear; this is speculative though and not an actual attempt to establish causality.\n# EVALUATING VOTE MARGIN AND Stock MODEL # Evaluate the in-sample fit of your preferred model. # R-squared method # With 2020 print(paste(\u0026#34;With 2020 R-Squared: \u0026#34;, summary(reg_stock_margin)$r.squared)) ## [1] \u0026#34;With 2020 R-Squared: 0.114865484041972\u0026#34; # Without 2020 print(paste(\u0026#34;Without 2020 R-Squared: \u0026#34;, summary(reg_stock_margin_2)$r.squared)) ## [1] \u0026#34;Without 2020 R-Squared: 0.0881691133665322\u0026#34; # In-sample error, plotting residuals # With 2020 plot(elec_econ_comb$year, elec_econ_comb$incumb_vote_margin, type = \u0026#34;l\u0026#34;, main =\u0026#34;True Y (Line), Predicted Y (Dot) for Each Year\u0026#34;) points(elec_econ_comb$year, predict(reg_stock_margin, elec_econ_comb)) # Without 2020 plot(elec_econ_comb_2$year, elec_econ_comb_2$incumb_vote_margin, type = \u0026#34;l\u0026#34;, main =\u0026#34;True Y (Line), Predicted Y (Dot) for Each Year\u0026#34;) points(elec_econ_comb_2$year, predict(reg_stock_margin_2, elec_econ_comb_2)) # Mean Squared Error mse_2020 \u0026lt;- mean((reg_stock_margin$model$incumb_vote_margin - reg_stock_margin$fitted.values)^2) mse_no2020 \u0026lt;- mean((reg_stock_margin_2$model$incumb_vote_margin - reg_stock_margin_2$fitted.values)^2) print(paste(\u0026#34;With 2020 Mean Squared Error: \u0026#34;, mse_2020)) ## [1] \u0026#34;With 2020 Mean Squared Error: 86.4146581543887\u0026#34; print(paste(\u0026#34;Without 2020 Mean Squared Error: \u0026#34;, mse_no2020)) ## [1] \u0026#34;Without 2020 Mean Squared Error: 90.5146374330731\u0026#34; # # Model Testing: Leave-One-Out # (out_samp_pred \u0026lt;- predict(reg_stock_margin_2, elec_econ_comb_2[elec_econ_comb_2$year == 2020,])) # (out_samp_truth \u0026lt;- elec_econ_comb_2 |\u0026gt; filter(year == 2020) |\u0026gt; select(incumb_vote_margin)) # print(paste(\u0026#34;Leave-One-Out: \u0026#34;, (out_samp_pred - out_samp_truth))) # Dangers of fundamentals-only model! # https://www.nytimes.com/2020/07/30/business/economy/q2-gdp-coronavirus-economy.html # # Model Testing: Cross-Validation (One Run) # years_out_samp \u0026lt;- sample(elec_econ_comb_2$year, 9) # mod \u0026lt;- lm(incumb_vote_margin ~ GDP_growth_quarterly, # elec_econ_comb_2[!(elec_econ_comb_2$year %in% years_out_samp),]) # out_samp_pred \u0026lt;- predict(mod, elec_econ_comb_2[elec_econ_comb_2$year %in% years_out_samp,]) # out_samp_truth \u0026lt;- elec_econ_comb_2$incumb_vote_margin[elec_econ_comb_2$year %in% years_out_samp] # mean(out_samp_pred - out_samp_truth) # Model Testing: Cross-Validation (1000 Runs) out_samp_errors \u0026lt;- sapply(1:1000, function(i) { years_out_samp \u0026lt;- sample(elec_econ_comb_2$year, 9) mod \u0026lt;- lm(incumb_vote_margin ~ sp500_perf, elec_econ_comb_2[!(elec_econ_comb_2$year %in% years_out_samp),]) out_samp_pred \u0026lt;- predict(mod, elec_econ_comb_2[elec_econ_comb_2$year %in% years_out_samp,]) out_samp_truth \u0026lt;- elec_econ_comb_2$incumb_vote_margin[elec_econ_comb_2$year %in% years_out_samp] mean(out_samp_pred - out_samp_truth) }) # mean(out_samp_errors) print(paste(\u0026#34;Cross-Validation Mean Absolute Value Error (Without 2020): \u0026#34;, mean(abs(out_samp_errors)))) ## [1] \u0026#34;Cross-Validation Mean Absolute Value Error (Without 2020): 4.08597249172685\u0026#34; Like the rest, the stock market model performs poorly in measures of in-sample and out-of-sample testing. The R-Squared values are low, the Mean Square Errors are high, and the Cross-Validation Mean Absolute Value is a large percentage value.\n####----------------------------------------------------------# #### Predicting 2024 results using simple GDP and vote margin model. ####----------------------------------------------------------# # Sequester 2024 data. stock_new \u0026lt;- d_fred |\u0026gt; filter(year == 2024 \u0026amp; quarter == 2) |\u0026gt; mutate(sp500_perf = (sp500_close-sp500_open)/(sp500_open)*100)|\u0026gt; select(sp500_perf) # Predict. print(paste(\u0026#34;2024 Stock Market-Predicted Incumbent Vote Margin:\u0026#34;, predict(reg_stock_margin, stock_new))) ## [1] \u0026#34;2024 Stock Market-Predicted Incumbent Vote Margin: 3.99855641825043\u0026#34; print(paste(\u0026#34;2024 Stock Market--Predicted Incumbent Vote Margin (Excluding 2020 from Model):\u0026#34;, predict(reg_stock_margin_2, stock_new))) ## [1] \u0026#34;2024 Stock Market--Predicted Incumbent Vote Margin (Excluding 2020 from Model): 3.8267002013802\u0026#34; When we predict incumbent vote margin using this model, we get that Harris will be ahead of Trump by about 4 points with regards to the national popular vote share.\nHarris +1\nConclusion # Harris: 4/ Trump: 1/ Prediction: Harris will win the popular vote in November.\nIf we treat each metric of the economy (that I used to run these regressions) as keys, we see that Harris has won four economic keys and Trump has won just one. This deviates from Skelley\u0026rsquo;s suggestion that retrospective voters will disfavor Harris in light of their economic grievances.\nIn all honesty, these models are quite bad. I would not put my money on the prediction resultant from them. The best model by in-sample and out-of-sample metrics was the Quarterly-GDP-Growth-Predicted Model, which itself was pretty poor. The absolute worst model overall was the Quarterly-RDPI-Growth Predicted Model. I suspect that these models are not robust because there are only 18 or 19 (when including 2020) observations of election years off of which I am working. It is a pretty small sample size and difficult to draw statistically significant insights from. This reflects a challenge with using economic data to forecast elections—there are only so many elections to draw data from and to use to train models, resulting in a lot of variance as we see with my linear regression models. Across all models, I had errors that could have totally changed the outcome of who wins the popular vote. How can we base a forecast on models that themselves cannot make a real prediction?\nIn future economic models, I hope to use more granular data (month-wise or quarter-wise) and involve polling data to track how opinions change along with measures of economic performance. This time, I only used bivariate linear regressions, but I will in the future include multiple independent variables and weigh them by polls of voters and how salient they are.\n##Sources##\n“Presidential Debates Do Matter | 538 Politics Podcast.” YouTube, uploaded by FiveThirtyEight, 9 Sept. 2024, www.youtube.com/watch?v=PkjfKF0frvs.\nData Provided by GOV 1347: Election Analytics teaching staff (which itself drew from the Burueau of Economic Analysia and Federal Reserve Economic Data)\n"},{"id":1,"href":"/2024election-blog/post/2024-09-09-week-1-past-presidential-elections/","title":"Week 1: Past Presidential Elections","section":"Posts","content":" Week 1: Past Presidential Elections # Monday, September 9, 2024\n56 Days until Presidential Election\nWelcome to my first week tracking and forecasting the 2024 US Presidential Election. The main purpose of this first post is to get acquainted with the process of analyzing basic election data. Every Monday, I will come back here to post increasingly more sophisticated and informed additions to my forecast. For now, I am relying on past election data to predict who will become the next president of the United States. What you will find in this post is a very rudimentary method of forecasting, given it is the first week, but it should not be wholly discounted. Arguably, the best way to predict the future is by looking to the past.\nA Note on Data-Driven Prophecies and Crystal Balls # Just last week, an article in Politico written by Stanford’s Justin Grimmer, cast doubt on the ability to forecast presidential elections in the first place (Grimmer 2024). He and his co-authors for the paper behind the article, Dean Knox and Sean Westwood, find that the accuracy of election forecasts is virtually untestable because it relies on probabilities to be played out. Say, for example, that a famous poll aggregator forecasted that Kamala Harris were to win the next election 45 out of 100 times. They make the point that we have not even seen 100 presidential elections as a country to test this finding and compare it to other models.\nThough I believe Grimmer, Knox, and Westwood to be overly pessimistic about the attention given to political forecasts, especially presidential ones, I will carry their skepticism with me as I build my models. There is value in mathematically evaluating how various data inputs could impact candidate success, but surely an overreliance on quantitative data will not be truly informative.\nCreating a Standard Style # # custom ggplot theme my_prettier_theme \u0026lt;- function() { theme( # no border panel.border = element_blank(), # background panel.background = element_rect(fill = \u0026#34;snow2\u0026#34;), # text plot.title = element_text(size = 15, hjust = .5, face = \u0026#34;bold\u0026#34;, family = \u0026#34;sans\u0026#34;), plot.subtitle = element_text(size = 13, hjust = .5, family = \u0026#34;sans\u0026#34;), plot.title.position = \u0026#34;panel\u0026#34;, axis.text.x = element_text(size = 8, angle = 45, hjust = .5, family = \u0026#34;sans\u0026#34;), axis.text.y = element_text(size = 8, family = \u0026#34;sans\u0026#34;), axis.title.x = element_text(family = \u0026#34;sans\u0026#34;), axis.title.y = element_text(angle = 90, family = \u0026#34;sans\u0026#34;), axis.ticks = element_line(colour = \u0026#34;black\u0026#34;), axis.line = element_line(colour = \u0026#34;grey\u0026#34;), # legend legend.position = \u0026#34;right\u0026#34;, legend.title = element_text(size = 12, family = \u0026#34;sans\u0026#34;), legend.text = element_text(size = 10, family = \u0026#34;sans\u0026#34;), # aspect ratio aspect.ratio = .8 ) } Before we move into content, I wanted to establish a standard style for my visualizations going forward. I choose sans serif font and relatively large size text for ease of reading.\nGuiding Questions for this Week # How competitive are presidential elections in the United States?\nWhich states vote blue/red and how consistently?\nTo answer these questions, let’s look at popular vote share and electoral college data from presidential elections between 1948 and 2020. Thank you to Matthew Dardet for cleaning and providing this data.\n####----------------------------------------------------------# #### Visualize trends in national presidential popular vote. ####----------------------------------------------------------# # Visualize the two-party presidential popular over time. two_party_visualization \u0026lt;- d_popvote |\u0026gt; ggplot(mapping = aes(x = year, y = pv2p, # look at two-party popular vote color = party)) + # color code by winning party geom_line() + geom_point() + # add points for each election scale_color_manual(\u0026#34;Party\u0026#34;, values = c(\u0026#34;steelblue3\u0026#34;, \u0026#34;tomato3\u0026#34;)) + labs(title = \u0026#34;Two Party Presidential Popular Over Time\u0026#34;, subtitle = \u0026#34;1948-2020\u0026#34;, x = \u0026#34;Year\u0026#34;, y = \u0026#34;Winning Popular Vote Share\u0026#34;) + my_prettier_theme() two_party_visualization ggsave (\u0026#34;figures/two_party_vis.png\u0026#34;) ## Saving 7 x 5 in image The above line chart helps visualize an answer to our question on the competitiveness of presidential elections in the United States. Broadly speaking, I would say that the presidential races are very competitive between the two main parties, Democrats and Republicans. The chart shows that no one party has a solidified dominance over the popular vote, though it is noteworthy that Democrats have won the popular vote for the past four elections. According to findings in Gallup from 2021, partisan identification with either Democrats or Republicans is relatively the same but independents remain the largest group of American voters, hinting their potential to sway elections differently each election (Jones 2022). Popular vote is not necessarily how candidates win the presidency, though, so let’s take a look at state and electoral vote data.\n####----------------------------------------------------------# #### State-by-state map of presidential popular votes. ####----------------------------------------------------------# # Sequester shapefile of states from `maps` library. states_map \u0026lt;- map_data(\u0026#34;state\u0026#34;) unique(states_map$region) ## [1] \u0026quot;alabama\u0026quot; \u0026quot;arizona\u0026quot; \u0026quot;arkansas\u0026quot; ## [4] \u0026quot;california\u0026quot; \u0026quot;colorado\u0026quot; \u0026quot;connecticut\u0026quot; ## [7] \u0026quot;delaware\u0026quot; \u0026quot;district of columbia\u0026quot; \u0026quot;florida\u0026quot; ## [10] \u0026quot;georgia\u0026quot; \u0026quot;idaho\u0026quot; \u0026quot;illinois\u0026quot; ## [13] \u0026quot;indiana\u0026quot; \u0026quot;iowa\u0026quot; \u0026quot;kansas\u0026quot; ## [16] \u0026quot;kentucky\u0026quot; \u0026quot;louisiana\u0026quot; \u0026quot;maine\u0026quot; ## [19] \u0026quot;maryland\u0026quot; \u0026quot;massachusetts\u0026quot; \u0026quot;michigan\u0026quot; ## [22] \u0026quot;minnesota\u0026quot; \u0026quot;mississippi\u0026quot; \u0026quot;missouri\u0026quot; ## [25] \u0026quot;montana\u0026quot; \u0026quot;nebraska\u0026quot; \u0026quot;nevada\u0026quot; ## [28] \u0026quot;new hampshire\u0026quot; \u0026quot;new jersey\u0026quot; \u0026quot;new mexico\u0026quot; ## [31] \u0026quot;new york\u0026quot; \u0026quot;north carolina\u0026quot; \u0026quot;north dakota\u0026quot; ## [34] \u0026quot;ohio\u0026quot; \u0026quot;oklahoma\u0026quot; \u0026quot;oregon\u0026quot; ## [37] \u0026quot;pennsylvania\u0026quot; \u0026quot;rhode island\u0026quot; \u0026quot;south carolina\u0026quot; ## [40] \u0026quot;south dakota\u0026quot; \u0026quot;tennessee\u0026quot; \u0026quot;texas\u0026quot; ## [43] \u0026quot;utah\u0026quot; \u0026quot;vermont\u0026quot; \u0026quot;virginia\u0026quot; ## [46] \u0026quot;washington\u0026quot; \u0026quot;west virginia\u0026quot; \u0026quot;wisconsin\u0026quot; ## [49] \u0026quot;wyoming\u0026quot; # Read wide version of dataset that can be used to compare candidate votes with one another. d_pvstate_wide \u0026lt;- read_csv(\u0026#34;clean_wide_state_2pv_1948_2020.csv\u0026#34;) ## Rows: 959 Columns: 14 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: \u0026quot;,\u0026quot; ## chr (1): state ## dbl (13): year, D_pv, R_pv, D_pv2p, R_pv2p, D_pv_lag1, R_pv_lag1, D_pv2p_lag... ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. # Merge d_pvstate_wide with state_map. d_pvstate_wide$region \u0026lt;- tolower(d_pvstate_wide$state) pv_map \u0026lt;- d_pvstate_wide |\u0026gt; filter(year == 2020) |\u0026gt; left_join(states_map, by = \u0026#34;region\u0026#34;) # Make map grid of state winners for each election year available in the dataset. pv_win_map \u0026lt;- pv_map |\u0026gt; mutate(winner = ifelse(R_pv \u0026gt; D_pv, \u0026#34;republican\u0026#34;, \u0026#34;democrat\u0026#34;)) pv_win_map |\u0026gt; ggplot(aes(long, lat, group = group)) + geom_polygon(aes(fill = winner), color = \u0026#34;black\u0026#34;) + scale_fill_manual(values = c(\u0026#34;steelblue\u0026#34;, \u0026#34;tomato3\u0026#34;)) + theme_void() + labs(title = \u0026#34;Map Grid of State Winners\u0026#34;, subtitle = \u0026#34;2020 Election\u0026#34;) + my_prettier_theme() + theme(axis.title.x= element_blank(), axis.title.y= element_blank(), axis.text.x= element_blank(), axis.text.y= element_blank(), axis.ticks = element_blank(), axis.line= element_blank()) ggsave (\u0026#34;figures/PV_win_map.png\u0026#34;) ## Saving 7 x 5 in image Here, I have coded which candidate won in each state during the 2020 election between President Joe Biden and President Donald Trump. Democrats did very well along the coasts and Republicans the midwest and South with the notable exception of Georgia. Throughout this blog, I will draw consistent attention onto Georgia because it is my home state and I find its political behavior interesting.\nd_pvstate_wide |\u0026gt; filter(year \u0026gt;= 1980) |\u0026gt; left_join(states_map, by = \u0026#34;region\u0026#34;) |\u0026gt; mutate(winner = ifelse(R_pv2p\u0026gt;D_pv2p, \u0026#34;republican\u0026#34;, \u0026#34;democrat\u0026#34;)) |\u0026gt; ggplot(aes(long, lat, group = group)) + facet_wrap(facets = year ~.) + geom_polygon(aes(fill = winner), color = \u0026#34;white\u0026#34;)+ scale_fill_manual(values = c(\u0026#34;steelblue\u0026#34;, \u0026#34;tomato3\u0026#34;)) + labs(title = \u0026#34;Presidential Vote Share by State\u0026#34;, subtitle = \u0026#34;1980-2020\u0026#34;) + theme(strip.text = element_text(size = 12), aspect.ratio = 1) + my_prettier_theme() + theme(axis.title.x= element_blank(), axis.title.y= element_blank(), axis.text.x= element_blank(), axis.text.y= element_blank(), axis.ticks = element_blank(), axis.line= element_blank()) ggsave (\u0026#34;figures/PV_states_historical.png\u0026#34;) ## Saving 7 x 5 in image Placing the last map in context, we can see how certain states have either shifted parties (in the sense of having a preference for one party over another) or flip-flopped between elections over time. Something that sticks out to me is that California had pretty consistently voted Republican until 1992 when it firmly switched Democrat. New York has cast its electoral votes for Democrats for all elections in this period except 1984. Certain regions like the Midwest are solidly Republican from 1980 to 2020 and states like Texas, Alabama, Mississippi, South Carolina are firmly red. It appears that in the past few elections most states vote for a single party pretty consistently, but there exist certain states that swing either way.\n####----------------------------------------------------------# #### Forecast: simplified electoral cycle model. ####----------------------------------------------------------# # Create prediction (pv2p and margin) based on simplified electoral cycle model: # vote_2024 = 3/4*vote_2020 + 1/4*vote_2016 (lag1, lag2, respectively). pv2p_2024_states \u0026lt;- d_pvstate_wide |\u0026gt; filter(year == 2020) |\u0026gt; group_by(state)|\u0026gt; summarize(R_pv2p_2024 = .75*R_pv2p + .25*R_pv2p_lag1, D_pv2p_2024 = .75*D_pv2p + .25*D_pv2p_lag1) |\u0026gt; mutate(pv2p_2024_margin = R_pv2p_2024 - D_pv2p_2024, winner = ifelse(R_pv2p_2024 \u0026gt; D_pv2p_2024, \u0026#34;R\u0026#34;, \u0026#34;D\u0026#34;), region = tolower(state)) pv2p_2024_states_2 \u0026lt;- pv2p_2024_states # Plot the margin of victory in a U.S. state map. states_map \u0026lt;- map_data(\u0026#34;state\u0026#34;) state_mapa \u0026lt;- pv2p_2024_states |\u0026gt; left_join(states_map, by = \u0026#34;region\u0026#34;) state_centers \u0026lt;- data.frame(state.center, state.abb, state.name) state_mapa \u0026lt;- state_mapa |\u0026gt; ggplot(aes(long, lat, group = group)) + geom_polygon(aes(fill = pv2p_2024_margin), color = \u0026#34;black\u0026#34;)+ scale_fill_gradient2(high = \u0026#34;tomato3\u0026#34;, low = \u0026#34;steelblue3\u0026#34;, mid = \u0026#34;white\u0026#34;, name = \u0026#34;Two-Party Win Margin\u0026#34;, breaks = c(-50, -25, 0, 25, 50), limits = c(-50,50)) + labs(title = \u0026#34;2024 Presidential Forecast\u0026#34;, subtitle = \u0026#34;Simplified Electoral Cycle Model\u0026#34;) + my_prettier_theme() + theme(axis.title.x= element_blank(), axis.title.y= element_blank(), axis.text.x= element_blank(), axis.text.y= element_blank(), axis.ticks = element_blank(), axis.line= element_blank()) state_mapa ggsave(\u0026#34;figures/PV2024_simple_forecast.png\u0026#34;) ## Saving 7 x 5 in image For the above map, we rely on a very basic mathematical model to predict the outcome of the upcoming election. It works as a such: in a given state, we can find the popular vote in the 2024 election by \\(vote_{2024} = \\frac{3}{4}*vote_{2020} + \\frac{1}{4}*vote_{2016}\\). From there, we can color code each state on a gradient, which relies on the projected win margin for the two main parties. We find that states that are consistently red or blue tend to stay that way. The battleground states, which are those closest to white, are Pennsylvania, Georgia, Wisconsin, North Carolina, Nevada, and Arizona. This falls in line with generally accepted knowledge about the political behavior in these states. One thing that surprised me though was how close Texas is to being a battleground state based on this projection.\n####----------------------------------------------------------# #### Extension 1: Add state labels ####----------------------------------------------------------# # Rename ggplot state data region variable to state for ease states_map \u0026lt;- map_data(\u0026#34;state\u0026#34;) |\u0026gt; rename(state = region) # Transform state boundaries into an sf object states_sf \u0026lt;- st_as_sf(states_map, coords = c(\u0026#34;long\u0026#34;, \u0026#34;lat\u0026#34;), crs = 4326, agr = \u0026#34;constant\u0026#34;) # Create a geometry for each state states_sf \u0026lt;- states_sf |\u0026gt; group_by(state) |\u0026gt; summarize(geometry = st_combine(geometry)) |\u0026gt; st_cast(\u0026#34;POLYGON\u0026#34;) |\u0026gt; st_make_valid() # Merge with your election results data pv2p_2024_states \u0026lt;- pv2p_2024_states |\u0026gt; mutate(state = tolower(state)) # Merge state polygons with 2024 vote margin data states_sf \u0026lt;- left_join(states_sf, pv2p_2024_states, by = \u0026#34;state\u0026#34;) # Create an interactive map with leaflet interactive_map \u0026lt;- leaflet(states_sf) |\u0026gt; addTiles() |\u0026gt; addPolygons( fillColor = ~colorBin(palette = c(\u0026#34;steelblue3\u0026#34;, \u0026#34;white\u0026#34;, \u0026#34;tomato3\u0026#34;), domain = states_sf$pv2p_2024_margin, bins = c(-50, -25, 0, 25, 50))(pv2p_2024_margin), fillOpacity = 0.7, color = \u0026#34;black\u0026#34;, weight = 1, highlight = highlightOptions( weight = 3, color = \u0026#34;#666\u0026#34;, fillOpacity = 0.7, bringToFront = TRUE ), label = ~paste(str_to_title(state), \u0026#34; Win Margin: \u0026#34;, round(pv2p_2024_margin,2)), labelOptions = labelOptions( style = list(\u0026#34;font-weight\u0026#34; = \u0026#34;normal\u0026#34;, padding = \u0026#34;5px 10px\u0026#34;), textsize = \u0026#34;15px\u0026#34;, direction = \u0026#34;auto\u0026#34; ) ) |\u0026gt; addLegend( pal = colorBin(palette = c(\u0026#34;steelblue3\u0026#34;, \u0026#34;white\u0026#34;, \u0026#34;tomato3\u0026#34;), domain = states_sf$pv2p_2024_margin, bins = c(-50, -25, 0, 25, 50)), values = ~pv2p_2024_margin, opacity = 0.7, title = \u0026#34;Two-Party Win Margin (%)\u0026#34;, position = \u0026#34;bottomleft\u0026#34; ) |\u0026gt; addControl( html = \u0026#34;\u0026lt;h3 style=\u0026#39;color: black; text-align: center;\u0026#39;\u0026gt;2024 Presidential Forecast\u0026lt;/h3\u0026gt;\u0026lt;h5\u0026gt;Simplified Electoral Cycle Model\u0026lt;/h5\u0026gt;\u0026#34;, position = \u0026#34;topright\u0026#34;, className = \u0026#34;map-title\u0026#34;) ## Warning in colorBin(palette = c(\u0026quot;steelblue3\u0026quot;, \u0026quot;white\u0026quot;, \u0026quot;tomato3\u0026quot;), domain = ## states_sf$pv2p_2024_margin, : Some values were outside the color scale and will ## be treated as NA interactive_map If you are unfamiliar with American geography, here is an interactive version of the same map, where you can see state labels and what notable cities are in each state.\n# Generate projected state winners and merge with electoral college votes to make # summary of electoral college vote distributions. ec \u0026lt;- read_csv(\u0026#34;ec_full.csv\u0026#34;) ## Rows: 1010 Columns: 4 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: \u0026quot;,\u0026quot; ## chr (2): state, stateab ## dbl (2): year, electors ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. pv2p_2024_states_2 \u0026lt;- pv2p_2024_states_2 |\u0026gt; mutate(year = 2024)|\u0026gt; left_join(ec, by = c(\u0026#34;state\u0026#34;, \u0026#34;year\u0026#34;)) projected_electoral_winner \u0026lt;- pv2p_2024_states_2 |\u0026gt; group_by(winner)|\u0026gt; summarize(electoral_votes = sum(electors)) projected_electoral_winner ## # A tibble: 2 × 2 ## winner electoral_votes ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; ## 1 D 276 ## 2 R 262 Harris: 276 # Trump: 262 # Using the formula we drew on before, we can determine which states will (by this model) cast their electoral votes for Democrats and which will for Republicans. Then, we tally up the totals and find that Democrats pass the threshold of 270 to win the office. Based on this very rudimentary model, Kamala Harris is projected to be the next president of the United States.\nYou can find my code for this entry by clicking on the Github link to the right. Please reach out if you encounter any errors.\nSources # Grimmer, Justin. “Don’t Trust the Election Forecasts.” POLITICO, POLITICO, 3 Sept. 2024, www.politico.com/news/magazine/2024/09/03/election-forecasts-data-00176905.\nJones, Jeffrey M. “U.S. Political Party Preferences Shifted Greatly During 2021.” Gallup, 17 Jan. 2022, https://news.gallup.com/poll/388781/political-party-preferences-shifted-greatly-during-2021.aspx.\nData Provided by GOV 1347: Election Analytics teaching staff.\n"}]