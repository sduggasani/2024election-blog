[{"id":0,"href":"/2024election-blog/post/2024-10-12-week-6-campaign-spending/","title":"Week 6: Campaign Expenditure","section":"Posts","content":" Week 6: Campaign Expenditure # Monday, October 14, 2024\n21 Days until Presidential Election\nWe are now less than a month away from election day! It means a lot that you\u0026rsquo;ve followed along this far. Thank you! This week, we will be considering how campaign advertisement expenditure can play a role in election outcomes. In the 2020 Presidential Elections, I remember one day receiving over 20 campaign flyers and virtually the only ads aired on television being political. I thought that, if forecasters could take a metric of campaign mail count in my suburban Atlanta district, they\u0026rsquo;d probably have a more accurate model. I cannot monitor the ads in Georgia as closely as I did in the last election because I\u0026rsquo;m in college now, but I hope to at least involve available data on campaign ad expenditure into my model.\nCampaign Ads and Messaging # Above, we see a chart presenting the tone of campaign ads by party and by election cycle. We see that across cycles, Democrats tend to not make the majority of their ads with an attacking tone, but in 2004 and 2012, Republicans did just that. Overall, there is no clear trend as to the tone of campaign ads over time, and I would argue that it depends heavily on the candidates running and their style of campaigning.\nWe also see a visualization of of the purpose of campaign ads by party and by presidential election year. Most of the time, we see that policy ads are the most common across parties and across cycles, except for ads by Democrats in 2016. Across most election cycles, it seems that Democrats field more personal ads than Republicans, and this difference can be marginal or staggering like it was in 2016.\nHere, we can take a look at the issues most frequently mentioned in campaign ads across elections from 2000-2012. In addition to there being more ads in general as time goes on, we see a notable changed in the issues that are mentioned in ads between cycles. The one issue that stays across all cycles is taxes and jobs/employment seems pretty sticky as well.\nGoing into the party split for campaign ads for 2000 and 2012, we see notable differences in the topics for which parties choose to air ads. One thing I find interesting is that, in 2000, Democrats did not touch homosexuality as a topic for campaign ads, and Republicans wre the only ones to air ads on the issue, presumably against it. By 2012, more Democratic ads on homosexuality appeared and the name of the issue changed to a split between Moral/Family/Religious values (for which there were more Republican ads) and Homosexuality/Gay \u0026amp; Lesbian Rights.\nThose issues which both parties pretty evenly air ads on are also very similar to the issues observed in the first plot, which shows the most frequently mentioned issues in campaign ads regardless of party and across election cycles. Taxes, healthcare, and deficit are among them.\nCampaign Expenditure Model # Model 1 Model 2 (Intercept) 46.808 −23.093 (0.771) (7.160) contribution_receipt_amount 0.0000002 (3e−08) log(contribution_receipt_amount) 4.659 (0.460) Num.Obs. 200 200 R2 0.168 0.341 R2 Adj. 0.163 0.338 AIC 1476.7 1430.1 BIC 1486.6 1439.9 Log.Lik. −735.367 −712.027 F 39.886 102.423 RMSE 9.56 8.51 The model summary we see here is a linear regression for Democratic campaign spending and the Democratic two-party vote share. Model 1 refers to treating campaign expenditure as an unmodified variable while Model 2 applies a log transformation to better understand the relationship between the two variables. We see that, in the context of this linear regression, campaign expenditure for Democrats has a positive impact on their two party vote share. This motivates my inclusion of campaign expenditure data into the model I use to predict the outcome of the 2024 elections.\nBayesianism # ## Trying to compile a simple C file ## Running /Library/Frameworks/R.framework/Resources/bin/R CMD SHLIB foo.c ## clang -mmacosx-version-min=10.13 -I\u0026#34;/Library/Frameworks/R.framework/Resources/include\u0026#34; -DNDEBUG -I\u0026#34;/Users/sammy/Library/R/x86_64/4.2/library/Rcpp/include/\u0026#34; -I\u0026#34;/Users/sammy/Library/R/x86_64/4.2/library/RcppEigen/include/\u0026#34; -I\u0026#34;/Users/sammy/Library/R/x86_64/4.2/library/RcppEigen/include/unsupported\u0026#34; -I\u0026#34;/Library/Frameworks/R.framework/Versions/4.2/Resources/library/BH/include\u0026#34; -I\u0026#34;/Users/sammy/Library/R/x86_64/4.2/library/StanHeaders/include/src/\u0026#34; -I\u0026#34;/Users/sammy/Library/R/x86_64/4.2/library/StanHeaders/include/\u0026#34; -I\u0026#34;/Users/sammy/Library/R/x86_64/4.2/library/RcppParallel/include/\u0026#34; -I\u0026#34;/Users/sammy/Library/R/x86_64/4.2/library/rstan/include\u0026#34; -DEIGEN_NO_DEBUG -DBOOST_DISABLE_ASSERTS -DBOOST_PENDING_INTEGER_LOG2_HPP -DSTAN_THREADS -DUSE_STANC3 -DSTRICT_R_HEADERS -DBOOST_PHOENIX_NO_VARIADIC_EXPRESSION -D_HAS_AUTO_PTR_ETC=0 -include \u0026#39;/Users/sammy/Library/R/x86_64/4.2/library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp\u0026#39; -D_REENTRANT -DRCPP_PARALLEL_USE_TBB=1 -I/usr/local/include -fPIC -Wall -g -O2 -c foo.c -o foo.o ## In file included from \u0026lt;built-in\u0026gt;:1: ## In file included from /Users/sammy/Library/R/x86_64/4.2/library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp:22: ## In file included from /Users/sammy/Library/R/x86_64/4.2/library/RcppEigen/include/Eigen/Dense:1: ## In file included from /Users/sammy/Library/R/x86_64/4.2/library/RcppEigen/include/Eigen/Core:88: ## /Users/sammy/Library/R/x86_64/4.2/library/RcppEigen/include/Eigen/src/Core/util/Macros.h:628:1: error: unknown type name \u0026#39;namespace\u0026#39; ## namespace Eigen { ## ^ ## /Users/sammy/Library/R/x86_64/4.2/library/RcppEigen/include/Eigen/src/Core/util/Macros.h:628:16: error: expected \u0026#39;;\u0026#39; after top level declarator ## namespace Eigen { ## ^ ## ; ## In file included from \u0026lt;built-in\u0026gt;:1: ## In file included from /Users/sammy/Library/R/x86_64/4.2/library/StanHeaders/include/stan/math/prim/fun/Eigen.hpp:22: ## In file included from /Users/sammy/Library/R/x86_64/4.2/library/RcppEigen/include/Eigen/Dense:1: ## /Users/sammy/Library/R/x86_64/4.2/library/RcppEigen/include/Eigen/Core:96:10: fatal error: \u0026#39;complex\u0026#39; file not found ## #include \u0026lt;complex\u0026gt; ## ^~~~~~~~~ ## 3 errors generated. ## make: *** [foo.o] Error 1 ## ## SAMPLING FOR MODEL \u0026#39;anon_model\u0026#39; NOW (CHAIN 1). ## Chain 1: ## Chain 1: Gradient evaluation took 0.00012 seconds ## Chain 1: 1000 transitions using 10 leapfrog steps per transition would take 1.2 seconds. ## Chain 1: Adjust your expectations accordingly! ## Chain 1: ## Chain 1: ## Chain 1: Iteration: 1 / 4000 [ 0%] (Warmup) ## Chain 1: Iteration: 400 / 4000 [ 10%] (Warmup) ## Chain 1: Iteration: 800 / 4000 [ 20%] (Warmup) ## Chain 1: Iteration: 1001 / 4000 [ 25%] (Sampling) ## Chain 1: Iteration: 1400 / 4000 [ 35%] (Sampling) ## Chain 1: Iteration: 1800 / 4000 [ 45%] (Sampling) ## Chain 1: Iteration: 2200 / 4000 [ 55%] (Sampling) ## Chain 1: Iteration: 2600 / 4000 [ 65%] (Sampling) ## Chain 1: Iteration: 3000 / 4000 [ 75%] (Sampling) ## Chain 1: Iteration: 3400 / 4000 [ 85%] (Sampling) ## Chain 1: Iteration: 3800 / 4000 [ 95%] (Sampling) ## Chain 1: Iteration: 4000 / 4000 [100%] (Sampling) ## Chain 1: ## Chain 1: Elapsed Time: 1.543 seconds (Warm-up) ## Chain 1: 4.306 seconds (Sampling) ## Chain 1: 5.849 seconds (Total) ## Chain 1: ## ## SAMPLING FOR MODEL \u0026#39;anon_model\u0026#39; NOW (CHAIN 2). ## Chain 2: ## Chain 2: Gradient evaluation took 1.7e-05 seconds ## Chain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.17 seconds. ## Chain 2: Adjust your expectations accordingly! ## Chain 2: ## Chain 2: ## Chain 2: Iteration: 1 / 4000 [ 0%] (Warmup) ## Chain 2: Iteration: 400 / 4000 [ 10%] (Warmup) ## Chain 2: Iteration: 800 / 4000 [ 20%] (Warmup) ## Chain 2: Iteration: 1001 / 4000 [ 25%] (Sampling) ## Chain 2: Iteration: 1400 / 4000 [ 35%] (Sampling) ## Chain 2: Iteration: 1800 / 4000 [ 45%] (Sampling) ## Chain 2: Iteration: 2200 / 4000 [ 55%] (Sampling) ## Chain 2: Iteration: 2600 / 4000 [ 65%] (Sampling) ## Chain 2: Iteration: 3000 / 4000 [ 75%] (Sampling) ## Chain 2: Iteration: 3400 / 4000 [ 85%] (Sampling) ## Chain 2: Iteration: 3800 / 4000 [ 95%] (Sampling) ## Chain 2: Iteration: 4000 / 4000 [100%] (Sampling) ## Chain 2: ## Chain 2: Elapsed Time: 1.338 seconds (Warm-up) ## Chain 2: 4.217 seconds (Sampling) ## Chain 2: 5.555 seconds (Total) ## Chain 2: ## ## SAMPLING FOR MODEL \u0026#39;anon_model\u0026#39; NOW (CHAIN 3). ## Chain 3: ## Chain 3: Gradient evaluation took 1.5e-05 seconds ## Chain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.15 seconds. ## Chain 3: Adjust your expectations accordingly! ## Chain 3: ## Chain 3: ## Chain 3: Iteration: 1 / 4000 [ 0%] (Warmup) ## Chain 3: Iteration: 400 / 4000 [ 10%] (Warmup) ## Chain 3: Iteration: 800 / 4000 [ 20%] (Warmup) ## Chain 3: Iteration: 1001 / 4000 [ 25%] (Sampling) ## Chain 3: Iteration: 1400 / 4000 [ 35%] (Sampling) ## Chain 3: Iteration: 1800 / 4000 [ 45%] (Sampling) ## Chain 3: Iteration: 2200 / 4000 [ 55%] (Sampling) ## Chain 3: Iteration: 2600 / 4000 [ 65%] (Sampling) ## Chain 3: Iteration: 3000 / 4000 [ 75%] (Sampling) ## Chain 3: Iteration: 3400 / 4000 [ 85%] (Sampling) ## Chain 3: Iteration: 3800 / 4000 [ 95%] (Sampling) ## Chain 3: Iteration: 4000 / 4000 [100%] (Sampling) ## Chain 3: ## Chain 3: Elapsed Time: 1.4 seconds (Warm-up) ## Chain 3: 4.394 seconds (Sampling) ## Chain 3: 5.794 seconds (Total) ## Chain 3: ## ## SAMPLING FOR MODEL \u0026#39;anon_model\u0026#39; NOW (CHAIN 4). ## Chain 4: ## Chain 4: Gradient evaluation took 1.8e-05 seconds ## Chain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.18 seconds. ## Chain 4: Adjust your expectations accordingly! ## Chain 4: ## Chain 4: ## Chain 4: Iteration: 1 / 4000 [ 0%] (Warmup) ## Chain 4: Iteration: 400 / 4000 [ 10%] (Warmup) ## Chain 4: Iteration: 800 / 4000 [ 20%] (Warmup) ## Chain 4: Iteration: 1001 / 4000 [ 25%] (Sampling) ## Chain 4: Iteration: 1400 / 4000 [ 35%] (Sampling) ## Chain 4: Iteration: 1800 / 4000 [ 45%] (Sampling) ## Chain 4: Iteration: 2200 / 4000 [ 55%] (Sampling) ## Chain 4: Iteration: 2600 / 4000 [ 65%] (Sampling) ## Chain 4: Iteration: 3000 / 4000 [ 75%] (Sampling) ## Chain 4: Iteration: 3400 / 4000 [ 85%] (Sampling) ## Chain 4: Iteration: 3800 / 4000 [ 95%] (Sampling) ## Chain 4: Iteration: 4000 / 4000 [100%] (Sampling) ## Chain 4: ## Chain 4: Elapsed Time: 1.4 seconds (Warm-up) ## Chain 4: 4.348 seconds (Sampling) ## Chain 4: 5.748 seconds (Total) ## Chain 4: ## ## Call: ## lm(formula = D_pv2p ~ latest_pollav_DEM + mean_pollav_DEM + D_pv2p_lag1 + ## D_pv2p_lag2, data = d.train) ## ## Residuals: ## Min 1Q Median 3Q Max ## -10.4485 -2.0088 -0.4128 1.7700 9.8659 ## ## Coefficients: ## Estimate Std. Error t value Pr(\u0026gt;|t|) ## (Intercept) 9.03700 1.84335 4.902 1.97e-06 *** ## latest_pollav_DEM 0.88022 0.08197 10.739 \u0026lt; 2e-16 *** ## mean_pollav_DEM -0.27845 0.07428 -3.749 0.000233 *** ## D_pv2p_lag1 0.44393 0.04578 9.698 \u0026lt; 2e-16 *** ## D_pv2p_lag2 -0.17487 0.03974 -4.400 1.77e-05 *** ## --- ## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1 ## ## Residual standard error: 3.383 on 197 degrees of freedom ## Multiple R-squared: 0.7767,\tAdjusted R-squared: 0.7722 ## F-statistic: 171.3 on 4 and 197 DF, p-value: \u0026lt; 2.2e-16 ## Inference for Stan model: anon_model. ## 4 chains, each with iter=4000; warmup=1000; thin=1; ## post-warmup draws per chain=3000, total post-warmup draws=12000. ## ## mean se_mean sd 2.5% 25% 50% 75% 97.5% n_eff Rhat ## alpha 9.09 0.02 1.88 5.38 7.83 9.09 10.36 12.73 7851 1 ## beta1 0.88 0.00 0.08 0.72 0.82 0.88 0.94 1.04 6238 1 ## beta2 -0.28 0.00 0.08 -0.43 -0.33 -0.28 -0.23 -0.13 6801 1 ## beta3 0.44 0.00 0.05 0.35 0.41 0.44 0.47 0.53 7053 1 ## beta4 -0.17 0.00 0.04 -0.25 -0.20 -0.17 -0.15 -0.10 8151 1 ## sigma 3.40 0.00 0.17 3.09 3.28 3.40 3.51 3.77 8252 1 ## ## Samples were drawn using NUTS(diag_e) at Tue Oct 15 13:40:20 2024. ## For each parameter, n_eff is a crude measure of effective sample size, ## and Rhat is the potential scale reduction factor on split chains (at ## convergence, Rhat=1). Using code provided by Matthew Dardet, I experiment with the use of a Bayesian model as opposed to the frequentist models I have been constructing thus far. In essence, a Bayesian model is one that adjusts its predictions with the addition of new information; in this case, the information we take in is new polling data. If you compare the summary statistics between the frequentist (linear regression) model and the Bayesian model, you cannot find much of a difference between the coefficients (to compare coefficients, go row by row where alpha is the intercept, beta1 is latest_pollav_DEM, etc.). FiveThirtyEight uses Bayesian updating to adjust for changes in the lean of certain polls (see: https://fivethirtyeight.com/methodology/how-our-polling-averages-work/). One objection to the use of Bayesian inference is that the reliance on the idea of prior and posterior knowledge obfuscates what we know to be objective and thus makes the analysis drawn from Bayesian models dubious (counterarguments presented and refuted in Andrew Gelman\u0026rsquo;s http://www.stat.columbia.edu/~gelman/research/published/badbayesmain.pdf). In light of this, I will use a frequentist model for the rest of this week but continue to play around with Bayesianism.\nUpdating Model Predictions # ## `summarise()` has grouped output by \u0026#39;state\u0026#39;. You can override using the ## `.groups` argument. ## Warning: Option grouped=FALSE enforced in cv.glmnet, since \u0026lt; 3 observations per ## fold state electors winner Alabama 9 Republican Alaska 3 Republican Arizona 11 Republican Arkansas 6 Republican California 54 Democrat Colorado 10 Democrat Connecticut 7 Democrat Delaware 3 Democrat District Of Columbia 3 Democrat Florida 30 Republican Georgia 16 Republican Hawaii 4 Democrat Idaho 4 Republican Illinois 19 Democrat Indiana 11 Republican Iowa 6 Republican Kansas 6 Republican Kentucky 8 Republican Louisiana 8 Republican Maine 4 Democrat Maryland 10 Democrat Massachusetts 11 Democrat Michigan 15 Democrat Minnesota 10 Democrat Mississippi 6 Republican Missouri 10 Republican Montana 4 Republican Nebraska 5 Republican Nevada 6 Democrat New Hampshire 4 Democrat New Jersey 14 Democrat New Mexico 5 Democrat New York 28 Democrat North Carolina 16 Republican North Dakota 3 Republican Ohio 17 Republican Oklahoma 7 Republican Oregon 8 Democrat Pennsylvania 19 Democrat Rhode Island 4 Democrat South Carolina 9 Republican South Dakota 3 Republican Tennessee 11 Republican Texas 40 Republican Utah 6 Republican Vermont 3 Republican Virginia 13 Democrat Washington 12 Democrat West Virginia 4 Republican Wisconsin 10 Democrat Wyoming 3 Republican winner electoral_votes Democrat 273 Republican 265 To update this week\u0026rsquo;s model, I involved campaign expenditure data alongside economic fundamentals and polling data. Campaign expenditure data is taken for Democrats only because the model predicts for Democrats and calculates Republican by subtracting Democratic vote share from 100. The last model individually predicted each party\u0026rsquo;s vote share, which made it difficult to really see who was ahead.\nI, then, regularize the model, using LASSO which is a machine learning model that selects relevant features and neutralizes features that are not. This was helpful to making election results appear more realistic. The final results of this model show an incredibly close race with Harris winning over Trump by just 8 electoral votes. The model forecasts that Trump will take Arizona, Georgia, and North Carolina while Harris takes Pennsylvania, Nevada, and Michigan. This presents a pretty even split among swing states between the two candidates.\nConclusion # According to this week\u0026rsquo;s models, Harris will win the 2024 Presidential Election, taking 273 electoral votes.\nIn comparison to last week\u0026rsquo;s model, this week presents a much closer race between Harris and Trump, which I believe will be the case. I made an effort to regularize my model this week, which I did not last week, and I think that is mainly why this week\u0026rsquo;s model presents a much much tighter margin. I will continue to regualarize my models going forward as a result. The involvement of campaign expenditure seems to advantage Democrats in this race, which would make sense considering Harris has raked in $1 billion since entering the race (Goldmacher \u0026amp; Haberman).\nSources # Goldmacher, Shane and Maggie Haberman. \u0026ldquo;Harris Raises $1 Billion, Cementing Status as Fundraising Powerhouse.\u0026rdquo; The New York Times, 9 Oct. 2024, www.nytimes.com/2024/10/09/us/politics/harris-billion-dollar-fundraising.html.\nGelman, Andrew. Why We (Usually) Don’t Have to Worry About Multiple Comparisons. Columbia University, www.stat.columbia.edu/~gelman/research/published/badbayesmain.pdf.\nMorris, G. Elliot \u0026ldquo;How Our Polling Averages Work.\u0026rdquo; FiveThirtyEight, 18 Aug. 2020, fivethirtyeight.com/methodology/how-our-polling-averages-work/.\nPolling Data Provided by GOV 1347: Election Analytics teaching staff (which itself drew from the FiveThirtyEight GitHub)\nEconomic Data Provided by GOV 1347: Election Analytics teaching staff (which itself drew from the Burueau of Economic Analysia and Federal Reserve Economic Data)\n"},{"id":1,"href":"/2024election-blog/post/2024-10-05-week-5-demographics/","title":"Week 5: Demographics","section":"Posts","content":" Week 5: Demographics # Monday, October 7, 2024\n28 Days until Presidential Election\nWelcome back! This week I will focus on demographic data and the role it plays in forecasting. Since last week, the vice presidential candidates faced off in a relatively calm and respectful debate. Again, a principal topic was that of immigration, which, in addition to being incredibly polarizing, often falls to identity-based arguments and concerns over the makeup of the United States demographically. Demographic shifts in race, educational attainment, and income distribution are an undercurrent to many political debates at the community level up to the national level. How identity can affect electoral politics is an incredibly large academic theme within the field of political science. In this post, I will touch on a seminal paper by Kim and Zilinsky (2024), which contributes to the question of if demographics motivate vote choice. I will then move into analyzing the demographics of my own state and a significant battleground state: Georgia. I will end by running simulations of my own model to quantify uncertainty in my own prediction and to visualize what that final prediction looks like as of now.\nDemographic Indicators and Vote Choice # ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading Model 1 (Intercept) 1.697 (0.112) age 0.001 (0.0008) gender −0.348 (0.030) race −0.496 (0.020) educ 0.021 (0.016) income 0.104 (0.012) religion −0.221 (0.014) attend_church −0.121 (0.009) southern −0.137 (0.032) work_status 0.065 (0.013) homeowner −0.0007 (0.006) married −0.071 (0.009) Num.Obs. 21726 AIC 27961.6 BIC 28057.4 Log.Lik. −13968.797 RMSE 0.47 ## Confusion Matrix and Statistics ## ## Reference ## Prediction Democrat Republican ## Democrat 8082 3961 ## Republican 3704 5979 ## ## Accuracy : 0.6472 ## 95% CI : (0.6408, 0.6536) ## No Information Rate : 0.5425 ## P-Value [Acc \u0026gt; NIR] : \u0026lt; 2.2e-16 ## ## Kappa : 0.2878 ## ## Mcnemar\u0026#39;s Test P-Value : 0.003455 ## ## Sensitivity : 0.6857 ## Specificity : 0.6015 ## Pos Pred Value : 0.6711 ## Neg Pred Value : 0.6175 ## Prevalence : 0.5425 ## Detection Rate : 0.3720 ## Detection Prevalence : 0.5543 ## Balanced Accuracy : 0.6436 ## ## \u0026#39;Positive\u0026#39; Class : Democrat ## ## Warning in predict.lm(object, newdata, se.fit, scale = 1, type = if (type == : ## prediction from a rank-deficient fit may be misleading ## Confusion Matrix and Statistics ## ## Reference ## Prediction Democrat Republican ## Democrat 1973 975 ## Republican 973 1509 ## ## Accuracy : 0.6413 ## 95% CI : (0.6283, 0.654) ## No Information Rate : 0.5425 ## P-Value [Acc \u0026gt; NIR] : \u0026lt;2e-16 ## ## Kappa : 0.2772 ## ## Mcnemar\u0026#39;s Test P-Value : 0.9819 ## ## Sensitivity : 0.6697 ## Specificity : 0.6075 ## Pos Pred Value : 0.6693 ## Neg Pred Value : 0.6080 ## Prevalence : 0.5425 ## Detection Rate : 0.3634 ## Detection Prevalence : 0.5429 ## Balanced Accuracy : 0.6386 ## ## \u0026#39;Positive\u0026#39; Class : Democrat ## The above figures are a result of using a logistic regression that involves demographics to predict presidential vote choice. Much of this code can be attributed to Matthew Dardet, but instead of just looking at how well demographics predicted vote choice in 1964, I included all years including and thereafter. The demographics we involve are age, gender, race, education level, income, religion, whether the voter attends church, whether the voter is from a southern state, work status, home-owning status, and marriage status. The model summary above shows that gender and race have by far the most sway on a voter\u0026rsquo;s choice among these demographics. What I find interesting is that age does not really have that much of an impact on vote choice as compared to other demographics. This work is a replication of the original work of Kim and Zilinsky (2024). Similar to their paper\u0026rsquo;s most notable finding, this replication finds that these key demographics can only predict the vote choice accurately about 64% of the time. Given the reliance of popular media and conventional wisdom on identity politics, it would seem that demographics would play a huge role in vote choice, and they are certainly not negligible. But key demographics are not as determinative as we might have thought.\n## Confusion Matrix and Statistics ## ## Reference ## Prediction Democrat Republican ## Democrat 7926 3091 ## Republican 3860 6849 ## ## Accuracy : 0.6801 ## 95% CI : (0.6738, 0.6863) ## No Information Rate : 0.5425 ## P-Value [Acc \u0026gt; NIR] : \u0026lt; 2.2e-16 ## ## Kappa : 0.3593 ## ## Mcnemar\u0026#39;s Test P-Value : \u0026lt; 2.2e-16 ## ## Sensitivity : 0.6725 ## Specificity : 0.6890 ## Pos Pred Value : 0.7194 ## Neg Pred Value : 0.6396 ## Prevalence : 0.5425 ## Detection Rate : 0.3648 ## Detection Prevalence : 0.5071 ## Balanced Accuracy : 0.6808 ## ## \u0026#39;Positive\u0026#39; Class : Democrat ## ## Confusion Matrix and Statistics ## ## Reference ## Prediction Democrat Republican ## Democrat 1951 728 ## Republican 995 1756 ## ## Accuracy : 0.6827 ## 95% CI : (0.6701, 0.6951) ## No Information Rate : 0.5425 ## P-Value [Acc \u0026gt; NIR] : \u0026lt; 2.2e-16 ## ## Kappa : 0.3661 ## ## Mcnemar\u0026#39;s Test P-Value : 1.472e-10 ## ## Sensitivity : 0.6623 ## Specificity : 0.7069 ## Pos Pred Value : 0.7283 ## Neg Pred Value : 0.6383 ## Prevalence : 0.5425 ## Detection Rate : 0.3593 ## Detection Prevalence : 0.4934 ## Balanced Accuracy : 0.6846 ## ## \u0026#39;Positive\u0026#39; Class : Democrat ## Here, instead of relying on a logistic regression, we employ a Random Forests model. Random Forest modeling is a type of machine learning model where multiple decision trees are built for training and their predictions are aggregated in such a way that is advantageous for accuracy and the reduction of overfitting. Because we are involving so many demographic indicators, it would be useful to use Random Forest modeling and be aware of the risk of overfitting. When we use Random Forests to replicate Kim and Zilinsky\u0026rsquo;s (2024) work, we find that the key demographics can only predict vote choice about 68% of the time. This is a few percentage points higher than when we relied on the logistic regression, but it is not fully determinative, underscoring Kim and Zilinsky\u0026rsquo;s findings as well.\nParty Predicted Vote Share (%) Democrat 50.46 Republican 49.54 I use the Random Forest modeling, which at its crux relies on bootstrap sampling, to predict national vote share based on demographics, including ideology identification metrics. It finds that the Democrats will just narrowly win the popular vote in November. This falls in line with previous models and current polls about the election being one of the closest in decades.\nDelving into a State Voter File # Now, let\u0026rsquo;s delve into a sample of Georgia\u0026rsquo;s voter file. I chose Georgia because it is my home state, I have done political mobilizing on the ground there, and I have been closely following it this election. The voter file data we are relying on is a sample of 1% of the total voter file data for the Georgia electoral and has been generously provided by Statara Solutions. Please check them out here.\nAbove, we look at five key demographics indicators and how they are distributed for the Georgia electorate. First, we see that the gender distribution is relatively similar among males and females in the state with slightly more females. The population of those pertaining to expansive gender identities is very few and among this sample only 8 actually do identify as such.\nThe age distribution for various ranges is even, except for 18-24 year olds and 65+. This makes sense because the range of ages for 18-24 is fewer than other buckets and there are a large amount of ages for which the 65+ bucket covers. Remember this was an indicator that, according to Kim and Zilinsky\u0026rsquo;s (2024) finding, did not affect vote choice all that much.\nDespite the national trend toward the minority majority phenomenon, Georgia\u0026rsquo;s electorate is still majority white. It also has a large Black population and sizable Asian and Hispanic/Latino populations. The indigenous population among Georgia\u0026rsquo;s electorate is quite low, especially compared to other states like Hawaii and Alaska.\nAs for education attainment, the plurality of Georgia\u0026rsquo;s electorate completed high school and a relatively large portion completed college. I did not expect that more Georgian voters completed graduate school than just some college or higher.\nBecause this data was available, I was curious to see the distribution of homeowners versus renters among Georgian voters. I was surprised to see that most voters are actually homeowners, according to this sample.\nLastly, Georgia has one very large metropolitan city with urban sprawl, Atlanta, and a lot of other small to mid size cities. It also has a large rural populations. This even distribution is reflected in the urbanicity graph.\nModel Simulations for Battleground States # ## `summarise()` has grouped output by \u0026#39;state\u0026#39;. You can override using the ## `.groups` argument. State Democrat Republican Arizona 0.0006 0.9994 Georgia 0.9116 0.0884 Michigan 1.0000 0.0000 Nevada 1.0000 0.0000 North Carolina 0.9755 0.0245 Pennsylvania 1.0000 0.0000 Wisconsin 1.0000 0.0000 State mean_dem mean_rep sd_dem sd_rep lower_dem upper_dem lower_rep upper_rep Arizona 52.25068 53.01345 0.1576075 0.3662173 51.94177 52.55959 52.29567 53.73124 Georgia 52.57779 52.29352 0.1605107 0.3729632 52.26319 52.89239 51.56251 53.02452 Michigan 53.61763 50.50728 0.1603770 0.3726526 53.30329 53.93197 49.77688 51.23768 Nevada 54.10442 52.23273 0.1599942 0.3717632 53.79083 54.41801 51.50407 52.96138 North Carolina 52.60621 52.20061 0.1577668 0.3665874 52.29699 52.91543 51.48210 52.91912 Pennsylvania 52.87369 51.60073 0.1587398 0.3688483 52.56256 53.18482 50.87779 52.32368 Wisconsin 53.30806 51.05413 0.1592734 0.3700883 52.99589 53.62024 50.32875 51.77950 Here, I simulate the 2024 election for key battleground states: Georgia, Michigan, Nevada, Wisconsin, North Carolina, Arizona, and Pennsylvania. I involve Democratic and Republican vote shares for the past two elections, Democratic and Republican polling averages for this election, voter turnout, and economic indicators in the form of the Consumer Price Index and the quarterly GDP growth. This is an expansion of my model from past weeks because I now involve voter turnout data.\nPopular poll aggregators and forecasters, like FiveThirtyEight and the Silver Bulletin, use simulations to quantify the uncertainty of their models. Most recently, simulation of FiveThirtyEight\u0026rsquo;s model has demonstrated a virtual coin flip outcome, or a 53 in 100 chance of Harris winning the electoral college and 47 in 100 change of Trump winning the electoral college.\nIt appears that all cases the sum of the mean two party vote share for Democrats and Republicans in the same state is more than 100%. We can attribute this to the fact that these models independently and linearly (without an imposed bound) predict for vote shares between Republicans and Democrats. In 6 out of the 7 battleground states, Democrats are projected to win. The one state where Republicans win is Arizona, which would be a flip back to a Trump victory after Biden won the state in 2020. It is critical to note that for all these predictions, the winning vote shares are well within the margins of error and each party realistically has a chance to win. This is not reflected looking just at how the simulation attributes wins to each party, for example, saying that Democrats win Nevada in 100% of all simulations. When more variables are involved in the simulation, particularly racial demographic changes and respective voter turnouts among racial groups, I predict that this would be much closer across all simulations.\nD R 305 233 Here is the map I predict to see on Election Night this November, according to my model this week. I predict that Harris will win the electoral college and clear the 270 threshold, as per my simulations that involve voter turnout and economic indicators as well as polling data and past vote shares. In all honesty, though, I think the race will be much closer than this, and I hope in future weeks to reflect that.\nConclusion # According to this week\u0026rsquo;s models, Harris will win the 2024 Presidential Election, taking 305 electoral votes.\nI myself am skeptical of this finding because it does not fall in line with the conventional wisdom about the closeness of this race. It also does not comport well with the incredibly close national popular vote share that I calculated using the Random Forests model based on demographics. I find it hard to believe a possibility where Harris would barely win over Trump in the popular vote by less than a percentage point but also take 6 of the 7 critical battleground states. In future models, I hope to reflect the competitiveness of this race better.\nSources # \u0026ldquo;2024 Election Forecast.\u0026rdquo; FiveThirtyEight, 2024, https://projects.fivethirtyeight.com/2024-election-forecast/.\nSeo-young Silvia Kim and Jan Zilinsky. Division does not imply predictability: Demographics continue to reveal little about voting and partisanship. Political Behavior, 46(1):67–87, March 2024. ISSN 1573-6687. doi: 10.1007/s11109-022-09816-z.\nPolling Data Provided by GOV 1347: Election Analytics teaching staff (which itself drew from the FiveThirtyEight GitHub)\nEconomic Data Provided by GOV 1347: Election Analytics teaching staff (which itself drew from the Burueau of Economic Analysia and Federal Reserve Economic Data)\nDemographic Data Provided by GOV 1347: Election Analytics teaching staff (which itself drew from the Burueau of Economic Analysia and Federal Reserve Economic Data)\nVoter File Data Provided by Statara Solutions. Check them out here: https://statara.com/.\n"},{"id":2,"href":"/2024election-blog/post/2024-09-25-week-4-fundamentals-ii-incumbency/","title":"Week 4: Fundamentals II, Incumbency","section":"Posts","content":" Week 4: Fundamentals II, Incumbency # Monday, September 30, 2024\n35 Days until Presidential Election\nToday marks about a month since I\u0026rsquo;ve started this blog to follow and forecast the 2024 Presidential Election. Thanks for following along!\nAfter two assassination attempts, the presence of Security Service at Trump\u0026rsquo;s rallies has become a point of attack for his campaign. Most recently, he has blamed the Biden administration for withholding personnel to guard his events, thereby hindering them from reaching the size they once did. The powers that incumbent political candidates have an don\u0026rsquo;t have is a large focus of American political science. While I am skeptical that we can group Trump\u0026rsquo;s rally attendance in with incumbent advantage, we should scrutinize how the theory applies to this year\u0026rsquo;s election—especially in relation to who we actually consider to be the incumbent between Harris and Trump.\nDescriptive Statistics on Incumbent Advantage # Incumbent President Re-elected Count Percentage FALSE 12 66.67 TRUE 6 33.33 ## Elections with At Least One Incumbent Running: 11 ## Incumbent Victories: 7 ## Percentage: 63.64 Election Year Democratic Candidate Republican Candidate Democratic Incumbency Republican Incumbency Democratic Win Republican Win 2004 Kerry, John Bush, George W. FALSE TRUE FALSE TRUE 2012 Obama, Barack H. Romney, Mitt TRUE FALSE TRUE FALSE 2020 Biden, Joseph R. Trump, Donald J. FALSE TRUE TRUE FALSE Incumbent Party Re-elected Count Percentage FALSE 10 55.56 TRUE 8 44.44 Previous Administration Member Elected Percentage FALSE 72.22 TRUE 27.78 Above we calculate some descriptive statistics on the incumbency advantage. If we simply look at the number of times an incumbent president is reelected or the number of times an incumbent party is reelected, it looks like incumbents actually have worse chances at being elected into office for a second time. Let us actually consider those elections which have incumbent running, however, and we see that incumbents have a higher rate of winning elections than non-incumbents.\nPork Barrel Spending and Incumbency # The advantage of incumbents is partly attributed to the powers they hold while in office and the ability to leverage them to garner votes. One such power is the power to apportion federal spending monies to key certain constituencies; this is known as pork barrel spending. The function of pork barrel spending lies in the idea that voters who receive more funding from an incumbent administration are more likely to view that administration favorably and cast their votes for them in the next election.\nTable 1: Pork County-Level Model Model 1 (Intercept) −6.450 (0.084) dpct_grants 0.005 (0.001) comp_state 0.153 (0.076) as.factor(year)1992 0.171 (0.116) as.factor(year)1996 6.345 (0.116) as.factor(year)2000 −2.050 (0.116) as.factor(year)2004 8.407 (0.116) as.factor(year)2008 3.137 (0.116) dpct_grants × comp_state 0.006 (0.002) Num.Obs. 18464 R2 0.403 R2 Adj. 0.402 AIC 107912.7 BIC 107990.9 Log.Lik. −53946.355 F 1555.616 RMSE 4.49 Table 1: Extended Pork County-Level Model Model 1 (Intercept) −6.523 (0.085) dpct_grants 0.004 (0.001) comp_state 0.155 (0.077) as.factor(year)1992 −0.156 (0.121) as.factor(year)1996 6.231 (0.120) as.factor(year)2000 −2.000 (0.119) as.factor(year)2004 8.248 (0.119) as.factor(year)2008 3.574 (0.124) dpc_income 0.134 (0.022) inc_ad_diff 0.061 (0.011) inc_campaign_diff 0.162 (0.013) dhousevote_inc 0.012 (0.002) iraq_cas2004 −0.153 (0.070) iraq_cas2008 −0.165 (0.022) dpct_popl 2.103 (0.530) dpct_grants × comp_state 0.006 (0.002) Num.Obs. 17959 R2 0.420 R2 Adj. 0.419 AIC 104624.8 BIC 104757.3 Log.Lik. −52295.398 F 865.892 RMSE 4.45 Table 1: Pork State-Level Model Model 1 (Intercept) 9.635 (3.632) is_comp −0.400 (4.150) change_grant_mil 0.114 (0.105) as.factor(year)1992 6.895 (6.717) as.factor(year)1996 −21.379 (5.273) as.factor(year)2000 3.577 (5.626) as.factor(year)2004 −30.162 (5.475) as.factor(year)2008 1.085 (4.863) is_comp × change_grant_mil −0.103 (0.164) Num.Obs. 300 R2 0.268 R2 Adj. 0.247 AIC 2754.6 BIC 2791.6 Log.Lik. −1367.285 F 13.286 RMSE 23.07 Here, we visualize a replication of the findings from Kriner and Reeves' \"Presidential Particularism and Divide-the-Dollar Politics\" (2015). They find that spending of federal grants in swing states is higher than core states. Just looking at swing states, there is a sizable difference in spending when an incumbent is running in an election versus when they are not. It is intuitive that incumbents use federal spending to advantage them in upcoming elections when they have them. My hope is that visualizing pork barrel spending can help give shape to the idea of the incumbency advantage. Time for a Change Model # One model of the incumbency advantage is Alan Abramowitz\u0026rsquo;s Time for Change model, which he developed in 1988. It is a simple Ordinary Least Squares Regression Model that relies on three independent variables: GDP Growth for Quarter 2, June Gallup Poll Approval, and a binary variable on incumbency status of a candidate.\nTable 2: Time for Change Models for 2024 Excluding 2020 Data Including 2020 Data Harris Non-Incumbent Hypothetical, Excluding 2020 Harris Non-Incumbent Hypothetical, Including 2020 (Intercept) 48.212 49.236 48.212 49.236 (1.070) (1.117) (1.070) (1.117) GDP Growth (Quarterly) 0.465 0.147 0.465 0.147 (0.155) (0.088) (0.155) (0.088) Incumbency Status 2.220 2.576 2.220 2.576 (1.244) (1.411) (1.244) (1.411) Approval Rating in June 0.132 0.139 0.132 0.139 (0.025) (0.029) (0.025) (0.029) Num.Obs. 18 19 18 19 R2 0.817 0.753 0.817 0.753 R2 Adj. 0.777 0.703 0.777 0.703 AIC 89.3 99.1 89.3 99.1 BIC 93.8 103.8 93.8 103.8 Log.Lik. −39.673 −44.548 −39.673 −44.548 F 20.783 15.217 20.783 15.217 RMSE 2.19 2.52 2.19 2.52 Table 2: Two-Party Vote Shares (%) Across Various Time for Change Models Candidate Excluding 2020 Data Including 2020 Data Harris Non-Incumbent Hypothetical, Excluding 2020 Harris Non-Incumbent Hypothetical, Including 2020 Silver's Ensemble Model, Weighing Polls Closer to Election Day Kamala Harris 48.93 49.2 46.71 46.62 51.31 Donald Trump 51.07 50.8 53.29 53.38 48.07 I have constructed four models based off of Abramowitz's Time for Change theory and predicted the upcoming 2024 election. In two models, I treat Harris as an incumbent candidate (and Trump a non-incumbent) and the other two models, I treat both candidates as non-incumbents. Like in previous weeks, I have compare models that include 2020 as a data point on which I train the model. All models show promise with relatively high R-squared and adjusted-R-squared values. For the very first time since I have started this blog, a model I constructed predicted a Trump win in popular vote. In fact, across all Time for Change models, Trump is predicted to win the popular vote—whether or not I include 2020 training data and whether I not I treat Harris as an incumbent candidate. We can see how this differs from my preferred model thus far constructed: Nate Silver\u0026rsquo;s, which is an ensemble model that involves economic and polling data and weighs polls higher the closer they get to election day (See more on this in Week 3\u0026rsquo;s blog post).\nAll this to say, the predicted two-party vote shares predicted from Abramowitz\u0026rsquo;s model shows a difference when we treat Harris as an incumbent and when we do not. This makes sense as we would expect an incumbent to be advantaged by some number of percentage points than they would otherwise.\nConclusion # Trump is predicted to win the popular vote in November.\nAcross all four models I constructed off of Abramowitz\u0026rsquo;s Time for Change Model, Donald Trump is predicted to have a greater-than-one-point lead over Harris in two-party popular vote share. This is the first time that Trump has been predicted to win in my models. When Harris\u0026rsquo;s incumbent advantage is removed, his lead over her widens.\nSources # Abramowitz, Alan I. “An Improved Model for Predicting Presidential Election Outcomes.” PS: Political Science and Politics, vol. 21, no. 4, 1988, pp. 843–47. JSTOR, https://doi.org/10.2307/420023.\nKriner, Douglas L., and Andrew Reeves. “Presidential Particularism and Divide-the-Dollar Politics.” American Political Science Review 109.1 (2015): 155–171. Web.\nOlmsted, Edith. “Trump Has a Wild New Theory for His Flagging Crowd Sizes.” The New Republic, 30 Sept. 2024, https://newrepublic.com/post/186504/donald-trump-joe-biden-theory-crowd-sizes.\n“When and Where Is the Vance-Walz US Vice Presidential Debate?” Reuters, 19 Sept. 2024, www.reuters.com/world/us/when-where-is-vance-walz-us-vice-presidential-debate-2024-09-19/.\nPolling Data Provided by GOV 1347: Election Analytics teaching staff (which itself drew from the FiveThirtyEight GitHub)\nEconomic Data Provided by GOV 1347: Election Analytics teaching staff (which itself drew from the Burueau of Economic Analysia and Federal Reserve Economic Data)\n"},{"id":3,"href":"/2024election-blog/post/2024-09-23-week-3-polling/","title":"Week 3: Polling","section":"Posts","content":" Week 3: Polling # Monday, September 23, 2024\n42 Days until Presidential Election\nHi again! Since last week, the Harris and Trump campaigns have been campaigning aggressively in battleground states. Realistically, who the next president will be hinges on voters in these key states: some have called this the closest presidential race of the past six decades. I touched briefly on the Harris-Trump debate last week, and although the Harris campaign agreed to another, Trump refuses to debate while voters in some states are beginning to cast their ballots. The VP candidates, however, are scheduled to debate each other next week on October 1st. This week, early voting begins in Minnesota, South Dakota, and Virginia. Considering how thin the margins between Harris and Trump are, it is important to consistently track their performance through polling data. Involving polling data into my model is the focus of this week. Because this race is unique in the fact that Harris entered with less than 16 weeks until election day, the scope of our forecasting is much more limited in available polling data than previous election years.\nIndividual Poll Ratings # In the charts above, I visualize the distribution of ratings of individual polls I use for the 2016, 2020, and 2024 election years. This data was provided by Matthew Dardet, who initially sourced it from FiveThirtyEight\u0026rsquo;s public GitHub. FiveThirtyEight, a poll aggregator, assigns grade values to individual polls, which we can use a proxy to interpret how much trust to put into their numbers. You might notice that the scale evolves from an A-D grading scaling, to A-F with \u0026ldquo;on-the-fence\u0026rdquo; assignments as well (e.g. \u0026ldquo;A/B\u0026rdquo;), to a continuous numeric scale from 0-3.0. For the sake of comparison, I\u0026rsquo;ve stacked these plots to understand how the distribution of polling quality varies from election year to election year. It seems that there exists—as a whole—a pretty even spread of poll ratings, with convergence on A, B, C grades (or 3, 2, 1 grades). In 2020, however, there seem to be significantly more polls with a C rating. There are also a good amount of polls that have not been assigned grades (NA values). In its forecasting, FiveThirtyEight weights poll data by its rating, so as not to give the same importance to the numbers of a fail-grade poll as an exceptional one.\n2016 Polling Averages # To set up this plot, I averaged individual polls across the same day for the year leading up to the 2016 election. The polling numbers are interesting here because for the first few months it appears that, as Clinton went up in approval, so did Trump—same with when her numbers fell. This is not intuitive because, one would assume, that when a Democratic candidate does well a Republican candidate\u0026rsquo;s approval drops (and vice versa). It is important to note, however, this is before both parties\u0026rsquo; primaries even began. After February 1, 2016 when primaries began, Clinton\u0026rsquo;s gains coincide with Trump\u0026rsquo;s losses and Trump\u0026rsquo;s gains with Clinton\u0026rsquo;s losses. I hypothesize that this is because a frontrunner emerges within each party and voters begin to seriously compare top candidates across parties, resulting in inverse effects between them. The Clinton-Trump polling margin ranged from over 10 points to less than one 1 point. Clinton seemed to maintain the lead throughout the race however, which is in line with her eventually winning the popular vote in November. The dashed line represents each candidate\u0026rsquo;s actual vote share in the election; as a whole, these polls underestimated the popular vote share of both candidates.\n2020 Polling Averages # I set up this plot the same way I did for 2016, by taking day averages. The party primaries in 2020 began on February 3rd. We see the same phenomenon we did in 2016, where before that point the approval of both candidates seems to line up with the same ups and downs. After February 3rd, however, the main candidates emerge and begin to diverge: when Trump did well, Biden did poorly and when Biden did well, Trump did poorly. Especially in comparison to 2016, the final polls were remarkably close to predicting the actual vote share of each candidate. For Biden, it is virtually the same, and for Trump, just a point or two short.\n2024 Polling Averages # For this plot, I calculated and plotted day averages just like I did for 2016 and 2024. You might notice that you see much less polling data for Harris (blue dots) until about July. This is because Biden was the assumed Democratic candidate who would face off against Trump for the majority of the election cycle. The polls that collected data on Harris were likely operating under a hypothetical and testing how various alternates would fare against Trump. After Biden dropped out and that became a reality, more polling data on Harris as president was collected.\nRegularized Regression Using Individual Polls # ## ## November Polling Average OLS Regressions ## ============================================================= ## Dependent variable: ## ----------------------------------------- ## pv ## OLS ## Democratic Candidates Party-Stacked ## (1) (2) ## ------------------------------------------------------------- ## nov_poll 0.745 0.681* ## (0.209) ## ## Constant 13.340 15.733 ## (9.775) ## ## ------------------------------------------------------------- ## Observations 2 4 ## R2 1.000 0.842 ## Adjusted R2 0.763 ## Residual Std. Error 1.314 (df = 2) ## F Statistic 10.635* (df = 1; 2) ## ============================================================= ## Note: *p\u0026lt;0.1; **p\u0026lt;0.05; ***p\u0026lt;0.01 ## ## Comparison of OLS and Regularized Regression Methods ## ============================================== ## Dependent variable: ## --------------------------- ## pv ~ ## OLS ## ---------------------------------------------- ## poll_weeks_left_7 -3.488 ## ## ## poll_weeks_left_8 5.957 ## ## ## poll_weeks_left_9 -1.465 ## ## ## poll_weeks_left_10 ## ## ## poll_weeks_left_11 ## ## ## poll_weeks_left_12 ## ## ## poll_weeks_left_13 ## ## ## poll_weeks_left_14 ## ## ## poll_weeks_left_15 ## ## ## poll_weeks_left_16 ## ## ## Constant 1.984 ## ## ## ---------------------------------------------- ## Observations 4 ## R2 1.000 ## ============================================== ## Note: *p\u0026lt;0.1; **p\u0026lt;0.05; ***p\u0026lt;0.01 ## 11 x 1 sparse Matrix of class \u0026#34;dgCMatrix\u0026#34; ## s1 ## (Intercept) 32.11771129 ## poll_weeks_left_7 0.03034872 ## poll_weeks_left_8 0.03382783 ## poll_weeks_left_9 0.03150732 ## poll_weeks_left_10 0.03251707 ## poll_weeks_left_11 0.03591400 ## poll_weeks_left_12 0.03424576 ## poll_weeks_left_13 0.03573401 ## poll_weeks_left_14 0.03675323 ## poll_weeks_left_15 0.03401006 ## poll_weeks_left_16 0.03482219 ## 11 x 1 sparse Matrix of class \u0026#34;dgCMatrix\u0026#34; ## s1 ## (Intercept) 16.5080023 ## poll_weeks_left_7 . ## poll_weeks_left_8 . ## poll_weeks_left_9 . ## poll_weeks_left_10 . ## poll_weeks_left_11 . ## poll_weeks_left_12 . ## poll_weeks_left_13 0.5079695 ## poll_weeks_left_14 . ## poll_weeks_left_15 0.1674345 ## poll_weeks_left_16 . ## [1] 1.676314 ## [1] 0.3259247 ## [1] 0.5028851 Table: Table 1: 2024 National Popular Vote Prediction \u0026ndash; Individual Polls\ns1 Harris 47.96284 Trump 47.31766 The above charts are bit technical, but their purpose is to visualize the regularization of my regression that uses individual polls from 2016 and 2020 to predict the outcome of the 2024 election. I essentially train a model on polling data from 2016 and 2020, subsetting to the period of 16 weeks to 7 weeks out from election day because accurate polls for Harris\u0026rsquo;s campaign are only available for this time. I, then, test on the Harris-Trump polling data in this period and predict the outcome. I rely on an elastic net model that would minimize multi-collinearity and increase robustness. Though LASSO and Ridge regression are also useful models, the elastic net is versatile and flexibile because it incorporates both of those methods as well. It is also much preferable to Ordinary Least Squares (OLS) because OLS is susceptible to overfitting and collinearity.\nBased on the visualization, we see that 14 weeks from election day (the week after Harris announced her campaign), 11 weeks from election day (during the DNC), and 8 weeks from election day (during the presidential debate where Harris performed well) the model demonstrates relatively higher coefficients—though a marginal difference as compared to other weeks. My model based on individual polls predicts Harris\u0026rsquo;s popular vote share at about 47.96% and Trump\u0026rsquo;s at 47.32%, corroborating predicitions of an incredibly close election. This is a much closer margin than what Dardet predicted with national poll averages from 1968-2024, which had Harris at 51.8% and Trump at 50.7%. We will address later how it is possible that both candidates\u0026rsquo; vote shares add up to more than 100%.\nEnsemble Models Using Individual Polls # Table: Table 2: 2024 National Popular Vote Prediction \u0026ndash; Elastic-Net, Fundamentals\ns1 Harris 50 Trump 50 Table: Table 2: 2024 National Popular Vote Prediction \u0026ndash; Elastic-Net Polls and Fundamentals\ns1 Harris 50 Trump 50 Table: Table 2: 2024 National Popular Vote Prediction \u0026ndash; Unweighted Polls and Fundamentals\ns1 Harris 50.16519 Trump 49.83481 Table: Table 2: 2024 National Popular Vote Prediction \u0026ndash; Weighted Polls Closer to November (Silver)\ns1 Harris 50.28765 Trump 49.71235 Table: Table 2: 2024 National Popular Vote Prediction \u0026ndash; Weighted Fundamentals Closer to November (Gelman \u0026amp; King, 1993)\ns1 Harris 50.04688 Trump 49.95312 After using 2016 and 2020 individual polls to predict the 2024 popular vote outcome, I decided I also wanted involve a fundamentals model (See: Week 2 Post for more details) and consider models that weight data heavier for weeks closer to election day. There are five new models, which I construct.\nA Fundamentals Only Model using Elastic Net\nA Combined Fundamentals and Polling Data Model using Elastic Net\nAn Unweighted Polling Data and Fundamentals Model\nAn Closer-To-November-Increasing Weight Polling Data Model (attributable to Nate Silver)\nAn Closer-To-November-Increasing Weight Fundamentals Model (attributable to Gelman \u0026amp; King, 1993)\nBecause elastic net predicts linearly and without constraints, I initially had predictions saying that Harris and Trump would get popular vote shares above 60% each. This does not make sense, so I regularized the scales and recalculated such that Harris and Trump were compared against each other and their sums would be 100% to be more informative of how they would actually fare in the election. This would be similar to a two-party vote share. The first two models show that Harris and Trump will tie at 50% vote shares. Once we move to the third Unweighted Polling Data and Fundamentals Model, we find that Harris is predicted to win the two-party popular vote by about .3 points. Mimicing Silver\u0026rsquo;s model, which assigns higher weights to polls as we move closer to election day, I find that Harris is predicted to win the two-party popular vote by about .6 points. The margins for a Harris win are much slimmer using Gelman \u0026amp; King\u0026rsquo;s model, which weights fundamentals higher closer to the election at .1.\nConclusion # Prediction: Based on my individual polls-generated models, Harris will win the popular vote in November by a razor-thin margin.\nAcross all models I constructed using individual polls from 2016, 2020, and 2024, Harris is predicted to win the popular vote. The models all vary by how much she is predicted to win, but they all find that she will win by an incredibly thin margin. This corroborates the characterization of this race as the closest in decades.\nSources # Bradner, Eric. “Analysis: The Closest Presidential Race in a Generation.” CNN, 22 Sept. 2024, www.cnn.com/2024/09/22/politics/closest-presidential-race-harris-trump/index.html.Chiacu, Doina. “When and Where Is the Vance-Walz US Vice Presidential Debate?” Reuters, 19 Sept. 2024, www.reuters.com/world/us/when-where-is-vance-walz-us-vice-presidential-debate-2024-09-19/.\nCole, Devan. “Harris and Trump Set for First Debate of Closest Presidential Race in Years.” CNN, 21 Sept. 2024, www.cnn.com/2024/09/21/politics/presidential-debate-harris-trump-cnn/index.html.\n“Early In-Person Voting Begins in Three States, Kicking off the Sprint to Election Day.” PBS NewsHour, 22 Sept. 2024, www.pbs.org/newshour/politics/early-in-person-voting-begins-in-three-states-kicking-off-the-sprint-to-election-day.\nPolling Data Provided by GOV 1347: Election Analytics teaching staff (which itself drew from the FiveThirtyEight GitHub)\nEconomic Data Provided by GOV 1347: Election Analytics teaching staff (which itself drew from the Burueau of Economic Analysia and Federal Reserve Economic Data)\nCollaborated with Shivali Korgaonkar and Nick Dominguez to construct this model, as part of our week\u0026rsquo;s presentation on polling.\n"},{"id":4,"href":"/2024election-blog/post/2024-09-12-week-2-fundamentals-i-the-economy/","title":"Week 2: Fundamentals I, The Economy ","section":"Posts","content":" Week 2: Forecasting Fundamentals, the Economy # Monday, September 16, 2024\n49 Days until Presidential Election\nWelcome back and thanks for following along my forecast of the 2024 US Presidential Election. Since my last post, Vice President Harris and President Trump faced off in a debate moderated by ABC\u0026rsquo;s Linsey Davis and David Muir. Both candidates were asked about abortion, immigration, foreign policy, and the economy. Only one question was directly asked about the economy, aimed at VP Harris. \u0026ldquo;When it comes to the economy, do you believe Americans are better off than they were four years ago?\u0026rdquo; The focus of this week\u0026rsquo;s post is to build and evaluate models that attempt to illustrate the relationship between incumbent success and measures of the economy.\nA Quick Note on Methodology # I deviate from class-provided data by using incumbent vote margin as the outcome variable instead of incumbent two-party-adjusted vote share. There are two main reasons for this. The first is that two-party-adjusted vote metrics do not account for votes for third-party candidates, overlooking potentially significant voter dissatisfaction with the incumbent and/or main challenger candidate. At the same time, the vote margin metric is resistant to the shocks that a potentially \u0026ldquo;successful\u0026rdquo; third-party candidate might have on vote share. The second is that vote margin provides us with more insight into the swing between the main candidate: how far ahead was the winner to the runner-up and how close was the election are questions for which the vote margin metric can provide insight.\nI source relevant metrics of the economy from a lively discussion between Geoffrey Skelley and Mary Radcliffe on the FiveThirtyEight Politics Podcast Episode \u0026ldquo;Presidential Debates Do Matter\u0026rdquo;. I highly recommend listening to the episode here. Interestingly, Skelley notes that American voters tend to look to national metrics of the economy in deciding who to vote for more than personal metrics, a phenomenon known as sociotropic voting. I believe there is some truth to this, especially in the ways that changes in national economic performance can trickle down to affect personal finances. Radcliffe and Skelley put together four broad economic phemeona voters internalize as they vote:\ninflation\nunemployment\npersonal finances\nstock market performance\nPart of my contribution this week is interpreting these phenomena into specific metrics. I rely on the Consumer Price Index as a measure of inflation, the unemployment rate as a measure of unemployment, quarterly growth in Real Disposable Personal Income as a measure of personal finances, and percent change between SP500 Open and Close reports as a measure of stock market performance. Radcliffe argues that before COVID the price of goods and services and unemployment/jobs were the most salient economic issues to voters. Since shutdowns, though, unemployment has become a much bigger concern for voters.\nGDP Growth and Vote Margin # Let\u0026rsquo;s first look at a broad measure of economic performance and evaluate it against incumbent vote margin:\n## Warning: The following aesthetics were dropped during statistical transformation: label. ## ℹ This can happen when ggplot fails to infer the correct grouping structure in ## the data. ## ℹ Did you forget to specify a `group` aesthetic or to convert a numerical ## variable into a factor? ## Warning: The following aesthetics were dropped during statistical transformation: label. ## ℹ This can happen when ggplot fails to infer the correct grouping structure in ## the data. ## ℹ Did you forget to specify a `group` aesthetic or to convert a numerical ## variable into a factor? Here, I run a linear regression on the relationship between between Quarterly GDP Growth and Incumbent Vote Margin, mapping actual election results from 1948 to 2020 onto the plot as well. We observe a pretty strong positive relationship between GDP growth and incumbent vote margin, suggesting that the better the output of the national economy, the better an incumbent party's performance in the upcoming presidential election. You might notice that I have two plots: one with 2020 as a data point and one without. This is because across a number of metrics 2020 is a distant outlier, which often skews models in a ways that confuses any actual evaluation of a relationship between economy and election performance. I keep both plots to illustrate this discrepancy and to note which metrics 2020 data falls into a predicted pattern for and which it does not. ## [1] \u0026#34;With 2020 R-Squared: 0.187884044842374\u0026#34; ## [1] \u0026#34;Without 2020 R-Squared: 0.317291723250674\u0026#34; ## [1] \u0026#34;With 2020 Mean Squared Error: 79.2859405902988\u0026#34; ## [1] \u0026#34;Without 2020 Mean Squared Error: 67.7703432164646\u0026#34; ## [1] \u0026#34;Cross-Validation Mean Absolute Value Error (Without 2020): 3.48738948365726\u0026#34; Above are some in-sample and out-of-sample ways to evaluate the strength of GDP Growth model. Across the board, the model performs pretty poorly, as we see very low R-Squared values, high Mean Squared Errors and Cross-Validation Mean Absolute Value Errors with vote margin percentages large enough to sway a close election. The GDP model that leaves out 2020 generally fares better, but it is still not great.\n## [1] \u0026#34;2024 GDP-Predicted Incumbent Vote Margin: 4.15855909921272\u0026#34; ## [1] \u0026#34;2024 GDP-Predicted Incumbent Vote Margin (Excluding 2020 from Model): 3.21368743265838\u0026#34; Even still, we can predict how the incumbent party will perform given GDP growth as the input. Across models that involve 2020 and exclude it, it seems that Harris will have a fairly large lead in national popular vote share against Trump. We will tally these outcomes, although flawed in terms of strength of model, as we go along.\nHarris +1\nCPI and Vote Margin # ## Warning: The following aesthetics were dropped during statistical transformation: label. ## ℹ This can happen when ggplot fails to infer the correct grouping structure in ## the data. ## ℹ Did you forget to specify a `group` aesthetic or to convert a numerical ## variable into a factor? ## Warning: The following aesthetics were dropped during statistical transformation: label. ## ℹ This can happen when ggplot fails to infer the correct grouping structure in ## the data. ## ℹ Did you forget to specify a `group` aesthetic or to convert a numerical ## variable into a factor? Above, I run a linear regression on the relationship between between Consumer Price Index and Incumbent Vote Margin. This is a critical measure because voters are exposed to sticker shock effects as a result of inflation and can vote accordingly. It might be a national measure, but individual voters are directly exposed to it. According to the model, there is a pretty strong negative relationship between CPI and incumbent vote margin, suggesting that the higher that consumer prices are, the worse an incumbent party's performance in the upcoming presidential election. Here, it seems that 2020 actually does not distort the model's relationship of the two variables. ## [1] \u0026#34;With 2020 R-Squared: 0.0801668996456767\u0026#34; ## [1] \u0026#34;Without 2020 R-Squared: 0.0520097549971837\u0026#34; ## [1] \u0026#34;With 2020 Mean Squared Error: 89.8022407816482\u0026#34; ## [1] \u0026#34;Without 2020 Mean Squared Error: 94.1040653199678\u0026#34; ## [1] \u0026#34;Cross-Validation Mean Absolute Value Error (Without 2020): 4.19577582571556\u0026#34; The CPI model fares even worse than the GDP model with abysmal R-Squared values, high Mean Squared Errors, and a large Cross-Validation Mean Absolute Value Error.\n## [1] \u0026#34;2024 CPI-Predicted Incumbent Vote Margin: -3.30839041076806\u0026#34; ## [1] \u0026#34;2024 CPI-Predicted Incumbent Vote Margin (Excluding 2020 from Model): -2.19490995507331\u0026#34; Building our linear regression model on solely the CPI, we see that Harris trails Trump by 3.3% share of national popular vote with 2020 data and 2.2% excluding it. This makes sense as voters have consistently aired their grievances about inflation through this campaign season.\nTrump +1\nRDPI Growth and Vote Margin # ## Warning: The following aesthetics were dropped during statistical transformation: label. ## ℹ This can happen when ggplot fails to infer the correct grouping structure in ## the data. ## ℹ Did you forget to specify a `group` aesthetic or to convert a numerical ## variable into a factor? ## Warning: The following aesthetics were dropped during statistical transformation: label. ## ℹ This can happen when ggplot fails to infer the correct grouping structure in ## the data. ## ℹ Did you forget to specify a `group` aesthetic or to convert a numerical ## variable into a factor? Now, I run a linear regression on the relationship between between Quarterly Growth in Real Disposable Personal Income and Incumbent Vote Margin. RDPI is my proxy for personal finances and can provide insight into how much voters are actually working with after taxes. According to the model, there is a pretty strong positive relationship between RDPI and incumbent vote margin, suggesting that the greater growth in RDPI, the better an incumbent party's performance in the upcoming presidential election. Here, it seems that 2020 completely distorts the model's relationship of the two variables, so it is probably best to leave it out. ## [1] \u0026#34;With 2020 R-Squared: 0.00355888626006062\u0026#34; ## [1] \u0026#34;Without 2020 R-Squared: 0.109188411395232\u0026#34; ## [1] \u0026#34;With 2020 Mean Squared Error: 97.2813924464543\u0026#34; ## [1] \u0026#34;Without 2020 Mean Squared Error: 88.4281166011348\u0026#34; ## [1] \u0026#34;Cross-Validation Mean Absolute Value Error (Without 2020): 4.2520935685221\u0026#34; Again, the RDPI model performs pretty poorly with in-sample and out-of-sample tests. It yields low R-Squared values even when I leave out 2020 data. The Mean Squared Error is high and so is the Cross-Validation Mean Absolute Value Error.\n## [1] \u0026#34;2024 RDPI Growth-Predicted Incumbent Vote Margin: 3.9250814230794\u0026#34; ## [1] \u0026#34;2024 RDPI Growth-Predicted Incumbent Vote Margin (Excluding 2020 from Model): 0.788092792500218\u0026#34; However, if we use this model to forecast the upcoming election, it appears that Harris will win. The model that involves 2020 data I determined was extremely flawed for distorting the input-outcome relationship. When we exclude 2020 data, it appears that Harris only wins the national popular vote share by less than a percentage, signaling a close race (if Quarterly RDPI Growth is all that mattered to voters).\nHarris +1\nUnemployment and Vote Margin # ## Warning: The following aesthetics were dropped during statistical transformation: label. ## ℹ This can happen when ggplot fails to infer the correct grouping structure in ## the data. ## ℹ Did you forget to specify a `group` aesthetic or to convert a numerical ## variable into a factor? ## Warning: The following aesthetics were dropped during statistical transformation: label. ## ℹ This can happen when ggplot fails to infer the correct grouping structure in ## the data. ## ℹ Did you forget to specify a `group` aesthetic or to convert a numerical ## variable into a factor? Continuing with the economic phenomena Radcliffe and Skelley highlight as important to voters, I run a linear regression on the relationship between between Unemployment and Incumbent Vote Margin. Interestingly, the model suggests that there is no correlation between unemployment and incumbent vote margin, especially if we look at the one that excludes 2020 data. It makes sense to exclude 2020 here because it forces a relationship that looks like does not exist. ## [1] \u0026#34;With 2020 R-Squared: 0.0165836375771564\u0026#34; ## [1] \u0026#34;Without 2020 R-Squared: 0.00052581496233859\u0026#34; ## [1] \u0026#34;With 2020 Mean Squared Error: 96.0098010529196\u0026#34; ## [1] \u0026#34;Without 2020 Mean Squared Error: 99.2147171241475\u0026#34; ## [1] \u0026#34;Cross-Validation Mean Absolute Value Error (Without 2020): 4.31983962251656\u0026#34; The R-Squared values for the unemployment-predicted model are the lowest we have seen so far. THe Mean Squared Errors are also the highest and the Cross-Validation Mean Absolute Value Error is a large percentage vote margin that could push an election in any direction.\n## [1] \u0026#34;2024 Unemployment-Predicted Incumbent Vote Margin: 4.67350537665337\u0026#34; ## [1] \u0026#34;2024 Unemployment-Predicted Incumbent Vote Margin (Excluding 2020 from Model): 3.79434427081865\u0026#34; The model suggests that the incumbent party, Harris and the Democrats, will win the national popular vote share in November—whether we include 2020 data or not.\nHarris +1\nStock Market Performance and Vote Margin # ## Warning: The following aesthetics were dropped during statistical transformation: label. ## ℹ This can happen when ggplot fails to infer the correct grouping structure in ## the data. ## ℹ Did you forget to specify a `group` aesthetic or to convert a numerical ## variable into a factor? ## Warning: The following aesthetics were dropped during statistical transformation: label. ## ℹ This can happen when ggplot fails to infer the correct grouping structure in ## the data. ## ℹ Did you forget to specify a `group` aesthetic or to convert a numerical ## variable into a factor? Finally, we look to stock market performance as a metric of economic success that voters find salient. Both 2020-inclusive and 2020-exclusive models suggest a negative relationship between Stock Market Change and Incumbent Vote Margin. This is counter-intuitive because it suggests that greater growth of the SP500 coincides with poorer performance of the incumbent party in an upcoming election. It might be that higher percentage stock market changes actually signal a volatile economy that voters fear; this is speculative though and not an actual attempt to establish causality. If this were the case, it would not be wise to use a linear model and to use a more complex one instead.\n## [1] \u0026#34;With 2020 R-Squared: 0.114865484041972\u0026#34; ## [1] \u0026#34;Without 2020 R-Squared: 0.0881691133665322\u0026#34; ## [1] \u0026#34;With 2020 Mean Squared Error: 86.4146581543887\u0026#34; ## [1] \u0026#34;Without 2020 Mean Squared Error: 90.5146374330731\u0026#34; ## [1] \u0026#34;Cross-Validation Mean Absolute Value Error (Without 2020): 4.08833453129254\u0026#34; Like the rest, the stock market model performs poorly in measures of in-sample and out-of-sample testing. The R-Squared values are low, the Mean Square Errors are high, and the Cross-Validation Mean Absolute Value is a large percentage value.\n## [1] \u0026#34;2024 Stock Market-Predicted Incumbent Vote Margin: 3.99855641825043\u0026#34; ## [1] \u0026#34;2024 Stock Market--Predicted Incumbent Vote Margin (Excluding 2020 from Model): 3.8267002013802\u0026#34; When we predict incumbent vote margin using this model, we get that Harris will be ahead of Trump by about 4 points with regards to the national popular vote share.\nHarris +1\nConclusion # Harris: 4\nTrump: 1\nPrediction: Harris will win the popular vote in November.\nIf we treat each metric of the economy (that I used to run these regressions) as keys, we see that Harris has won four economic keys and Trump has won just one. This deviates from Skelley\u0026rsquo;s suggestion that retrospective voters will disfavor Harris in light of their economic grievances.\nIn all honesty, these models are quite bad. I would not put my money on the prediction resultant from them. The best model by in-sample and out-of-sample metrics was the Quarterly-GDP-Growth-Predicted Model, which itself was pretty poor. The absolute worst model overall was the Quarterly-RDPI-Growth Predicted Model. I suspect that these models are not robust because there are only 18 or 19 (when including 2020) observations of election years off of which I am working. It is a pretty small sample size and difficult to draw statistically significant insights from. This reflects a challenge with using economic data to forecast elections—there are only so many elections to draw data from and to use to train models, resulting in a lot of variance as we see with my linear regression models. Across all models, I had errors that could have totally changed the outcome of who wins the popular vote. How can we base a forecast on models that themselves cannot make a real prediction?\nIn future economic models, I hope to use more granular data (month-wise or quarter-wise) and involve polling data to track how opinions change along with measures of economic performance. This time, I only used bivariate linear regressions, but I will in the future include multiple independent variables and weigh them by polls of voters and how salient they are.\nSources # “Presidential Debates Do Matter | 538 Politics Podcast.” YouTube, uploaded by FiveThirtyEight, 9 Sept. 2024, www.youtube.com/watch?v=PkjfKF0frvs.\nData Provided by GOV 1347: Election Analytics teaching staff (which itself drew from the Burueau of Economic Analysia and Federal Reserve Economic Data)\n"},{"id":5,"href":"/2024election-blog/post/2024-09-09-week-1-past-presidential-elections/","title":"Week 1: Past Presidential Elections","section":"Posts","content":" Week 1: Past Presidential Elections # Monday, September 9, 2024\n56 Days until Presidential Election\nWelcome to my first week tracking and forecasting the 2024 US Presidential Election. The main purpose of this first post is to get acquainted with the process of analyzing basic election data. Every Monday, I will come back here to post increasingly more sophisticated and informed additions to my forecast. For now, I am relying on past election data to predict who will become the next president of the United States. What you will find in this post is a very rudimentary method of forecasting, given it is the first week, but it should not be wholly discounted. Arguably, the best way to predict the future is by looking to the past.\nA Note on Data-Driven Prophecies and Crystal Balls # Just last week, an article in Politico written by Stanford’s Justin Grimmer, cast doubt on the ability to forecast presidential elections in the first place (Grimmer 2024). He and his co-authors for the paper behind the article, Dean Knox and Sean Westwood, find that the accuracy of election forecasts is virtually untestable because it relies on probabilities to be played out. Say, for example, that a famous poll aggregator forecasted that Kamala Harris were to win the next election 45 out of 100 times. They make the point that we have not even seen 100 presidential elections as a country to test this finding and compare it to other models.\nThough I believe Grimmer, Knox, and Westwood to be overly pessimistic about the attention given to political forecasts, especially presidential ones, I will carry their skepticism with me as I build my models. There is value in mathematically evaluating how various data inputs could impact candidate success, but surely an overreliance on quantitative data will not be truly informative.\nCreating a Standard Style # # custom ggplot theme my_prettier_theme \u0026lt;- function() { theme( # no border panel.border = element_blank(), # background panel.background = element_rect(fill = \u0026#34;snow2\u0026#34;), # text plot.title = element_text(size = 15, hjust = .5, face = \u0026#34;bold\u0026#34;, family = \u0026#34;sans\u0026#34;), plot.subtitle = element_text(size = 13, hjust = .5, family = \u0026#34;sans\u0026#34;), plot.title.position = \u0026#34;panel\u0026#34;, axis.text.x = element_text(size = 8, angle = 45, hjust = .5, family = \u0026#34;sans\u0026#34;), axis.text.y = element_text(size = 8, family = \u0026#34;sans\u0026#34;), axis.title.x = element_text(family = \u0026#34;sans\u0026#34;), axis.title.y = element_text(angle = 90, family = \u0026#34;sans\u0026#34;), axis.ticks = element_line(colour = \u0026#34;black\u0026#34;), axis.line = element_line(colour = \u0026#34;grey\u0026#34;), # legend legend.position = \u0026#34;right\u0026#34;, legend.title = element_text(size = 12, family = \u0026#34;sans\u0026#34;), legend.text = element_text(size = 10, family = \u0026#34;sans\u0026#34;), # aspect ratio aspect.ratio = .8 ) } Before we move into content, I wanted to establish a standard style for my visualizations going forward. I choose sans serif font and relatively large size text for ease of reading.\nGuiding Questions for this Week # How competitive are presidential elections in the United States?\nWhich states vote blue/red and how consistently?\nTo answer these questions, let’s look at popular vote share and electoral college data from presidential elections between 1948 and 2020. Thank you to Matthew Dardet for cleaning and providing this data.\n####----------------------------------------------------------# #### Visualize trends in national presidential popular vote. ####----------------------------------------------------------# # Visualize the two-party presidential popular over time. two_party_visualization \u0026lt;- d_popvote |\u0026gt; ggplot(mapping = aes(x = year, y = pv2p, # look at two-party popular vote color = party)) + # color code by winning party geom_line() + geom_point() + # add points for each election scale_color_manual(\u0026#34;Party\u0026#34;, values = c(\u0026#34;steelblue3\u0026#34;, \u0026#34;tomato3\u0026#34;)) + labs(title = \u0026#34;Two Party Presidential Popular Over Time\u0026#34;, subtitle = \u0026#34;1948-2020\u0026#34;, x = \u0026#34;Year\u0026#34;, y = \u0026#34;Winning Popular Vote Share\u0026#34;) + my_prettier_theme() two_party_visualization ggsave (\u0026#34;figures/two_party_vis.png\u0026#34;) ## Saving 7 x 5 in image The above line chart helps visualize an answer to our question on the competitiveness of presidential elections in the United States. Broadly speaking, I would say that the presidential races are very competitive between the two main parties, Democrats and Republicans. The chart shows that no one party has a solidified dominance over the popular vote, though it is noteworthy that Democrats have won the popular vote for the past four elections. According to findings in Gallup from 2021, partisan identification with either Democrats or Republicans is relatively the same but independents remain the largest group of American voters, hinting their potential to sway elections differently each election (Jones 2022). Popular vote is not necessarily how candidates win the presidency, though, so let’s take a look at state and electoral vote data.\n####----------------------------------------------------------# #### State-by-state map of presidential popular votes. ####----------------------------------------------------------# # Sequester shapefile of states from `maps` library. states_map \u0026lt;- map_data(\u0026#34;state\u0026#34;) unique(states_map$region) ## [1] \u0026quot;alabama\u0026quot; \u0026quot;arizona\u0026quot; \u0026quot;arkansas\u0026quot; ## [4] \u0026quot;california\u0026quot; \u0026quot;colorado\u0026quot; \u0026quot;connecticut\u0026quot; ## [7] \u0026quot;delaware\u0026quot; \u0026quot;district of columbia\u0026quot; \u0026quot;florida\u0026quot; ## [10] \u0026quot;georgia\u0026quot; \u0026quot;idaho\u0026quot; \u0026quot;illinois\u0026quot; ## [13] \u0026quot;indiana\u0026quot; \u0026quot;iowa\u0026quot; \u0026quot;kansas\u0026quot; ## [16] \u0026quot;kentucky\u0026quot; \u0026quot;louisiana\u0026quot; \u0026quot;maine\u0026quot; ## [19] \u0026quot;maryland\u0026quot; \u0026quot;massachusetts\u0026quot; \u0026quot;michigan\u0026quot; ## [22] \u0026quot;minnesota\u0026quot; \u0026quot;mississippi\u0026quot; \u0026quot;missouri\u0026quot; ## [25] \u0026quot;montana\u0026quot; \u0026quot;nebraska\u0026quot; \u0026quot;nevada\u0026quot; ## [28] \u0026quot;new hampshire\u0026quot; \u0026quot;new jersey\u0026quot; \u0026quot;new mexico\u0026quot; ## [31] \u0026quot;new york\u0026quot; \u0026quot;north carolina\u0026quot; \u0026quot;north dakota\u0026quot; ## [34] \u0026quot;ohio\u0026quot; \u0026quot;oklahoma\u0026quot; \u0026quot;oregon\u0026quot; ## [37] \u0026quot;pennsylvania\u0026quot; \u0026quot;rhode island\u0026quot; \u0026quot;south carolina\u0026quot; ## [40] \u0026quot;south dakota\u0026quot; \u0026quot;tennessee\u0026quot; \u0026quot;texas\u0026quot; ## [43] \u0026quot;utah\u0026quot; \u0026quot;vermont\u0026quot; \u0026quot;virginia\u0026quot; ## [46] \u0026quot;washington\u0026quot; \u0026quot;west virginia\u0026quot; \u0026quot;wisconsin\u0026quot; ## [49] \u0026quot;wyoming\u0026quot; # Read wide version of dataset that can be used to compare candidate votes with one another. d_pvstate_wide \u0026lt;- read_csv(\u0026#34;clean_wide_state_2pv_1948_2020.csv\u0026#34;) ## Rows: 959 Columns: 14 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: \u0026quot;,\u0026quot; ## chr (1): state ## dbl (13): year, D_pv, R_pv, D_pv2p, R_pv2p, D_pv_lag1, R_pv_lag1, D_pv2p_lag... ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. # Merge d_pvstate_wide with state_map. d_pvstate_wide$region \u0026lt;- tolower(d_pvstate_wide$state) pv_map \u0026lt;- d_pvstate_wide |\u0026gt; filter(year == 2020) |\u0026gt; left_join(states_map, by = \u0026#34;region\u0026#34;) # Make map grid of state winners for each election year available in the dataset. pv_win_map \u0026lt;- pv_map |\u0026gt; mutate(winner = ifelse(R_pv \u0026gt; D_pv, \u0026#34;republican\u0026#34;, \u0026#34;democrat\u0026#34;)) pv_win_map |\u0026gt; ggplot(aes(long, lat, group = group)) + geom_polygon(aes(fill = winner), color = \u0026#34;black\u0026#34;) + scale_fill_manual(values = c(\u0026#34;steelblue\u0026#34;, \u0026#34;tomato3\u0026#34;)) + theme_void() + labs(title = \u0026#34;Map Grid of State Winners\u0026#34;, subtitle = \u0026#34;2020 Election\u0026#34;) + my_prettier_theme() + theme(axis.title.x= element_blank(), axis.title.y= element_blank(), axis.text.x= element_blank(), axis.text.y= element_blank(), axis.ticks = element_blank(), axis.line= element_blank()) ggsave (\u0026#34;figures/PV_win_map.png\u0026#34;) ## Saving 7 x 5 in image Here, I have coded which candidate won in each state during the 2020 election between President Joe Biden and President Donald Trump. Democrats did very well along the coasts and Republicans the midwest and South with the notable exception of Georgia. Throughout this blog, I will draw consistent attention onto Georgia because it is my home state and I find its political behavior interesting.\nd_pvstate_wide |\u0026gt; filter(year \u0026gt;= 1980) |\u0026gt; left_join(states_map, by = \u0026#34;region\u0026#34;) |\u0026gt; mutate(winner = ifelse(R_pv2p\u0026gt;D_pv2p, \u0026#34;republican\u0026#34;, \u0026#34;democrat\u0026#34;)) |\u0026gt; ggplot(aes(long, lat, group = group)) + facet_wrap(facets = year ~.) + geom_polygon(aes(fill = winner), color = \u0026#34;white\u0026#34;)+ scale_fill_manual(values = c(\u0026#34;steelblue\u0026#34;, \u0026#34;tomato3\u0026#34;)) + labs(title = \u0026#34;Presidential Vote Share by State\u0026#34;, subtitle = \u0026#34;1980-2020\u0026#34;) + theme(strip.text = element_text(size = 12), aspect.ratio = 1) + my_prettier_theme() + theme(axis.title.x= element_blank(), axis.title.y= element_blank(), axis.text.x= element_blank(), axis.text.y= element_blank(), axis.ticks = element_blank(), axis.line= element_blank()) ## Warning in left_join(filter(d_pvstate_wide, year \u0026gt;= 1980), states_map, by = \u0026quot;region\u0026quot;): Detected an unexpected many-to-many relationship between `x` and `y`. ## ℹ Row 1 of `x` matches multiple rows in `y`. ## ℹ Row 1 of `y` matches multiple rows in `x`. ## ℹ If a many-to-many relationship is expected, set `relationship = ## \u0026quot;many-to-many\u0026quot;` to silence this warning. ggsave (\u0026#34;figures/PV_states_historical.png\u0026#34;) ## Saving 7 x 5 in image Placing the last map in context, we can see how certain states have either shifted parties (in the sense of having a preference for one party over another) or flip-flopped between elections over time. Something that sticks out to me is that California had pretty consistently voted Republican until 1992 when it firmly switched Democrat. New York has cast its electoral votes for Democrats for all elections in this period except 1984. Certain regions like the Midwest are solidly Republican from 1980 to 2020 and states like Texas, Alabama, Mississippi, South Carolina are firmly red. It appears that in the past few elections most states vote for a single party pretty consistently, but there exist certain states that swing either way.\n####----------------------------------------------------------# #### Forecast: simplified electoral cycle model. ####----------------------------------------------------------# # Create prediction (pv2p and margin) based on simplified electoral cycle model: # vote_2024 = 3/4*vote_2020 + 1/4*vote_2016 (lag1, lag2, respectively). pv2p_2024_states \u0026lt;- d_pvstate_wide |\u0026gt; filter(year == 2020) |\u0026gt; group_by(state)|\u0026gt; summarize(R_pv2p_2024 = .75*R_pv2p + .25*R_pv2p_lag1, D_pv2p_2024 = .75*D_pv2p + .25*D_pv2p_lag1) |\u0026gt; mutate(pv2p_2024_margin = R_pv2p_2024 - D_pv2p_2024, winner = ifelse(R_pv2p_2024 \u0026gt; D_pv2p_2024, \u0026#34;R\u0026#34;, \u0026#34;D\u0026#34;), region = tolower(state)) pv2p_2024_states_2 \u0026lt;- pv2p_2024_states # Plot the margin of victory in a U.S. state map. states_map \u0026lt;- map_data(\u0026#34;state\u0026#34;) state_mapa \u0026lt;- pv2p_2024_states |\u0026gt; left_join(states_map, by = \u0026#34;region\u0026#34;) state_centers \u0026lt;- data.frame(state.center, state.abb, state.name) state_mapa \u0026lt;- state_mapa |\u0026gt; ggplot(aes(long, lat, group = group)) + geom_polygon(aes(fill = pv2p_2024_margin), color = \u0026#34;black\u0026#34;)+ scale_fill_gradient2(high = \u0026#34;tomato3\u0026#34;, low = \u0026#34;steelblue3\u0026#34;, mid = \u0026#34;white\u0026#34;, name = \u0026#34;Two-Party Win Margin\u0026#34;, breaks = c(-50, -25, 0, 25, 50), limits = c(-50,50)) + labs(title = \u0026#34;2024 Presidential Forecast\u0026#34;, subtitle = \u0026#34;Simplified Electoral Cycle Model\u0026#34;) + my_prettier_theme() + theme(axis.title.x= element_blank(), axis.title.y= element_blank(), axis.text.x= element_blank(), axis.text.y= element_blank(), axis.ticks = element_blank(), axis.line= element_blank()) state_mapa ggsave(\u0026#34;figures/PV2024_simple_forecast.png\u0026#34;) ## Saving 7 x 5 in image For the above map, we rely on a very basic mathematical model to predict the outcome of the upcoming election. It works as a such: in a given state, we can find the popular vote in the 2024 election by \\(vote_{2024} = \\frac{3}{4}*vote_{2020} + \\frac{1}{4}*vote_{2016}\\). From there, we can color code each state on a gradient, which relies on the projected win margin for the two main parties. We find that states that are consistently red or blue tend to stay that way. The battleground states, which are those closest to white, are Pennsylvania, Georgia, Wisconsin, North Carolina, Nevada, and Arizona. This falls in line with generally accepted knowledge about the political behavior in these states. One thing that surprised me though was how close Texas is to being a battleground state based on this projection.\n####----------------------------------------------------------# #### Extension 1: Add state labels ####----------------------------------------------------------# # Rename ggplot state data region variable to state for ease states_map \u0026lt;- map_data(\u0026#34;state\u0026#34;) |\u0026gt; rename(state = region) # Transform state boundaries into an sf object states_sf \u0026lt;- st_as_sf(states_map, coords = c(\u0026#34;long\u0026#34;, \u0026#34;lat\u0026#34;), crs = 4326, agr = \u0026#34;constant\u0026#34;) # Create a geometry for each state states_sf \u0026lt;- states_sf |\u0026gt; group_by(state) |\u0026gt; summarize(geometry = st_combine(geometry)) |\u0026gt; st_cast(\u0026#34;POLYGON\u0026#34;) |\u0026gt; st_make_valid() # Merge with your election results data pv2p_2024_states \u0026lt;- pv2p_2024_states |\u0026gt; mutate(state = tolower(state)) # Merge state polygons with 2024 vote margin data states_sf \u0026lt;- left_join(states_sf, pv2p_2024_states, by = \u0026#34;state\u0026#34;) # Create an interactive map with leaflet interactive_map \u0026lt;- leaflet(states_sf) |\u0026gt; addTiles() |\u0026gt; addPolygons( fillColor = ~colorBin(palette = c(\u0026#34;steelblue3\u0026#34;, \u0026#34;white\u0026#34;, \u0026#34;tomato3\u0026#34;), domain = states_sf$pv2p_2024_margin, bins = c(-50, -25, 0, 25, 50))(pv2p_2024_margin), fillOpacity = 0.7, color = \u0026#34;black\u0026#34;, weight = 1, highlight = highlightOptions( weight = 3, color = \u0026#34;#666\u0026#34;, fillOpacity = 0.7, bringToFront = TRUE ), label = ~paste(str_to_title(state), \u0026#34; Win Margin: \u0026#34;, round(pv2p_2024_margin,2)), labelOptions = labelOptions( style = list(\u0026#34;font-weight\u0026#34; = \u0026#34;normal\u0026#34;, padding = \u0026#34;5px 10px\u0026#34;), textsize = \u0026#34;15px\u0026#34;, direction = \u0026#34;auto\u0026#34; ) ) |\u0026gt; addLegend( pal = colorBin(palette = c(\u0026#34;steelblue3\u0026#34;, \u0026#34;white\u0026#34;, \u0026#34;tomato3\u0026#34;), domain = states_sf$pv2p_2024_margin, bins = c(-50, -25, 0, 25, 50)), values = ~pv2p_2024_margin, opacity = 0.7, title = \u0026#34;Two-Party Win Margin (%)\u0026#34;, position = \u0026#34;bottomleft\u0026#34; ) |\u0026gt; addControl( html = \u0026#34;\u0026lt;h3 style=\u0026#39;color: black; text-align: center;\u0026#39;\u0026gt;2024 Presidential Forecast\u0026lt;/h3\u0026gt;\u0026lt;h5\u0026gt;Simplified Electoral Cycle Model\u0026lt;/h5\u0026gt;\u0026#34;, position = \u0026#34;topright\u0026#34;, className = \u0026#34;map-title\u0026#34;) ## Warning in colorBin(palette = c(\u0026quot;steelblue3\u0026quot;, \u0026quot;white\u0026quot;, \u0026quot;tomato3\u0026quot;), domain = ## states_sf$pv2p_2024_margin, : Some values were outside the color scale and will ## be treated as NA interactive_map If you are unfamiliar with American geography, here is an interactive version of the same map, where you can see state labels and what notable cities are in each state.\n# Generate projected state winners and merge with electoral college votes to make # summary of electoral college vote distributions. ec \u0026lt;- read_csv(\u0026#34;ec_full.csv\u0026#34;) ## Rows: 1010 Columns: 4 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: \u0026quot;,\u0026quot; ## chr (2): state, stateab ## dbl (2): year, electors ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. pv2p_2024_states_2 \u0026lt;- pv2p_2024_states_2 |\u0026gt; mutate(year = 2024)|\u0026gt; left_join(ec, by = c(\u0026#34;state\u0026#34;, \u0026#34;year\u0026#34;)) projected_electoral_winner \u0026lt;- pv2p_2024_states_2 |\u0026gt; group_by(winner)|\u0026gt; summarize(electoral_votes = sum(electors)) projected_electoral_winner ## # A tibble: 2 × 2 ## winner electoral_votes ## \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt; ## 1 D 276 ## 2 R 262 Harris: 276 # Trump: 262 # Using the formula we drew on before, we can determine which states will (by this model) cast their electoral votes for Democrats and which will for Republicans. Then, we tally up the totals and find that Democrats pass the threshold of 270 to win the office. Based on this very rudimentary model, Kamala Harris is projected to be the next president of the United States.\nYou can find my code for this entry by clicking on the Github link to the right. Please reach out if you encounter any errors.\nSources # Grimmer, Justin. “Don’t Trust the Election Forecasts.” POLITICO, POLITICO, 3 Sept. 2024, www.politico.com/news/magazine/2024/09/03/election-forecasts-data-00176905.\nJones, Jeffrey M. “U.S. Political Party Preferences Shifted Greatly During 2021.” Gallup, 17 Jan. 2022, https://news.gallup.com/poll/388781/political-party-preferences-shifted-greatly-during-2021.aspx.\nData Provided by GOV 1347: Election Analytics teaching staff.\n"}]